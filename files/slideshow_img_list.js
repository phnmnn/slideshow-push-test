let slideshow_img_list = [



    {
        title: 'Ordered dithering ',
        url: 'https://upload.wikimedia.org/wikipedia/en/4/46/Lenna_ordered_dither.png',
        description: 'Ordered dithering is an image dithering algorithm. It is commonly used to display a continuous image on a display of smaller color depth. For example, Microsoft Windows uses it in 16-color graphics modes. The algorithm is characterized by noticeable crosshatch patterns in the result.',
        id: '0'
        },
        {
        title: 'Ordered dithering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e5/Ordered_4x4_Bayer_matrix_dithering.png',
        description: 'Ordered dithering is an image dithering algorithm. It is commonly used to display a continuous image on a display of smaller color depth. For example, Microsoft Windows uses it in 16-color graphics modes. The algorithm is characterized by noticeable crosshatch patterns in the result.',
        id: '1'
        },
        {
        title: 'Ordered dithering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4b/Scale_ordered_dither.png',
        description: 'Ordered dithering is an image dithering algorithm. It is commonly used to display a continuous image on a display of smaller color depth. For example, Microsoft Windows uses it in 16-color graphics modes. The algorithm is characterized by noticeable crosshatch patterns in the result.',
        id: '2'
        },
        {
        title: 'Ordered dithering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'Ordered dithering is an image dithering algorithm. It is commonly used to display a continuous image on a display of smaller color depth. For example, Microsoft Windows uses it in 16-color graphics modes. The algorithm is characterized by noticeable crosshatch patterns in the result.',
        id: '3'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Bayer_pattern_on_sensor.svg/700px-Bayer_pattern_on_sensor.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '4'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Bayer_pattern_on_sensor_profile.svg/700px-Bayer_pattern_on_sensor_profile.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '5'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Colorful_spring_garden_Bayer_%2B_RGB.png/480px-Colorful_spring_garden_Bayer_%2B_RGB.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '6'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/False_colour_artifact.JPG/440px-False_colour_artifact.JPG',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '7'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Zippering_artifact.JPG/440px-Zippering_artifact.JPG',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '8'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Kodak_RGBW_patterns.svg/480px-Kodak_RGBW_patterns.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '9'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/RGBW_Bayer.svg/128px-RGBW_Bayer.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '10'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/EXR_sensor.svg/216px-EXR_sensor.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '11'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Xtranscolourfilter.svg/200px-Xtranscolourfilter.svg.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '12'
        },
        {
        title: 'Bayer filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/10/US03971065_Bayer_Front.png',
        description: 'A Bayer filter mosaic is a color filter array (CFA) for arranging RGB color filters on a square grid of photosensors. Its particular arrangement of color filters is used in most single-chip digital image sensors used in digital cameras, camcorders, and scanners to create a color image. The filter pattern is half green, one quarter red and one quarter blue, hence is also called BGGR, RGBG, GRBG,[3] or RGGB.[4]',
        id: '13'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c1/Michelangelo%27s_David_-_Floyd-Steinberg.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '14'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/aa/Reducing_amplitude_resolution_plot.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '15'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Dithering_example_red_blue.svg/132px-Dithering_example_red_blue.svg.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '16'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d9/256colortestthing.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '17'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Color_dithering_on_a_towel.jpg/440px-Color_dithering_on_a_towel.jpg',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '18'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Dithering_example_undithered.png/225px-Dithering_example_undithered.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '19'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Dithering_example_undithered_web_palette.png/225px-Dithering_example_undithered_web_palette.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '20'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Dithering_example_dithered_web_palette.png/225px-Dithering_example_dithered_web_palette.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '21'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Dithering_example_dithered_256color.png/225px-Dithering_example_dithered_256color.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '22'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Dithering_example_undithered_16color.png/225px-Dithering_example_undithered_16color.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '23'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Dithering_example_dithered_16color.png/225px-Dithering_example_dithered_16color.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '24'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/71/Michelangelo%27s_David_-_63_grijswaarden.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '25'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a3/Michelangelo%27s_David_-_drempel.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '26'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/ce/Michelangelo%27s_David_-_ruis.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '27'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e3/Michelangelo%27s_David_-_halftoon.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '28'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ef/Michelangelo%27s_David_-_Bayer.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '29'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/48/Michelangelo%27s_David_-_Void-and-Cluster.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '30'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c1/Michelangelo%27s_David_-_Floyd-Steinberg.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '31'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/49/Michelangelo%27s_David_-_Jarvis%2C_Judice_%26_Ninke.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '32'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6d/Michelangelo%27s_David_-_Stucki.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '33'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/f5/Michelangelo%27s_David_-_Burkes.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '34'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a1/Michelangelo%27s_David_-_Sierra.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '35'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c9/Michelangelo%27s_David_-_tweerijig_Sierra.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '36'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d8/Michelangelo%27s_David_-_Sierra%27s_Filter_Lite.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '37'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4c/Michelangelo%27s_David_-_Atkinson.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '38'
        },
        {
        title: 'Dither ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b7/David-Gradient_based.png',
        description: 'Dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images. Dither is routinely used in processing of both digital audio and video data, and is often one of the last stages of mastering audio to a CD',
        id: '39'
        },
        {
        title: 'Quantization (signal processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Quantization_error.png/1000px-Quantization_error.png',
        description: 'Quantization, in mathematics and digital signal processing, is the process of mapping input values from a large set (often a continuous set) to output values in a (countable) smaller set, often with a finite number of elements.  Rounding and truncation are typical examples of quantization processes.  Quantization is involved to some degree in nearly all digital signal processing, as the process of representing a signal in digital form ordinarily involves rounding.  Quantization also forms the core of essentially all lossy compression algorithms',
        id: '40'
        },
        {
        title: 'Quantization (signal processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/2-bit_resolution_analog_comparison.png/440px-2-bit_resolution_analog_comparison.png',
        description: 'Quantization, in mathematics and digital signal processing, is the process of mapping input values from a large set (often a continuous set) to output values in a (countable) smaller set, often with a finite number of elements.  Rounding and truncation are typical examples of quantization processes.  Quantization is involved to some degree in nearly all digital signal processing, as the process of representing a signal in digital form ordinarily involves rounding.  Quantization also forms the core of essentially all lossy compression algorithms',
        id: '41'
        },
        {
        title: 'Quantization (signal processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/3-bit_resolution_analog_comparison.png/440px-3-bit_resolution_analog_comparison.png',
        description: 'Quantization, in mathematics and digital signal processing, is the process of mapping input values from a large set (often a continuous set) to output values in a (countable) smaller set, often with a finite number of elements.  Rounding and truncation are typical examples of quantization processes.  Quantization is involved to some degree in nearly all digital signal processing, as the process of representing a signal in digital form ordinarily involves rounding.  Quantization also forms the core of essentially all lossy compression algorithms',
        id: '42'
        },
        {
        title: 'Quantization (signal processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Frequency_spectrum_of_a_sinusoid_and_its_quantization_noise_floor.gif/600px-Frequency_spectrum_of_a_sinusoid_and_its_quantization_noise_floor.gif',
        description: 'Quantization, in mathematics and digital signal processing, is the process of mapping input values from a large set (often a continuous set) to output values in a (countable) smaller set, often with a finite number of elements.  Rounding and truncation are typical examples of quantization processes.  Quantization is involved to some degree in nearly all digital signal processing, as the process of representing a signal in digital form ordinarily involves rounding.  Quantization also forms the core of essentially all lossy compression algorithms',
        id: '43'
        },
        {
        title: 'Stochastic ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/32px-Wiktionary-logo-en-v2.svg.png',
        description: 'Stochastic (from Greek  στόχος (stókhos) refers to the property of being well described by a random probability distribution. Although stochasticity and randomness are distinct in that the former refers to a modeling approach and the latter refers to phenomena themselves, these two terms are often used synonymously. Furthermore, in probability theory, the formal concept of a stochastic process is also referred to as a random process',
        id: '44'
        },
        {
        title: 'Colour banding ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Colour banding is a subtle form of posterization in digital images, caused by the color of each pixel being rounded to the nearest of the digital color levels. While posterization is often done for artistic effect, colour banding is an undesired artifact. In 24-bit colour modes, 8 bits per channel is usually considered sufficient to render images in Rec. 709 or sRGB. However the eye can see the difference between the color levels, especially when there is a sharp border between two large areas of adjacent color levels. This will happen with gradual gradients (like sunsets, dawns or clear blue skies), and also when blurring an image a large amount',
        id: '45'
        },
        {
        title: 'Colour banding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/be/The_Foston_by_pass_on_the_A1_North_-_geograph.org.uk_-_1068397.jpg',
        description: 'Colour banding is a subtle form of posterization in digital images, caused by the color of each pixel being rounded to the nearest of the digital color levels. While posterization is often done for artistic effect, colour banding is an undesired artifact. In 24-bit colour modes, 8 bits per channel is usually considered sufficient to render images in Rec. 709 or sRGB. However the eye can see the difference between the color levels, especially when there is a sharp border between two large areas of adjacent color levels. This will happen with gradual gradients (like sunsets, dawns or clear blue skies), and also when blurring an image a large amount',
        id: '46'
        },
        {
        title: 'Colour banding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9a/Colour_banding_example01.png',
        description: 'Colour banding is a subtle form of posterization in digital images, caused by the color of each pixel being rounded to the nearest of the digital color levels. While posterization is often done for artistic effect, colour banding is an undesired artifact. In 24-bit colour modes, 8 bits per channel is usually considered sufficient to render images in Rec. 709 or sRGB. However the eye can see the difference between the color levels, especially when there is a sharp border between two large areas of adjacent color levels. This will happen with gradual gradients (like sunsets, dawns or clear blue skies), and also when blurring an image a large amount',
        id: '47'
        },
        {
        title: 'Colour banding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'Colour banding is a subtle form of posterization in digital images, caused by the color of each pixel being rounded to the nearest of the digital color levels. While posterization is often done for artistic effect, colour banding is an undesired artifact. In 24-bit colour modes, 8 bits per channel is usually considered sufficient to render images in Rec. 709 or sRGB. However the eye can see the difference between the color levels, especially when there is a sharp border between two large areas of adjacent color levels. This will happen with gradual gradients (like sunsets, dawns or clear blue skies), and also when blurring an image a large amount',
        id: '48'
        },
        {
        title: 'Colour banding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Emoji_u1f4bb.svg/60px-Emoji_u1f4bb.svg.png',
        description: 'Colour banding is a subtle form of posterization in digital images, caused by the color of each pixel being rounded to the nearest of the digital color levels. While posterization is often done for artistic effect, colour banding is an undesired artifact. In 24-bit colour modes, 8 bits per channel is usually considered sufficient to render images in Rec. 709 or sRGB. However the eye can see the difference between the color levels, especially when there is a sharp border between two large areas of adjacent color levels. This will happen with gradual gradients (like sunsets, dawns or clear blue skies), and also when blurring an image a large amount',
        id: '49'
        },
        {
        title: 'Posterization ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Posterization or posterisation of an image is the conversion of a continuous gradation of tone to several regions of fewer tones, causing abrupt changes from one tone to another.  This was originally done with photographic processes to create posters.  It can now be done photographically or with digital image processing and may be deliberate or an unintended artifact of color quantization.',
        id: '50'
        },
        {
        title: 'Posterization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Posterization_example.jpg/600px-Posterization_example.jpg',
        description: 'Posterization or posterisation of an image is the conversion of a continuous gradation of tone to several regions of fewer tones, causing abrupt changes from one tone to another.  This was originally done with photographic processes to create posters.  It can now be done photographically or with digital image processing and may be deliberate or an unintended artifact of color quantization.',
        id: '51'
        },
        {
        title: 'Posterization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Lucidity_I.jpg/600px-Lucidity_I.jpg',
        description: 'Posterization or posterisation of an image is the conversion of a continuous gradation of tone to several regions of fewer tones, causing abrupt changes from one tone to another.  This was originally done with photographic processes to create posters.  It can now be done photographically or with digital image processing and may be deliberate or an unintended artifact of color quantization.',
        id: '52'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Supersampling.svg/440px-Supersampling.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '53'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Naa-vs-aa.png/340px-Naa-vs-aa.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '54'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Supersampling_-_Uniform.svg/240px-Supersampling_-_Uniform.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '55'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Supersampling_-_Checker.svg/240px-Supersampling_-_Checker.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '56'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Supersampling_-_Random.svg/240px-Supersampling_-_Random.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '57'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Supersampling_-_Jittering.svg/240px-Supersampling_-_Jittering.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '58'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Supersampling_-_Poisson_Disc.svg/240px-Supersampling_-_Poisson_Disc.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '59'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Supersampling_-_QMC.svg/240px-Supersampling_-_QMC.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '60'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Supersampling_-_N-Rooks.svg/240px-Supersampling_-_N-Rooks.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '61'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Supersampling_-_RGSS.svg/240px-Supersampling_-_RGSS.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '62'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Supersampling_-_Quincunx.svg/240px-Supersampling_-_Quincunx.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '63'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Supersampling_-_Flipquad.svg/240px-Supersampling_-_Flipquad.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '64'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Supersampling_-_Fliptri.svg/240px-Supersampling_-_Fliptri.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '65'
        },
        {
        title: 'Supersampling ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Poisson_disk_sampling.svg/440px-Poisson_disk_sampling.svg.png',
        description: 'Supersampling or supersampling anti-aliasing (SSAA) is a spatial anti-aliasing method, i.e. a method used to remove aliasing (jagged and pixelated edges, colloquially known as "jaggies") from images rendered in computer games or other computer programs that generate imagery. Aliasing occurs because unlike real-world objects, which have continuous smooth curves and lines, a computer screen shows the viewer a large number of small squares.  These pixels all have the same size, and each one has a single color. A line can only be shown as a collection of pixels, and therefore appears jagged unless it is perfectly horizontal or vertical.  The aim of supersampling is to reduce this effect.  Color samples are taken at several instances inside the pixel (not just at the center as normal), and an average color value is calculated. This is achieved by rendering the image at a much higher resolution than the one being displayed, then shrinking it to the desired size, using the extra pixels for calculation. The result is a downsampled image with smoother transitions from one line of pixels to another along the edges of objects.',
        id: '66'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Moire_pattern_of_bricks.jpg/284px-Moire_pattern_of_bricks.jpg',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '67'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Moire_pattern_of_bricks_small.jpg/142px-Moire_pattern_of_bricks_small.jpg',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '68'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/3e/WagonWheelEffect.gif',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '69'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/16/Risingstar_test_crop.png',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '70'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/83/FFT_aliasing_600.gif',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '71'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Aliasing-folding_SVG.svg/775px-Aliasing-folding_SVG.svg.png',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '72'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/76/Example_of_spectral_%22folding%22_caused_by_sampling_a_real-valued_waveform.png',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '73'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Aliasing-folding.svg/540px-Aliasing-folding.svg.png',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '74'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Aliasing_between_a_positive_and_a_negative_frequency.svg/600px-Aliasing_between_a_positive_and_a_negative_frequency.svg.png',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '75'
        },
        {
        title: 'Aliasing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Aliasing.gif/600px-Aliasing.gif',
        description: 'In signal processing and related disciplines, aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed from samples is different from the original continuous signal',
        id: '76'
        },
        {
        title: 'Jaggies ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6b/Test_nn.gif',
        description: '"Jaggies" is the informal name for artifacts in raster images, most frequently from aliasing, which in turn is often caused by non-linear mixing effects producing high-frequency components, or missing or poor anti-aliasing filtering prior to sampling.',
        id: '77'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '78'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Rgb-raster-image.svg/440px-Rgb-raster-image.svg.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '79'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e4/Matrix_transpose.gif',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '80'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Raster_graphic_fish_20x23squares_sdtv-example.png/440px-Raster_graphic_fish_20x23squares_sdtv-example.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '81'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/The_use_of_a_raster_data_structure_to_summarize_a_point_pattern.gif/440px-The_use_of_a_raster_data_structure_to_summarize_a_point_pattern.gif',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '82'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '83'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '84'
        },
        {
        title: 'Raster graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/6/6a/Symbol_na_class.svg/31px-Symbol_na_class.svg.png',
        description: 'In computer graphics and digital photography, a raster graphic represents a two-dimensional image as a rectangular matrix or grid of square pixels, viewable via a computer display, paper, or other display medium. A raster is technically characterized by the width and height of the image in pixels and by the number of bits per pixel. Raster images are stored in image files with varying dissemination, production, generation, and acquisition formats.',
        id: '85'
        },
        {
        title: 'Voxel ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Voxels.svg/440px-Voxels.svg.png',
        description: 'In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap, voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).',
        id: '86'
        },
        {
        title: 'Voxel ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b4/Voxelgitter.png',
        description: 'In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap, voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).',
        id: '87'
        },
        {
        title: 'Voxel ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Vg_graphics.svg/200px-Vg_graphics.svg.png',
        description: 'In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap, voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).',
        id: '88'
        },
        {
        title: 'Voxel ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Ribo-Voxels.png/303px-Ribo-Voxels.png',
        description: 'In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap, voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).',
        id: '89'
        },
        {
        title: 'Voxel ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Abdominal_CT_with_scan_range_and_field_of_view%2C_with_box_and_text.jpg/440px-Abdominal_CT_with_scan_range_and_field_of_view%2C_with_box_and_text.jpg',
        description: 'In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap, voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).',
        id: '90'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Idealized_universal_joint_generated_by_ray_tracing.jpg/440px-Idealized_universal_joint_generated_by_ray_tracing.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '91'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Camera_models.jpg/777px-Camera_models.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '92'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Cameras_local_coordinate_system.jpg/440px-Cameras_local_coordinate_system.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '93'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Example_line_drawings.jpg/440px-Example_line_drawings.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '94'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Parallelepipeds.jpg/440px-Parallelepipeds.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '95'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Ray_in_binary_solid_construction.jpg/440px-Ray_in_binary_solid_construction.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '96'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Operations_on_ray_results.jpg/440px-Operations_on_ray_results.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '97'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Two_point_light_sources.jpg/440px-Two_point_light_sources.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '98'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Follow_up_rays_for_effects.jpg/800px-Follow_up_rays_for_effects.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '99'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Tree_of_enclosures.jpg/440px-Tree_of_enclosures.jpg',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '100'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/3a/Anarch_short_gameplay.gif',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '101'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/65/Camera_Rotation_vs_Shearing.gif/440px-Camera_Rotation_vs_Shearing.gif',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '102'
        },
        {
        title: 'Ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'Ray casting is the methodological basis for 3D CAD/CAM solid modeling and image rendering. It is essentially the same as ray tracing for computer graphics where virtual light rays are "cast" or "traced" on their path from the focal point of a camera through each pixel in the camera sensor to determine what is visible along the ray in the 3D scene. The term "Ray Casting" was introduced by Scott Roth while at the General Motors Research Labs from 1978–1980. His paper, "Ray Casting for Modeling Solids", describes modeled solid objects by combining primitive solids, such as blocks and cylinders, using the set operators union (+), intersection (&), and difference (-). The general idea of using these binary operators for solid modeling is largely due to Voelcker and Requichas geometric modelling group at the University of Rochester.[3] See Solid modeling for a broad overview of solid modeling methods. This figure on the right shows a U-Joint modeled from cylinders and blocks in a binary tree using Roths ray casting system, circa 1979.',
        id: '103'
        },
        {
        title: 'Marching cubes ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Marchingcubes-head.png/500px-Marchingcubes-head.png',
        description: 'Marching cubes is a computer graphics algorithm, published in the 1987 SIGGRAPH proceedings by Lorensen and Cline, for extracting a polygonal mesh of an isosurface from a three-dimensional discrete scalar field (the elements of which are sometimes called voxels). The applications of this algorithm are mainly concerned with medical visualizations such as CT and MRI scan data images, and special effects or 3-D modelling with what is usually called metaballs or other metasurfaces. The marching cubes algorithm is meant to be used for 3-D, the 2-D version of this algorithm is called the marching squares algorithm.  ',
        id: '104'
        },
        {
        title: 'Marching cubes ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/MarchingCubes.svg/700px-MarchingCubes.svg.png',
        description: 'Marching cubes is a computer graphics algorithm, published in the 1987 SIGGRAPH proceedings by Lorensen and Cline, for extracting a polygonal mesh of an isosurface from a three-dimensional discrete scalar field (the elements of which are sometimes called voxels). The applications of this algorithm are mainly concerned with medical visualizations such as CT and MRI scan data images, and special effects or 3-D modelling with what is usually called metaballs or other metasurfaces. The marching cubes algorithm is meant to be used for 3-D, the 2-D version of this algorithm is called the marching squares algorithm.  ',
        id: '105'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/VectorBitmapExample.svg/440px-VectorBitmapExample.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '106'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Space_Rocks_%28game%29.jpg/440px-Space_Rocks_%28game%29.jpg',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '107'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Vector-based_example.svg/440px-Vector-based_example.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '108'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Phone.jpg/440px-Phone.jpg',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '109'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Phone.svg/440px-Phone.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '110'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '111'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '112'
        },
        {
        title: 'Vector graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/6/6a/Symbol_na_class.svg/31px-Symbol_na_class.svg.png',
        description: 'Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from  geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons. These mechanisms may include vector display and printing hardware, vector data models and file formats, and software based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations.[1',
        id: '113'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/VectorField.svg/500px-VectorField.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '114'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Radial_vector_field_sparse.svg/280px-Radial_vector_field_sparse.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '115'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Radial_vector_field_dense.svg/280px-Radial_vector_field_dense.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '116'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Vector_sphere.svg/400px-Vector_sphere.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '117'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Cessna_182_model-wingtip-vortex.jpg/500px-Cessna_182_model-wingtip-vortex.jpg',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '118'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Bezier_curves_composition_ray-traced_in_3D.png/440px-Bezier_curves_composition_ray-traced_in_3D.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '119'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Irrotationalfield.svg/600px-Irrotationalfield.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '120'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Magnet0873.png/440px-Magnet0873.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '121'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '122'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '123'
        },
        {
        title: 'Vector field ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In vector calculus and physics, a vector field is an assignment of a vector to each point in a subset of space.  For instance, a vector field in the plane can be visualised as a collection of arrows with a given magnitude and direction, each attached to a point in the plane.  Vector  fields are often used to model, for example, the speed and direction of a moving fluid throughout space, or the strength and direction of some force, such as the magnetic or gravitational force, as it changes from one point to another point.',
        id: '124'
        },
        {
        title: 'Linear algebra ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Linear_subspaces_with_shading.svg/500px-Linear_subspaces_with_shading.svg.png',
        description: 'Linear algebra is the branch of mathematics concerning linear equations such as: ',
        id: '125'
        },
        {
        title: 'Linear algebra ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'Linear algebra is the branch of mathematics concerning linear equations such as: ',
        id: '126'
        },
        {
        title: 'Linear algebra ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'Linear algebra is the branch of mathematics concerning linear equations such as: ',
        id: '127'
        },
        {
        title: 'Linear algebra ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'Linear algebra is the branch of mathematics concerning linear equations such as: ',
        id: '128'
        },
        {
        title: 'Linear algebra ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'Linear algebra is the branch of mathematics concerning linear equations such as: ',
        id: '129'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Matris.png/440px-Matris.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '130'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/MatrixMultiplication.png/600px-MatrixMultiplication.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '131'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Area_parallellogram_as_determinant.svg/440px-Area_parallellogram_as_determinant.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '132'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/VerticalShear_m%3D1.25.svg/350px-VerticalShear_m%3D1.25.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '133'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Flip_map.svg/300px-Flip_map.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '134'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Squeeze_r%3D1.5.svg/300px-Squeeze_r%3D1.5.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '135'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Scaling_by_1.5.svg/250px-Scaling_by_1.5.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '136'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Rotation_by_pi_over_6.svg/250px-Rotation_by_pi_over_6.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '137'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Ellipse_in_coordinate_system_with_semi-axes_labelled.svg/300px-Ellipse_in_coordinate_system_with_semi-axes_labelled.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '138'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Hyperbola2_SVG.svg/300px-Hyperbola2_SVG.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '139'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Determinant_example.svg/600px-Determinant_example.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '140'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Jordan_blocks.svg/500px-Jordan_blocks.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '141'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Labelled_undirected_graph.svg/300px-Labelled_undirected_graph.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '142'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Saddle_Point_SVG.svg/440px-Saddle_Point_SVG.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '143'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Markov_chain_SVG.svg/560px-Markov_chain_SVG.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '144'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '145'
        },
        {
        title: 'Matrix (mathematics) ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object.',
        id: '146'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Cathode_ray_Tube.PNG/600px-Cathode_ray_Tube.PNG',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '147'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Oscilloscopic_tube.jpg/440px-Oscilloscopic_tube.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '148'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/CRT_color_enhanced.png/500px-CRT_color_enhanced.png',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '149'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/CRT_monochrome.png/500px-CRT_monochrome.png',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '150'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Crt14.jpg/500px-Crt14.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '151'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Television_set_from_the_early_1950s.jpg/440px-Television_set_from_the_early_1950s.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '152'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/CRTslowmotion_PetesDragon.jpg/440px-CRTslowmotion_PetesDragon.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '153'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/CRT_image_creation_animation.gif/440px-CRT_image_creation_animation.gif',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '154'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Egun.jpg/440px-Egun.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '155'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Braun_cathode_ray_tube.jpg/700px-Braun_cathode_ray_tube.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '156'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Coating_CRTs_at_Research_Enterprises.jpg/440px-Coating_CRTs_at_Research_Enterprises.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '157'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Mini_Star_416-8834.jpg/440px-Mini_Star_416-8834.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '158'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Trinitron_computer-monitor.jpg/440px-Trinitron_computer-monitor.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '159'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Mini_Star_416_-_cathode_ray_tube-2140.jpg/440px-Mini_Star_416_-_cathode_ray_tube-2140.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '160'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Macintosh_Plus_interior.jpg/440px-Macintosh_Plus_interior.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '161'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Cinescopio_per_televisore_a_schermo_rettangolare%2C_17_pollici%2C_deflessione_110%C2%B0%2C_bianco_e_nero_-_Museo_scienza_tecnologia_Milano_10081_dia.jpg/612px-Cinescopio_per_televisore_a_schermo_rettangolare%2C_17_pollici%2C_deflessione_110%C2%B0%2C_bianco_e_nero_-_Museo_scienza_tecnologia_Milano_10081_dia.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '162'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Cinescopio_per_televisore_a_schermo_rettangolare%2C_13_pollici%2C_deflessione_90%C2%B0%2C_bianco_e_nero_-_Museo_scienza_tecnologia_Milano_10082_dia.jpg/757px-Cinescopio_per_televisore_a_schermo_rettangolare%2C_13_pollici%2C_deflessione_90%C2%B0%2C_bianco_e_nero_-_Museo_scienza_tecnologia_Milano_10082_dia.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '163'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Mini_Star_416_-_cathode_ray_tube_with_deflection_coils-2210.jpg/360px-Mini_Star_416_-_cathode_ray_tube_with_deflection_coils-2210.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '164'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Mini_Star_416_-_cathode_ray_tube%2C_deflection_coils-2146.jpg/360px-Mini_Star_416_-_cathode_ray_tube%2C_deflection_coils-2146.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '165'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Osziroehre.jpg/859px-Osziroehre.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '166'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Monochrome_CRT_electron_gun_close_up.jpg/805px-Monochrome_CRT_electron_gun_close_up.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '167'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/CRT_screen._closeup.jpg/300px-CRT_screen._closeup.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '168'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/CRT_pixel_array.jpg/440px-CRT_pixel_array.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '169'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/CRT_Phosphors.jpg/300px-CRT_Phosphors.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '170'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/CRT_mask_types_en-de.svg/440px-CRT_mask_types_en-de.svg.png',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '171'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/CRT_phosphors.png/440px-CRT_phosphors.png',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '172'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Electron_gun.jpg/560px-Electron_gun.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '173'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/7e/Degauss-in-progress_at_Dell-Trinitron-monitor.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '174'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Mu_metal_CRT_shields.jpg/220px-Mu_metal_CRT_shields.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '175'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/SONY_03JM_2.5%22_Monochrome_Flat_Watchman_CRT_front.jpg/440px-SONY_03JM_2.5%22_Monochrome_Flat_Watchman_CRT_front.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '176'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/SinclairFTV1frontPCB6.jpg/440px-SinclairFTV1frontPCB6.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '177'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/20/SONY_03JM_2.5%22_Monochrome_Flat_Watchman_CRT_side.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '178'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Lissajous-Figur_1_zu_3_%28Oszilloskop%29.jpg/440px-Lissajous-Figur_1_zu_3_%28Oszilloskop%29.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '179'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Kathodestraalbuis2.jpg/440px-Kathodestraalbuis2.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '180'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Tektronix_564_Analog_Storage_Oscilloscope.jpg/440px-Tektronix_564_Analog_Storage_Oscilloscope.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '181'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/78/Nimo_tube_BA0000-P31_showing_digit_9.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '182'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b8/Tabgamb.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '183'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/CRT_implosion.JPG/440px-CRT_implosion.JPG',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '184'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Datapoint_1500_keyboard_mounted_in_case.jpg/440px-Datapoint_1500_keyboard_mounted_in_case.jpg',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '185'
        },
        {
        title: 'Cathode-ray tube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Nuvola_apps_ksim.png/56px-Nuvola_apps_ksim.png',
        description: 'A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, the beams of which are manipulated to display images on a phosphorescent screen. The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer',
        id: '186'
        },
        {
        title: 'Waveform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Waveforms.svg/700px-Waveforms.svg.png',
        description: 'In electronics, acoustics, and related fields, the waveform of a signal is the shape of its graph as a function of time, independent of its time and magnitude scales and of any displacement in time.',
        id: '187'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9f/24_bit.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '188'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/ff/8_bit.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '189'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0d/4_bit.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '190'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/56/2_bit.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '191'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/57/1_bit.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '192'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/16777216colors.png/400px-16777216colors.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '193'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/CIExy1931_srgb_gamut.png/480px-CIExy1931_srgb_gamut.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '194'
        },
        {
        title: 'Color depth ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'Color depth or colour depth (see spelling differences), also known as bit depth, is either the number of bits used to indicate the color of a single pixel, or the number of bits used for each color component of a single pixel. When referring to a pixel, the concept can be defined as bits per pixel (bpp). When referring to a color component, the concept can be defined as bits per component, bits per channel, bits per color (all three abbreviated bpc), and also bits per pixel component, bits per color channel or bits per sample (bps).[3] Modern standards tend to use bits per component,[4][5] but historical lower-depth systems used bits per pixel more often',
        id: '195'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/CIE1931xy_gamut_comparison.svg/440px-CIE1931xy_gamut_comparison.svg.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '196'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Colorspace.png/440px-Colorspace.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '197'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/YoungHelm.jpg/440px-YoungHelm.jpg',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '198'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/1b/RGB_and_CMYK_comparison.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '199'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/AdditiveColor.svg/400px-AdditiveColor.svg.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '200'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/SubtractiveColor.svg/400px-SubtractiveColor.svg.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '201'
        },
        {
        title: 'Color space ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'A color space is a specific organization of colors. In combination with color profiling supported by various physical devices, it supports reproducible representations of color -- whether such representation entails an analog or a digital representation. A color space may be arbitrary, i.e. with physically realized colors assigned to a set of physical color swatches with corresponding assigned color names (including discrete numbers in — for example — the Pantone collection), or structured with mathematical rigor (as with the NCS System, Adobe RGB and sRGB). A "color space" is a useful conceptual tool for understanding the color capabilities of a particular device or digital file. When trying to reproduce color on another device, color spaces can show whether you will be able to retain shadow/highlight detail, color saturation, and by how much either will be compromised.',
        id: '202'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Light_dispersion_of_a_mercury-vapor_lamp_with_a_flint_glass_prism_IPNr%C2%B00125.jpg/440px-Light_dispersion_of_a_mercury-vapor_lamp_with_a_flint_glass_prism_IPNr%C2%B00125.jpg',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '203'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Light_Amplification_by_Stimulated_Emission_of_Radiation.jpg/440px-Light_Amplification_by_Stimulated_Emission_of_Radiation.jpg',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '204'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Newton%27s_color_circle.png/440px-Newton%27s_color_circle.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '205'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Newton_prismatic_colours.JPG/700px-Newton_prismatic_colours.JPG',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '206'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Linear_visible_spectrum.svg/600px-Linear_visible_spectrum.svg.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '207'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Spectrum.svg/780px-Spectrum.svg.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '208'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Rendered_Spectrum.png/780px-Rendered_Spectrum.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '209'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Atmospheric_electromagnetic_opacity.svg/860px-Atmospheric_electromagnetic_opacity.svg.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '210'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Frequency_vs._wave_length.svg/1000px-Frequency_vs._wave_length.svg.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '211'
        },
        {
        title: 'Visible spectrum ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 380 to about 750 nanometers. In terms of frequency, this corresponds to a band in the vicinity of 400–790 terahertz. These boundaries are not sharply defined and may vary per individual. Under optimal conditions these limits of human perception can extend to 310 nm (ultraviolet) and 1100 nm (near infrared).[3][4] The optical spectrum is sometimes considered to be the same as the visible spectrum, but some authors define the term more broadly, to include the ultraviolet and infrared parts of the electromagnetic spectrum as well.[5]',
        id: '212'
        },
        {
        title: 'LZ77 and LZ78 ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977 and 1978. They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG and ZIP.',
        id: '213'
        },
        {
        title: 'LZ77 and LZ78 ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977 and 1978. They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG and ZIP.',
        id: '214'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Felis_silvestris_silvestris_small_gradual_decrease_of_quality.png/400px-Felis_silvestris_silvestris_small_gradual_decrease_of_quality.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '215'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/JPEG_example_subimage.svg/512px-JPEG_example_subimage.svg.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '216'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Dctjpeg.png/438px-Dctjpeg.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '217'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5e/Idct-animation.gif',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '218'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/JPEG_ZigZag.svg/440px-JPEG_ZigZag.svg.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '219'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/JPEG_process.svg/700px-JPEG_process.svg.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '220'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/ff/Lichtenstein_jpeg_difference.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '221'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/39/Lichtenstein_img_processing_test.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '222'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/15/Jpegvergroessert.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '223'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Lossless-circle.png/200px-Lossless-circle.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '224'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Lossy-circle.jpg/200px-Lossy-circle.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '225'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Lossless-circle-canny.png/200px-Lossless-circle-canny.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '226'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Lossy-circle-canny.png/200px-Lossy-circle-canny.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '227'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/JPEG_example_image.jpg/180px-JPEG_example_image.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '228'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/JPEG_example_image_decompressed.jpg/180px-JPEG_example_image_decompressed.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '229'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Visual_impact_of_a_jpeg_compression_on_Photoshop.jpg/400px-Visual_impact_of_a_jpeg_compression_on_Photoshop.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '230'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/JPEG_example_JPG_RIP_100.jpg/160px-JPEG_example_JPG_RIP_100.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '231'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/JPEG_example_JPG_RIP_050.jpg/160px-JPEG_example_JPG_RIP_050.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '232'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/JPEG_example_JPG_RIP_025.jpg/160px-JPEG_example_JPG_RIP_025.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '233'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/JPEG_example_JPG_RIP_010.jpg/160px-JPEG_example_JPG_RIP_010.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '234'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/JPEG_example_JPG_RIP_001.jpg/160px-JPEG_example_JPG_RIP_001.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '235'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/JPS-sample.jpg/440px-JPS-sample.jpg',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '236'
        },
        {
        title: 'JPEG ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/6/6a/Symbol_na_class.svg/31px-Symbol_na_class.svg.png',
        description: 'JPEG (/ˈdʒeɪpɛɡ/ JAY-peg) is a commonly used method of lossy compression for digital images, particularly for those images produced by digital photography. The degree of compression can be adjusted, allowing a selectable tradeoff between storage size and image quality. JPEG typically achieves 10:1 compression with little perceptible loss in image quality.[3] Since its introduction in 1992, JPEG has been the most widely used image compression standard in the world,[4][5] and the most widely used digital image format, with several billion JPEG images produced every day as of 2015.[6',
        id: '237'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/560px-PNG_transparency_demonstration_1.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '238'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/PNG-Gradient_hex.png/440px-PNG-Gradient_hex.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '239'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/PNG-Gradient.png/60px-PNG-Gradient.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '240'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9d/PNG_color_depth_comparison.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '241'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/ce/PNG_demo_Banana.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '242'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/39/PNG_demo_heatmap_Banana.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym "PNGs not GIF".[5',
        id: '243'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Pixel-prediction.svg/256px-Pixel-prediction.svg.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '244'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/89/PNG-Gradient.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '245'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/27/Adam7_passes.gif',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '246'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/14/Animated_PNG_example_bouncing_beach_ball.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '247'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a4/Comparison_of_JPEG_and_PNG.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '248'
        },
        {
        title: 'Portable Network Graphics ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/6/6a/Symbol_na_class.svg/31px-Symbol_na_class.svg.png',
        description: 'Portable Network Graphics (PNG, officially pronounced /pɪŋ/[3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression. PNG was developed as an improved, non-patented replacement for Graphics Interchange Format (GIF) — unofficially, the initials PNG stood for the recursive acronym PNG not GIF".[5',
        id: '249'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Recursive_raytrace_of_a_sphere.png/440px-Recursive_raytrace_of_a_sphere.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '250'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/D%C3%BCrer_-_Man_Drawing_a_Lute.jpg/440px-D%C3%BCrer_-_Man_Drawing_a_Lute.jpg',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '251'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Albrecht_durer_ray_tracing_enhanced.png/440px-Albrecht_durer_ray_tracing_enhanced.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '252'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flip_Book_Movie_v2.gif/440px-Flip_Book_Movie_v2.gif',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '253'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Ray_trace_diagram.svg/600px-Ray_trace_diagram.svg.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '254'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Ray_Tracing_Illustration_First_Bounce.png/600px-Ray_Tracing_Illustration_First_Bounce.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '255'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b2/RaysViewportSchema.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '256'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Visualization_of_SDF_ray_marching_algorithm.png/440px-Visualization_of_SDF_ray_marching_algorithm.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '257'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Glasses_800_edit.png/600px-Glasses_800_edit.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '258'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/BallsRender.png/600px-BallsRender.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '259'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Ray-traced_steel_balls.jpg/600px-Ray-traced_steel_balls.jpg',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '260'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Glass_ochem.png/600px-Glass_ochem.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '261'
        },
        {
        title: 'Ray tracing (graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/PathOfRays.svg/440px-PathOfRays.svg.png',
        description: 'In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images',
        id: '262'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/DOF-ShallowDepthofField.jpg/440px-DOF-ShallowDepthofField.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '263'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Depth_of_field_illustration.svg/440px-Depth_of_field_illustration.svg.png',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '264'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Dof_blocks_f1_4.jpg/500px-Dof_blocks_f1_4.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '265'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Dof_blocks_f4_0.jpg/500px-Dof_blocks_f4_0.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '266'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Dof_blocks_f22.jpg/500px-Dof_blocks_f22.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '267'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/DOF_scale_detail.png/440px-DOF_scale_detail.png',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '268'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/TessinaDOF.jpg/440px-TessinaDOF.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '269'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Contessa_hyperfocal.JPG/440px-Contessa_hyperfocal.JPG',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '270'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Minox_LX_hyperfocal.JPG/440px-Minox_LX_hyperfocal.JPG',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '271'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Nikon_28mm_lens_at_hyperfocus.jpg/440px-Nikon_28mm_lens_at_hyperfocus.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '272'
        },
        {
        title: 'Depth of field ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Minolta_100-300_at_hyperfocal_distance.jpg/440px-Minolta_100-300_at_hyperfocal_distance.jpg',
        description: 'For many cameras, depth of field (DOF) is the distance between the nearest and the farthest objects that are in acceptably sharp focus in an image.  The depth of field can be calculated based on focal length, distance to subject, the acceptable circle of confusion size, and aperture. A particular depth of field may be chosen for technical or artistic purposes. Limitations of depth of field can sometimes be overcome with various techniques and equipment.',
        id: '273'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Out-of-focus_image_of_a_spoke_target..svg/80px-Out-of-focus_image_of_a_spoke_target..svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '274'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/HartmannShack_1lenslet.svg/80px-HartmannShack_1lenslet.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '275'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Spherical_aberration_3.svg/80px-Spherical_aberration_3.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '276'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Astigmatism.svg/80px-Astigmatism.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '277'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Lens_coma.svg/80px-Lens_coma.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '278'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Barrel_distortion.svg/80px-Barrel_distortion.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '279'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Field_curvature.svg/80px-Field_curvature.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '280'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Chromatic_aberration_lens_diagram.svg/80px-Chromatic_aberration_lens_diagram.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '281'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/66/Chromatic_aberration_%28comparison%29.jpg',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '282'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Comparison_axial_lateral_chromatic_aberration.svg/440px-Comparison_axial_lateral_chromatic_aberration.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '283'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Comparison_chromatic_focus_shift_plots.svg/520px-Comparison_chromatic_focus_shift_plots.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '284'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Chromatic_aberration_lens_diagram.svg/500px-Chromatic_aberration_lens_diagram.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '285'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Diffractive.png/272px-Diffractive.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '286'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Lens6b-en.svg/500px-Lens6b-en.svg.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '287'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Nearsighted_color_fringing_-9.5_diopter_-_Canon_PowerShot_A640_thru_glasses_-_closeup_detail.jpg/425px-Nearsighted_color_fringing_-9.5_diopter_-_Canon_PowerShot_A640_thru_glasses_-_closeup_detail.jpg',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '288'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Purple_fringing.jpg/500px-Purple_fringing.jpg',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '289'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Filigranski_nakit_02_edit.JPG/340px-Filigranski_nakit_02_edit.JPG',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '290'
        },
        {
        title: 'Chromatic aberration ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Chris-chromatic-aberration.png',
        description: ' Tilt Spherical aberration Astigmatism Coma  Distortion Petzval field curvature Chromatic aberration',
        id: '291'
        },
        {
        title: 'Ambient occlusion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/AmbientOcclusion_German.jpg/440px-AmbientOcclusion_German.jpg',
        description: 'In 3D computer graphics, modeling, and animation, ambient occlusion is a shading and rendering technique used to calculate how exposed each point in a scene is to ambient lighting. For example, the interior of a tube is typically more occluded (and hence darker) than the exposed outer surfaces, and becomes darker the deeper inside the tube one goes.',
        id: '292'
        },
        {
        title: 'Ambient occlusion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Aocclude_bentnormal.png/800px-Aocclude_bentnormal.png',
        description: 'In 3D computer graphics, modeling, and animation, ambient occlusion is a shading and rendering technique used to calculate how exposed each point in a scene is to ambient lighting. For example, the interior of a tube is typically more occluded (and hence darker) than the exposed outer surfaces, and becomes darker the deeper inside the tube one goes.',
        id: '293'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Kaustik.jpg/220px-Kaustik.jpg',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '294'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/8c/Caustic00.jpg',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '295'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Great_Barracuda%2C_corals%2C_sea_urchin_and_Caustic_%28optics%29_in_Kona%2C_Hawaii_2009.jpg/440px-Great_Barracuda%2C_corals%2C_sea_urchin_and_Caustic_%28optics%29_in_Kona%2C_Hawaii_2009.jpg',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '296'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Caustics.gif/500px-Caustics.gif',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '297'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/c/c6/Wine_glass_caustic_example.jpg/340px-Wine_glass_caustic_example.jpg',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '298'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a5/Computer_rendering_of_a_wine_glass_caustic.png/440px-Computer_rendering_of_a_wine_glass_caustic.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '299'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/CausOptim.png/762px-CausOptim.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '300'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/76/TarOptim.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '301'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/59/Cam-geo-app.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '302'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Diffren.png/966px-Diffren.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '303'
        },
        {
        title: 'Caustic (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Screenshot_from_2020-01-29_13-57-56.png/462px-Screenshot_from_2020-01-29_13-57-56.png',
        description: 'In optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface.  The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light.  Therefore, in the photo to the right, caustics can be seen as patches of light or their bright edges. These shapes often have cusp singularities.',
        id: '304'
        },
        {
        title: 'Noise reduction ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Noisecorrp.png/580px-Noisecorrp.png',
        description: 'Noise reduction is the process of removing noise from a signal. Noise reduction techniques exist for audio and images. Noise reduction algorithms may distort the signal to some degree.',
        id: '305'
        },
        {
        title: 'Downsampling (signal processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Spectral_effects_of_decimation.svg/800px-Spectral_effects_of_decimation.svg.png',
        description: 'In digital signal processing, downsampling, compression, and decimation are terms associated with the process of resampling in a multi-rate digital signal processing system. Both downsampling and decimation can be synonymous with compression, or they can describe an entire process of bandwidth reduction (filtering) and sample-rate reduction. When the process is performed on a sequence of samples of a signal or a continuous function, it produces an approximation of the sequence that would have been obtained by sampling the signal at a lower rate (or density, as in the case of a photograph).',
        id: '306'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/CQT-piano-chord.png/440px-CQT-piano-chord.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '307'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Sine_voltage.svg/256px-Sine_voltage.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '308'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Phase_shift.svg/256px-Phase_shift.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '309'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fourier_unit_pulse.svg/600px-Fourier_unit_pulse.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '310'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fourier_unit_pulse.svg/600px-Fourier_unit_pulse.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '311'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/72/Fourier_transform_time_and_frequency_domains_%28small%29.gif',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '312'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Rising_circular.gif/440px-Rising_circular.gif',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '313'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Function_ocsillating_at_3_hertz.svg/720px-Function_ocsillating_at_3_hertz.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '314'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Onfreq.svg/720px-Onfreq.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '315'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Offfreq.svg/720px-Offfreq.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '316'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fourier_transform_of_oscillating_function.svg/720px-Fourier_transform_of_oscillating_function.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '317'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Fourier_transform_-_time_shifted_signal.gif/390px-Fourier_transform_-_time_shifted_signal.gif',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '318'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Rectangular_function.svg/440px-Rectangular_function.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '319'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Sinc_function_%28normalized%29.svg/440px-Sinc_function_%28normalized%29.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '320'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Commutative_diagram_illustrating_problem_solving_via_the_Fourier_transform.svg/800px-Commutative_diagram_illustrating_problem_solving_via_the_Fourier_transform.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '321'
        },
        {
        title: 'Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'A Fourier transform (FT) is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial frequency or temporal frequency. An example application would be decomposing the waveform of a musical chord into terms of the intensity of its constituent pitches. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of space or time.',
        id: '322'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/440px-Normal_Distribution_PDF.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '323'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/440px-Normal_Distribution_CDF.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '324'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Nuvola_apps_atlantik.png/100px-Nuvola_apps_atlantik.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '325'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/700px-Standard_deviation_diagram.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '326'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/06/De_moivre-laplace.gif',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '327'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Dice_sum_central_limit_theorem.svg/500px-Dice_sum_central_limit_theorem.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '328'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Probabilities_of_functions_of_normal_vectors.png/440px-Probabilities_of_functions_of_normal_vectors.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '329'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/bb/QHarmonicOscillator.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '330'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/440px-Fisher_iris_versicolor_sepalwidth.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '331'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/FitNormDistr.tif/lossless-page1-440px-FitNormDistr.tif.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '332'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Planche_de_Galton.jpg/500px-Planche_de_Galton.jpg',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '333'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Carl_Friedrich_Gauss.jpg/360px-Carl_Friedrich_Gauss.jpg',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '334'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Pierre-Simon_Laplace.jpg/360px-Pierre-Simon_Laplace.jpg',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '335'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/NormalDistribution.png/440px-NormalDistribution.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '336'
        },
        {
        title: 'Normal distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function i',
        id: '337'
        },
        {
        title: 'Discrete Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ea/From_Continuous_To_Discrete_Fourier_Transform.gif',
        description: 'In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.',
        id: '338'
        },
        {
        title: 'Discrete Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Fourier_transform%2C_Fourier_series%2C_DTFT%2C_DFT.svg/800px-Fourier_transform%2C_Fourier_series%2C_DTFT%2C_DFT.svg.png',
        description: 'In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.',
        id: '339'
        },
        {
        title: 'Discrete Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Dft_visualization_rev2_n0008_trimmed_nobox.svg/600px-Dft_visualization_rev2_n0008_trimmed_nobox.svg.png',
        description: 'In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.',
        id: '340'
        },
        {
        title: 'Discrete Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/DirectAndFourierSpaceLocations.png/600px-DirectAndFourierSpaceLocations.png',
        description: 'In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.',
        id: '341'
        },
        {
        title: 'Fast Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/DIT-FFT-butterfly.png/440px-DIT-FFT-butterfly.png',
        description: 'A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. This operation is useful in many fields, but computing it directly from the definition is often too slow to be practical. An FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors. As a result, it manages to reduce the complexity of computing the DFT from is the data size. The difference in speed can be enormous, especially for long data sets where N may be in the thousands or millions. In the presence of round-off error, many FFT algorithms are much more accurate than evaluating the DFT definition directly or indirectly. There are many different FFT algorithms based on a wide range of published theories, from simple complex-number arithmetic to group theory and number theory',
        id: '342'
        },
        {
        title: 'Fast Fourier transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/FFT_of_Cosine_Summation_Function.svg/440px-FFT_of_Cosine_Summation_Function.svg.png',
        description: 'A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. This operation is useful in many fields, but computing it directly from the definition is often too slow to be practical. An FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors. As a result, it manages to reduce the complexity of computing the DFT from is the data size. The difference in speed can be enormous, especially for long data sets where N may be in the thousands or millions. In the presence of round-off error, many FFT algorithms are much more accurate than evaluating the DFT definition directly or indirectly. There are many different FFT algorithms based on a wide range of published theories, from simple complex-number arithmetic to group theory and number theory',
        id: '343'
        },
        {
        title: 'Sine wave ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'A sine wave, sinusoidal wave, or just sinusoid is a mathematical curve defined in terms of the sine trigonometric function, of which it is the graph. It is a type of continuous wave and also a smooth periodic function. It occurs often in mathematics, as well as in physics, engineering, signal processing and many other fields. ',
        id: '344'
        },
        {
        title: 'Sine wave ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Sine_and_Cosine.svg/800px-Sine_and_Cosine.svg.png',
        description: 'A sine wave, sinusoidal wave, or just sinusoid is a mathematical curve defined in terms of the sine trigonometric function, of which it is the graph. It is a type of continuous wave and also a smooth periodic function. It occurs often in mathematics, as well as in physics, engineering, signal processing and many other fields. ',
        id: '345'
        },
        {
        title: 'Sine wave ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/25/Animated-mass-spring.gif',
        description: 'A sine wave, sinusoidal wave, or just sinusoid is a mathematical curve defined in terms of the sine trigonometric function, of which it is the graph. It is a type of continuous wave and also a smooth periodic function. It occurs often in mathematics, as well as in physics, engineering, signal processing and many other fields. ',
        id: '346'
        },
        {
        title: 'Sine wave ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/ComplexSinInATimeAxe.gif/400px-ComplexSinInATimeAxe.gif',
        description: 'A sine wave, sinusoidal wave, or just sinusoid is a mathematical curve defined in terms of the sine trigonometric function, of which it is the graph. It is a type of continuous wave and also a smooth periodic function. It occurs often in mathematics, as well as in physics, engineering, signal processing and many other fields. ',
        id: '347'
        },
        {
        title: 'Sine wave ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Waveforms.svg/800px-Waveforms.svg.png',
        description: 'A sine wave, sinusoidal wave, or just sinusoid is a mathematical curve defined in terms of the sine trigonometric function, of which it is the graph. It is a type of continuous wave and also a smooth periodic function. It occurs often in mathematics, as well as in physics, engineering, signal processing and many other fields. ',
        id: '348'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '349'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/720px-Normal_Distribution_PDF.svg.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '350'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Gaussian_2d_surface.png/440px-Gaussian_2d_surface.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '351'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Gaussian_2d_0_degrees.png/400px-Gaussian_2d_0_degrees.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '352'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Gaussian_2d_30_degrees.png/400px-Gaussian_2d_30_degrees.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '353'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Gaussian_2d_60_degrees.png/400px-Gaussian_2d_60_degrees.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '354'
        },
        {
        title: 'Gaussian function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Discrete_Gaussian_kernel.svg/440px-Discrete_Gaussian_kernel.svg.png',
        description: 'In mathematics, a Gaussian function, often simply referred to as a Gaussian, is a function of the form for arbitrary real constants a, b and non-zero c. It is named after the mathematician Carl Friedrich Gauss. The graph of a Gaussian is a characteristic symmetric "bell curve" shape. The parameter a is the height of the curves peak, b is the position of the center of the peak, and c (the standard deviation, sometimes called the Gaussian RMS width) controls the width of the "bell".',
        id: '355'
        },
        {
        title: 'Digital signal processing ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations.  The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency. In digital electronics, a digital signal is represented as a pulse train, which is typically generated by the switching of a transistor.[3]',
        id: '356'
        },
        {
        title: 'Digital signal processing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e0/Jpeg2000_2-level_wavelet_transform-lichtenstein.png',
        description: 'Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations.  The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency. In digital electronics, a digital signal is represented as a pulse train, which is typically generated by the switching of a transistor.[3]',
        id: '357'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Comparison_convolution_correlation.svg/800px-Comparison_convolution_correlation.svg.png',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '358'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Convolution3.svg/799px-Convolution3.svg.png',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '359'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '360'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b9/Convolution_of_spiky_function_with_box2.gif',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '361'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d7/Halftone%2C_Gaussian_Blur.jpg',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '362'
        },
        {
        title: 'Convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function  that expresses how the shape of one is modified by the other.  The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.  The integral is evaluated for all values of shift, producing the convolution function.',
        id: '363'
        },
        {
        title: 'Impulse response ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Impulse.png/600px-Impulse.png',
        description: 'In signal processing, the impulse response, or impulse response function (IRF), of a dynamic system is its output when presented with a brief input signal, called an impulse. More generally, an impulse response is the reaction of any dynamic system in response to some external change. In both cases, the impulse response describes the reaction of the system as a function of time (or possibly as a function of some other independent variable that parameterizes the dynamic behavior of the system).',
        id: '364'
        },
        {
        title: 'Impulse response ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In signal processing, the impulse response, or impulse response function (IRF), of a dynamic system is its output when presented with a brief input signal, called an impulse. More generally, an impulse response is the reaction of any dynamic system in response to some external change. In both cases, the impulse response describes the reaction of the system as a function of time (or possibly as a function of some other independent variable that parameterizes the dynamic behavior of the system).',
        id: '365'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Extreme_points.svg/440px-Extreme_points.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '366'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/ConvexHull.svg/440px-ConvexHull.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '367'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/3D_Convex_Hull.tiff/lossless-page1-440px-3D_Convex_Hull.tiff.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '368'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Versiera007.svg/440px-Versiera007.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '369'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Convex_hull.png/340px-Convex_hull.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '370'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Convex_hull_of_a_simple_polygon.svg/340px-Convex_hull_of_a_simple_polygon.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '371'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Oloid_structure.svg/440px-Oloid_structure.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '372'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Orthogonal-convex-hull.svg/426px-Orthogonal-convex-hull.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '373'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Relative_convex_hull.svg/442px-Relative_convex_hull.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '374'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Tverberg_heptagon.svg/340px-Tverberg_heptagon.svg.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '375'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Bagplot.png/440px-Bagplot.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '376'
        },
        {
        title: 'Convex hull ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Mg%E2%80%93C_convex_hull.png/440px-Mg%E2%80%93C_convex_hull.png',
        description: 'In geometry, the convex hull or convex envelope or convex closure of a shape is the smallest convex set that contains it. The convex hull may be defined either as the intersection of all convex sets containing a given subset of a Euclidean space, or equivalently as the set of all convex combinations of points in the subset. For a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around the subset',
        id: '377'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/2d_random_walk_ag_adatom_ag111.gif/440px-2d_random_walk_ag_adatom_ag111.gif',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '378'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Brownianmotion5particles150frame.gif/220px-Brownianmotion5particles150frame.gif',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '379'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Brownian_motion_large.gif/220px-Brownian_motion_large.gif',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '380'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/PerrinPlot2.svg/440px-PerrinPlot2.svg.png',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '381'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Diffusion_of_Brownian_particles.svg/600px-Diffusion_of_Brownian_particles.svg.png',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '382'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Brownian_motion_gamboge.jpg/440px-Brownian_motion_gamboge.jpg',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '383'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Wiener_process_3d.png/440px-Wiener_process_3d.png',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '384'
        },
        {
        title: 'Brownian motion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4e/BMonSphere.jpg',
        description: 'Brownian motion, or pedesis (from Ancient Greek: πήδησις /pɛ̌ːdɛːsis/ "leaping"), is the random motion of particles suspended in a medium (a liquid or a gas).[2',
        id: '385'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Delaunay_circumcircles_vectorial.svg/560px-Delaunay_circumcircles_vectorial.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '386'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Delaunay_circumcircles_centers.svg/400px-Delaunay_circumcircles_centers.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '387'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Delaunay_Voronoi.svg/400px-Delaunay_Voronoi.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '388'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Example_steps_in_Delauney_triangularization.png/440px-Example_steps_in_Delauney_triangularization.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '389'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/82/Delaunay_triangulation_does_not_minimize_edge_length.gif',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '390'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Delaunay_geometry.png/201px-Delaunay_geometry.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '391'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Point_inside_circle_-_Delaunay_condition_broken.svg/240px-Point_inside_circle_-_Delaunay_condition_broken.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '392'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Edge_Flip_-_Delaunay_condition_ok.svg/240px-Edge_Flip_-_Delaunay_condition_ok.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '393'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Point_inside_circle_-_Delaunay_condition_broken_-_Labelled.svg/440px-Point_inside_circle_-_Delaunay_condition_broken_-_Labelled.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '394'
        },
        {
        title: 'Delaunay triangulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Delaunay_Triangulation_%28100_Points%29.svg/500px-Delaunay_Triangulation_%28100_Points%29.svg.png',
        description: 'In mathematics and computational geometry,  a Delaunay triangulation (also known as a Delone triangulation) for a given set P of discrete points in a general position is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). Delaunay triangulations maximize the minimum angle of all the angles of the triangles in the triangulation; they tend to avoid sliver triangles. The triangulation is named after Boris Delaunay for his work on this topic from 1934.',
        id: '395'
        },
        {
        title: 'Worley noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Worley.jpg/400px-Worley.jpg',
        description: 'Worley noise is a noise function introduced by Steven Worley in 1996. In computer graphics it is used to create procedural textures, i.e. textures that are created automatically with arbitrary precision and do not have to be drawn by hand. Worley noise comes close to simulating textures of stone, water, or biological cells.',
        id: '396'
        },
        {
        title: 'Worley noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Crystal_Clear_app_kscreensaver.svg/70px-Crystal_Clear_app_kscreensaver.svg.png',
        description: 'Worley noise is a noise function introduced by Steven Worley in 1996. In computer graphics it is used to create procedural textures, i.e. textures that are created automatically with arbitrary precision and do not have to be drawn by hand. Worley noise comes close to simulating textures of stone, water, or biological cells.',
        id: '397'
        },
        {
        title: 'Worley noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/LampFlowchart.svg/44px-LampFlowchart.svg.png',
        description: 'Worley noise is a noise function introduced by Steven Worley in 1996. In computer graphics it is used to create procedural textures, i.e. textures that are created automatically with arbitrary precision and do not have to be drawn by hand. Worley noise comes close to simulating textures of stone, water, or biological cells.',
        id: '398'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Mandel_zoom_00_mandelbrot_set.jpg/400px-Mandel_zoom_00_mandelbrot_set.jpg',
        description: '',
        id: '399'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a4/Mandelbrot_sequence_new.gif',
        description: '',
        id: '400'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Sierpinski_carpet_6.svg/400px-Sierpinski_carpet_6.svg.png',
        description: '',
        id: '401'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/LineSegment_selfSimilar_svg.svg/400px-LineSegment_selfSimilar_svg.svg.png',
        description: '',
        id: '402'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Simple_Fractals.png/400px-Simple_Fractals.png',
        description: '',
        id: '403'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/FractalTree.gif/440px-FractalTree.gif',
        description: '',
        id: '404'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/3D_Computer_Generated_Fractal.png/440px-3D_Computer_Generated_Fractal.png',
        description: '',
        id: '405'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Von_Koch_curve.gif/200px-Von_Koch_curve.gif',
        description: '',
        id: '406'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Cantor_set_in_seven_iterations.svg/440px-Cantor_set_in_seven_iterations.svg.png',
        description: '',
        id: '407'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Julia_set_%28indigo%29.png/400px-Julia_set_%28indigo%29.png',
        description: '',
        id: '408'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a9/Fractal_tree.gif',
        description: '',
        id: '409'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5e/Karperien_Strange_Attractor_200.gif',
        description: '',
        id: '410'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Uniform_Triangle_Mass_Center_grade_5_fractal.gif/400px-Uniform_Triangle_Mass_Center_grade_5_fractal.gif',
        description: '',
        id: '411'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/60_degrees_2x_recursive_IFS.jpg/400px-60_degrees_2x_recursive_IFS.jpg',
        description: '',
        id: '412'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b7/KarperienFractalBranch.jpg',
        description: '',
        id: '413'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Finite_subdivision_of_a_radial_link.png/400px-Finite_subdivision_of_a_radial_link.png',
        description: '',
        id: '414'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Frost_patterns_2.jpg/630px-Frost_patterns_2.jpg',
        description: '',
        id: '415'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Optical_Billiard_Spheres_dsweet.jpeg/560px-Optical_Billiard_Spheres_dsweet.jpeg',
        description: '',
        id: '416'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Glue1_800x600.jpg/560px-Glue1_800x600.jpg',
        description: '',
        id: '417'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Lichtenberg_figure_in_block_of_Plexiglas.jpg/463px-Lichtenberg_figure_in_block_of_Plexiglas.jpg',
        description: '',
        id: '418'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Romanesco_broccoli_%28Brassica_oleracea%29.jpg/525px-Romanesco_broccoli_%28Brassica_oleracea%29.jpg',
        description: '',
        id: '419'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Fractal_defrosting_patterns_on_Mars.jpg/503px-Fractal_defrosting_patterns_on_Mars.jpg',
        description: '',
        id: '420'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Brefeldia_maxima_plasmodium_on_wood.jpg/561px-Brefeldia_maxima_plasmodium_on_wood.jpg',
        description: '',
        id: '421'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Animated_fractal_mountain.gif/386px-Animated_fractal_mountain.gif',
        description: '',
        id: '422'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/FRACTAL-3d-FLOWER.jpg/560px-FRACTAL-3d-FLOWER.jpg',
        description: '',
        id: '423'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Fractal-BUTTERFLY.jpg/560px-Fractal-BUTTERFLY.jpg',
        description: '',
        id: '424'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Apophysis-100303-104.jpg/560px-Apophysis-100303-104.jpg',
        description: '',
        id: '425'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: '',
        id: '426'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/C%C3%B4ne_textileII.png/200px-C%C3%B4ne_textileII.png',
        description: '',
        id: '427'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Circle_map_poincare_recurrence.jpeg/200px-Circle_map_poincare_recurrence.jpeg',
        description: '',
        id: '428'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/FWF_Samuel_Monnier_%28vertical_detail%29.jpg/150px-FWF_Samuel_Monnier_%28vertical_detail%29.jpg',
        description: '',
        id: '429'
        },
        {
        title: 'Fractal ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Yemen_Chameleon_%28cropped%29.jpg/160px-Yemen_Chameleon_%28cropped%29.jpg',
        description: '',
        id: '430'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '431'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Dragon_trees.jpg/660px-Dragon_trees.jpg',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '432'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Fractal_weeds.jpg/660px-Fractal_weeds.jpg',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '433'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0c/Graftal0.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '434'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d9/Graftal1.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '435'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/81/Graftal2.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '436'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/da/Graftal3.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '437'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/31/Graftal4.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '438'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5d/Graftal7.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '439'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Cantor_set_in_seven_iterations.svg/900px-Cantor_set_in_seven_iterations.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '440'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Square_koch.svg/40px-Square_koch.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '441'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Square_koch_1.svg/80px-Square_koch_1.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '442'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Square_koch_2.svg/200px-Square_koch_2.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '443'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Square_koch_3.svg/560px-Square_koch_3.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '444'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c4/Sierpinski_Triangle_%28from_L-System%2C_2_iterations%29.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '445'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/06/Sierpinski_Triangle_%28from_L-System%2C_4_iterations%29.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '446'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/3f/Sierpinski_Triangle_%28from_L-System%2C_6_iterations%29.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '447'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Serpinski_Lsystem.svg/972px-Serpinski_Lsystem.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '448'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Dragon_curve_L-system.svg/800px-Dragon_curve_L-system.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '449'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Fractal-plant.svg/906px-Fractal-plant.svg.png',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '450'
        },
        {
        title: 'L-system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4b/Fractal_Farn.gif',
        description: 'An L-system or Lindenmayer system is a parallel rewriting system and a type of formal grammar. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules that expand each symbol into some larger string of symbols, an initial "axiom" string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems were introduced and developed in 1968 by Aristid Lindenmayer, a Hungarian theoretical biologist and botanist at the University of Utrecht. Lindenmayer used L-systems to describe the behaviour of plant cells and to model the growth processes of plant development. L-systems have also been used to model the morphology of a variety of organisms and can be used to generate self-similar fractals.',
        id: '451'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Euclidean_Voronoi_diagram.svg/440px-Euclidean_Voronoi_diagram.svg.png',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '452'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Euclidean_Voronoi_diagram.svg/764px-Euclidean_Voronoi_diagram.svg.png',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '453'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Manhattan_Voronoi_Diagram.svg/764px-Manhattan_Voronoi_Diagram.svg.png',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '454'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Coloured_Voronoi_3D_slice.svg/440px-Coloured_Voronoi_3D_slice.svg.png',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '455'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Approximate_Voronoi_Diagram.svg/440px-Approximate_Voronoi_Diagram.svg.png',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '456'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Voronoi_growth_euclidean.gif/440px-Voronoi_growth_euclidean.gif',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '457'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Marble_floor_mosaic_Basilica_of_St_Mark_Vencice.jpg/180px-Marble_floor_mosaic_Basilica_of_St_Mark_Vencice.jpg',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '458'
        },
        {
        title: 'Voronoi diagram ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/2C_3_1979.JPG/180px-2C_3_1979.JPG',
        description: 'In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. The Voronoi diagram of a set of points is dual to its Delaunay triangulation.',
        id: '459'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/da/Perlin_noise.jpg',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '460'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Fractal_terrain_texture.jpg/440px-Fractal_terrain_texture.jpg',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '461'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Pink_red_liquid_using_perlin_noise_%2B_bump_%2B_coloring_%282415197699%29.png/440px-Pink_red_liquid_using_perlin_noise_%2B_bump_%2B_coloring_%282415197699%29.png',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '462'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/2D_sample_of_Perlin_noise.png/256px-2D_sample_of_Perlin_noise.png',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '463'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/PerlinNoiseGradientGrid.png/512px-PerlinNoiseGradientGrid.png',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '464'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/PerlinNoiseDotProducts.png/512px-PerlinNoiseDotProducts.png',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '465'
        },
        {
        title: 'Perlin noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/PerlinNoiseInterpolated.png/512px-PerlinNoiseInterpolated.png',
        description: 'Perlin noise is a type of gradient noise developed by Ken Perlin.  ',
        id: '466'
        },
        {
        title: 'Isotropy ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/LvMS-Lvv.jpg/440px-LvMS-Lvv.jpg',
        description: 'Isotropy is uniformity in all orientations; it is derived from the Greek isos (ἴσος, "equal") and tropos (τρόπος, "way"). Precise definitions depend on the subject area.  Exceptions, or inequalities, are frequently indicated by the prefix an, hence anisotropy. Anisotropy is also used to describe situations where properties vary systematically, dependent on direction. Isotropic radiation has the same intensity regardless of the direction of measurement, and an isotropic field exerts the same action regardless of how the test particle is oriented.',
        id: '467'
        },
        {
        title: 'Z-buffering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Z_buffer.svg/440px-Z_buffer.svg.png',
        description: 'A depth buffer, also known as a z-buffer, is a type of data buffer used in computer graphics to represent depth information of objects in 3D space from a particular perspective. Depth buffers are an aid to rendering a scene to ensure that the correct polygons properly occlude other polygons. Z-buffering was first described in 1974 by Wolfgang Straßer in his PhD thesis on fast algorithms for rendering occluded objects. A similar solution to determining overlapping polygons is the painters algorithm, which is capable of handling non-opaque scene elements, though at the cost of efficiency and incorrect results.',
        id: '468'
        },
        {
        title: 'Z-buffering ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'A depth buffer, also known as a z-buffer, is a type of data buffer used in computer graphics to represent depth information of objects in 3D space from a particular perspective. Depth buffers are an aid to rendering a scene to ensure that the correct polygons properly occlude other polygons. Z-buffering was first described in 1974 by Wolfgang Straßer in his PhD thesis on fast algorithms for rendering occluded objects. A similar solution to determining overlapping polygons is the painters algorithm, which is capable of handling non-opaque scene elements, though at the cost of efficiency and incorrect results.',
        id: '469'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Broadway_tower_edit.jpg/548px-Broadway_tower_edit.jpg',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '470'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Broadway_tower_edit_scale.png/372px-Broadway_tower_edit_scale.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '471'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Broadway_tower_edit_cropped.png/372px-Broadway_tower_edit_cropped.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '472'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Broadway_tower_edit_Seam_Carving.png/372px-Broadway_tower_edit_Seam_Carving.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '473'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e2/BroadwayTowerSeamCarvingA.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '474'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/53/BroadwayTowerSeamCarvingB.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '475'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/97/BroadwayTowerSeamCarvingC.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '476'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a6/BroadwayTowerSeamCarvingF.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '477'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/33/BroadwayTowerSeamCarvingE.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '478'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/DynamicProgrammingLeastEnergyPathA.svg/840px-DynamicProgrammingLeastEnergyPathA.svg.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '479'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/DynamicProgrammingLeastEnergyPathB.svg/840px-DynamicProgrammingLeastEnergyPathB.svg.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '480'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/DynamicProgrammingLeastEnergyPathC.svg/840px-DynamicProgrammingLeastEnergyPathC.svg.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '481'
        },
        {
        title: 'Seam carving ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Mitsubishi_logo.svg/100px-Mitsubishi_logo.svg.png',
        description: 'Seam carving (or liquid rescaling) is an algorithm for content-aware image resizing, developed by Shai Avidan, of Mitsubishi Electric Research Laboratories (MERL), and Ariel Shamir, of the Interdisciplinary Center and MERL. It functions by establishing a number of seams (paths of least importance) in an image and automatically removes seams to reduce image size or inserts seams to extend it. Seam carving also allows manually defining areas in which pixels may not be modified, and features the ability to remove whole objects from photographs.',
        id: '482'
        },
        {
        title: 'OpenCV ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage then Itseez (which was later acquired by Intel). The library is cross-platform and free for use under the open-source Apache 2 License. Starting with 2011, OpenCV features GPU acceleration for real-time operations.[3]',
        id: '483'
        },
        {
        title: 'OpenCV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/OpenCV_Logo_with_text_svg_version.svg/360px-OpenCV_Logo_with_text_svg_version.svg.png',
        description: 'OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage then Itseez (which was later acquired by Intel). The library is cross-platform and free for use under the open-source Apache 2 License. Starting with 2011, OpenCV features GPU acceleration for real-time operations.[3]',
        id: '484'
        },
        {
        title: 'OpenCV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/OfxOpenCV.png/440px-OfxOpenCV.png',
        description: 'OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage then Itseez (which was later acquired by Intel). The library is cross-platform and free for use under the open-source Apache 2 License. Starting with 2011, OpenCV features GPU acceleration for real-time operations.[3]',
        id: '485'
        },
        {
        title: 'sRGB ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/SRGB_chromaticity_CIE1931.svg/440px-SRGB_chromaticity_CIE1931.svg.png',
        description: 'sRGB is a standard RGB (red, green, blue) color space that HP and Microsoft created cooperatively in 1996 to use on monitors, printers, and the World Wide Web. It was subsequently standardized by the International Electrotechnical Commission (IEC) as IEC 61966-2-1:1999. sRGB is the current defined standard colorspace for the web, and it is usually the assumed colorspace for images that are neither tagged for a colorspace nor have an embedded color profile.',
        id: '486'
        },
        {
        title: 'sRGB ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/SRGB_gamma.svg/440px-SRGB_gamma.svg.png',
        description: 'sRGB is a standard RGB (red, green, blue) color space that HP and Microsoft created cooperatively in 1996 to use on monitors, printers, and the World Wide Web. It was subsequently standardized by the International Electrotechnical Commission (IEC) as IEC 61966-2-1:1999. sRGB is the current defined standard colorspace for the web, and it is usually the assumed colorspace for images that are neither tagged for a colorspace nor have an embedded color profile.',
        id: '487'
        },
        {
        title: 'sRGB ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c9/Srgbnonlinearity.png',
        description: 'sRGB is a standard RGB (red, green, blue) color space that HP and Microsoft created cooperatively in 1996 to use on monitors, printers, and the World Wide Web. It was subsequently standardized by the International Electrotechnical Commission (IEC) as IEC 61966-2-1:1999. sRGB is the current defined standard colorspace for the web, and it is usually the assumed colorspace for images that are neither tagged for a colorspace nor have an embedded color profile.',
        id: '488'
        },
        {
        title: 'sRGB ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Cie_Chart_with_sRGB_gamut_by_spigget.png/440px-Cie_Chart_with_sRGB_gamut_by_spigget.png',
        description: 'sRGB is a standard RGB (red, green, blue) color space that HP and Microsoft created cooperatively in 1996 to use on monitors, printers, and the World Wide Web. It was subsequently standardized by the International Electrotechnical Commission (IEC) as IEC 61966-2-1:1999. sRGB is the current defined standard colorspace for the web, and it is usually the assumed colorspace for images that are neither tagged for a colorspace nor have an embedded color profile.',
        id: '489'
        },
        {
        title: 'sRGB ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/CIE1931xy_gamut_comparison.svg/520px-CIE1931xy_gamut_comparison.svg.png',
        description: 'sRGB is a standard RGB (red, green, blue) color space that HP and Microsoft created cooperatively in 1996 to use on monitors, printers, and the World Wide Web. It was subsequently standardized by the International Electrotechnical Commission (IEC) as IEC 61966-2-1:1999. sRGB is the current defined standard colorspace for the web, and it is usually the assumed colorspace for images that are neither tagged for a colorspace nor have an embedded color profile.',
        id: '490'
        },
        {
        title: 'Mipmap ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer graphics, mipmaps (also MIP maps) or pyramids[3] are pre-calculated, optimized sequences of images, each of which is a progressively lower resolution representation of the previous. The height and width of each image, or level, in the mipmap is a factor of two smaller than the previous level. Mipmaps do not have to be square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera; lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering, and 2D and 3D GIS software. Their use is known as mipmapping. The letters MIP in the name are an acronym of the Latin phrase multum in parvo, meaning "much in little".[4]',
        id: '491'
        },
        {
        title: 'Mipmap ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Mipmap_Aliasing_Comparison.png/880px-Mipmap_Aliasing_Comparison.png',
        description: 'In computer graphics, mipmaps (also MIP maps) or pyramids[3] are pre-calculated, optimized sequences of images, each of which is a progressively lower resolution representation of the previous. The height and width of each image, or level, in the mipmap is a factor of two smaller than the previous level. Mipmaps do not have to be square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera; lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering, and 2D and 3D GIS software. Their use is known as mipmapping. The letters MIP in the name are an acronym of the Latin phrase multum in parvo, meaning "much in little".[4]',
        id: '492'
        },
        {
        title: 'Mipmap ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5c/MipMap_Example_STS101.jpg',
        description: 'In computer graphics, mipmaps (also MIP maps) or pyramids[3] are pre-calculated, optimized sequences of images, each of which is a progressively lower resolution representation of the previous. The height and width of each image, or level, in the mipmap is a factor of two smaller than the previous level. Mipmaps do not have to be square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera; lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering, and 2D and 3D GIS software. Their use is known as mipmapping. The letters MIP in the name are an acronym of the Latin phrase multum in parvo, meaning "much in little".[4]',
        id: '493'
        },
        {
        title: 'Mipmap ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ed/Mipmap_illustration2.png',
        description: 'In computer graphics, mipmaps (also MIP maps) or pyramids[3] are pre-calculated, optimized sequences of images, each of which is a progressively lower resolution representation of the previous. The height and width of each image, or level, in the mipmap is a factor of two smaller than the previous level. Mipmaps do not have to be square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera; lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering, and 2D and 3D GIS software. Their use is known as mipmapping. The letters MIP in the name are an acronym of the Latin phrase multum in parvo, meaning "much in little".[4]',
        id: '494'
        },
        {
        title: 'Mipmap ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/7f/Mipmap_illustration1.png',
        description: 'In computer graphics, mipmaps (also MIP maps) or pyramids[3] are pre-calculated, optimized sequences of images, each of which is a progressively lower resolution representation of the previous. The height and width of each image, or level, in the mipmap is a factor of two smaller than the previous level. Mipmaps do not have to be square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera; lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering, and 2D and 3D GIS software. Their use is known as mipmapping. The letters MIP in the name are an acronym of the Latin phrase multum in parvo, meaning "much in little".[4]',
        id: '495'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '496'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Texturedm1a2.png/440px-Texturedm1a2.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '497'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Texture_mapping_demonstration_animation.gif/220px-Texture_mapping_demonstration_animation.gif',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '498'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Bumpandopacity.png/560px-Bumpandopacity.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '499'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Perspective_correct_texture_mapping.svg/800px-Perspective_correct_texture_mapping.svg.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '500'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Freedoom_2018.png/600px-Freedoom_2018.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '501'
        },
        {
        title: 'Texture mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Texturemapping_subdivision.svg/400px-Texturemapping_subdivision.svg.png',
        description: 'Texture mapping[3] is a method for defining high frequency detail, surface texture, or color information on a computer-generated graphic or 3D model. The original technique was pioneered by Edwin Catmull in 1974.[4]',
        id: '502'
        },
        {
        title: 'Bump mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0a/Bump-map-demo-full.png',
        description: 'Bump mapping is a texture mapping technique in computer graphics for simulating bumps and wrinkles on the surface of an object. This is achieved by perturbing the surface normals of the object and using the perturbed normal during lighting calculations. The result is an apparently bumpy surface rather than a smooth surface although the surface of the underlying object is not changed. Bump mapping was introduced by James Blinn in 1978.',
        id: '503'
        },
        {
        title: 'Bump mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Bump_map_vs_isosurface2.png/800px-Bump_map_vs_isosurface2.png',
        description: 'Bump mapping is a texture mapping technique in computer graphics for simulating bumps and wrinkles on the surface of an object. This is achieved by perturbing the surface normals of the object and using the perturbed normal during lighting calculations. The result is an apparently bumpy surface rather than a smooth surface although the surface of the underlying object is not changed. Bump mapping was introduced by James Blinn in 1978.',
        id: '504'
        },
        {
        title: 'Bump mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/FakeBump2D-animation.gif/800px-FakeBump2D-animation.gif',
        description: 'Bump mapping is a texture mapping technique in computer graphics for simulating bumps and wrinkles on the surface of an object. This is achieved by perturbing the surface normals of the object and using the perturbed normal during lighting calculations. The result is an apparently bumpy surface rather than a smooth surface although the surface of the underlying object is not changed. Bump mapping was introduced by James Blinn in 1978.',
        id: '505'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9a/%E0%B9%80%E0%B8%9B%E0%B8%A3%E0%B8%B5%E0%B8%A2%E0%B8%9A%E0%B9%80%E0%B8%97%E0%B8%B5%E0%B8%A2%E0%B8%9A%E0%B9%82%E0%B8%A1%E0%B9%80%E0%B8%94%E0%B8%A5%E0%B8%97%E0%B8%B5%E0%B9%88%E0%B9%83%E0%B8%8A%E0%B9%89_normal_map.png',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '506'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/NormalMaps.png/400px-NormalMaps.png',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '507'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Image_Tangent-plane.svg/440px-Image_Tangent-plane.svg.png',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '508'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '509'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e4/Rendering_with_normal_mapping.gif',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '510'
        },
        {
        title: 'Normal mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Normal_map_example_with_scene_and_result.png/800px-Normal_map_example_with_scene_and_result.png',
        description: 'In 3D computer graphics, normal mapping, or Dot3 bump mapping, is a texture mapping technique used for faking the lighting of bumps and dents – an implementation of bump mapping. It is used to add details without using more polygons. A common use of this technique is to greatly enhance the appearance and details of a low polygon model by generating a normal map from a high polygon model or height map.',
        id: '511'
        },
        {
        title: 'Bilinear interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Bilininterp.png/440px-Bilininterp.png',
        description: 'In mathematics, bilinear interpolation is a method for interpolating functions of two variables (e.g., x and y) using repeated linear interpolation. It is usually applied to functions sampled on a 2D rectilinear grid, though it can be generalized to functions defined on the vertices of (a mesh of) arbitrary convex quadrilaterals.',
        id: '512'
        },
        {
        title: 'Bilinear interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/BilinearInterpolation.svg/440px-BilinearInterpolation.svg.png',
        description: 'In mathematics, bilinear interpolation is a method for interpolating functions of two variables (e.g., x and y) using repeated linear interpolation. It is usually applied to functions sampled on a 2D rectilinear grid, though it can be generalized to functions defined on the vertices of (a mesh of) arbitrary convex quadrilaterals.',
        id: '513'
        },
        {
        title: 'Bilinear interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Bilinear_interpolation_visualisation.svg/340px-Bilinear_interpolation_visualisation.svg.png',
        description: 'In mathematics, bilinear interpolation is a method for interpolating functions of two variables (e.g., x and y) using repeated linear interpolation. It is usually applied to functions sampled on a 2D rectilinear grid, though it can be generalized to functions defined on the vertices of (a mesh of) arbitrary convex quadrilaterals.',
        id: '514'
        },
        {
        title: 'Bilinear interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Comparison_of_1D_and_2D_interpolation.svg/500px-Comparison_of_1D_and_2D_interpolation.svg.png',
        description: 'In mathematics, bilinear interpolation is a method for interpolating functions of two variables (e.g., x and y) using repeated linear interpolation. It is usually applied to functions sampled on a 2D rectilinear grid, though it can be generalized to functions defined on the vertices of (a mesh of) arbitrary convex quadrilaterals.',
        id: '515'
        },
        {
        title: 'Bilinear interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Bilin3.png/220px-Bilin3.png',
        description: 'In mathematics, bilinear interpolation is a method for interpolating functions of two variables (e.g., x and y) using repeated linear interpolation. It is usually applied to functions sampled on a 2D rectilinear grid, though it can be generalized to functions defined on the vertices of (a mesh of) arbitrary convex quadrilaterals.',
        id: '516'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '517'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Piecewise_constant.svg/440px-Piecewise_constant.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '518'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Interpolation-nearest.svg/440px-Interpolation-nearest.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '519'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Comparison_of_1D_and_2D_interpolation.svg/440px-Comparison_of_1D_and_2D_interpolation.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '520'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Coloured_Voronoi_2D.svg/440px-Coloured_Voronoi_2D.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '521'
        },
        {
        title: 'Nearest-neighbor interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Arithmetic_symbols.svg/42px-Arithmetic_symbols.svg.png',
        description: 'Nearest-neighbor interpolation (also known as proximal interpolation or, in some contexts, point sampling) is a simple method of multivariate interpolation in one or more dimensions.',
        id: '522'
        },
        {
        title: 'Point cloud ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Point_cloud_torus.gif/220px-Point_cloud_torus.gif',
        description: 'A point cloud is a set of data points in space. The points may represent a 3D shape or object. Each point position has its set of Cartesian coordinates (X, Y, Z). Point clouds are generally produced by 3D scanners or by photogrammetry software, which measure many points on the external surfaces of objects around them. As the output of 3D scanning processes, point clouds are used for many purposes, including to create 3D CAD models for manufactured parts, for metrology and quality inspection, and for a multitude of visualization, animation, rendering and mass customization applications.',
        id: '523'
        },
        {
        title: 'Point cloud ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Geo-Referenced_Point_Cloud.JPG/440px-Geo-Referenced_Point_Cloud.JPG',
        description: 'A point cloud is a set of data points in space. The points may represent a 3D shape or object. Each point position has its set of Cartesian coordinates (X, Y, Z). Point clouds are generally produced by 3D scanners or by photogrammetry software, which measure many points on the external surfaces of objects around them. As the output of 3D scanning processes, point clouds are used for many purposes, including to create 3D CAD models for manufactured parts, for metrology and quality inspection, and for a multitude of visualization, animation, rendering and mass customization applications.',
        id: '524'
        },
        {
        title: 'Point cloud ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Extract_Video_Beit_Ghazaleh_Orthophoto_Survey_AG%26P_2017.gif/440px-Extract_Video_Beit_Ghazaleh_Orthophoto_Survey_AG%26P_2017.gif',
        description: 'A point cloud is a set of data points in space. The points may represent a 3D shape or object. Each point position has its set of Cartesian coordinates (X, Y, Z). Point clouds are generally produced by 3D scanners or by photogrammetry software, which measure many points on the external surfaces of objects around them. As the output of 3D scanning processes, point clouds are used for many purposes, including to create 3D CAD models for manufactured parts, for metrology and quality inspection, and for a multitude of visualization, animation, rendering and mass customization applications.',
        id: '525'
        },
        {
        title: 'Point cloud ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png/440px-Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png',
        description: 'A point cloud is a set of data points in space. The points may represent a 3D shape or object. Each point position has its set of Cartesian coordinates (X, Y, Z). Point clouds are generally produced by 3D scanners or by photogrammetry software, which measure many points on the external surfaces of objects around them. As the output of 3D scanning processes, point clouds are used for many purposes, including to create 3D CAD models for manufactured parts, for metrology and quality inspection, and for a multitude of visualization, animation, rendering and mass customization applications.',
        id: '526'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Three_Arch_Bay_Photo_Taken_by_pilot_D_Ramey_Logan.jpg/580px-Three_Arch_Bay_Photo_Taken_by_pilot_D_Ramey_Logan.jpg',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '527'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Photogrammetry_Wiora_EN.svg/600px-Photogrammetry_Wiora_EN.svg.png',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '528'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Tuure_Lepp%C3%A4nen%2C_Reconstruction_I.png/440px-Tuure_Lepp%C3%A4nen%2C_Reconstruction_I.png',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '529'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Future-cities-best-76.jpg/440px-Future-cities-best-76.jpg',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '530'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/1/1a/Jiska-Photomapping-Drawing.jpg/440px-Jiska-Photomapping-Drawing.jpg',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '531'
        },
        {
        title: 'Photogrammetry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Pteryx_UAV_-_wiki.jpg/340px-Pteryx_UAV_-_wiki.jpg',
        description: 'Photogrammetry is the science and technology of obtaining reliable information about physical objects and the environment through the process of recording, measuring and interpreting photographic images and patterns of electromagnetic radiant imagery and other phenomena.',
        id: '532'
        },
        {
        title: 'Wavelet transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e0/Jpeg2000_2-level_wavelet_transform-lichtenstein.png',
        description: 'In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[3][4][5]',
        id: '533'
        },
        {
        title: 'Wavelet transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Basis_function_with_compression_factor.jpg/430px-Basis_function_with_compression_factor.jpg',
        description: 'In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[3][4][5]',
        id: '534'
        },
        {
        title: 'Wavelet transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/STFT_and_WT.jpg/500px-STFT_and_WT.jpg',
        description: 'In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[3][4][5]',
        id: '535'
        },
        {
        title: 'Wavelet transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Analysis_of_three_superposed_sinusoidal_signals.jpg/500px-Analysis_of_three_superposed_sinusoidal_signals.jpg',
        description: 'In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[3][4][5]',
        id: '536'
        },
        {
        title: 'Wavelet transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/2f/Typical_wavelet_transform_diagram.png',
        description: 'In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[3][4][5]',
        id: '537'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Moir%C3%A9_pattern.svg/302px-Moir%C3%A9_pattern.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '538'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Divers_-_Illustrated_London_News_Feb_6_1873-2.PNG/306px-Divers_-_Illustrated_London_News_Feb_6_1873-2.PNG',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '539'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Moire-bridge-picket-fence.jpg/440px-Moire-bridge-picket-fence.jpg',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '540'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/03/Moir%C3%A9_pattern.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '541'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/070309-moire-a5-a5-upward-movement.gif/220px-070309-moire-a5-a5-upward-movement.gif',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '542'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/070320-a6-shape-moire-pr-gt-pb.gif/440px-070320-a6-shape-moire-pr-gt-pb.gif',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '543'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Moire.gif/440px-Moire.gif',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '544'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '545'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Moire_parallel.svg/222px-Moire_parallel.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '546'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Moire_ecart_angulaire.png/386px-Moire_ecart_angulaire.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '547'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Moir%C3%A9_grid.svg/340px-Moir%C3%A9_grid.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '548'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/27/Moire_calcul_angle.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '549'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Moire02.gif/148px-Moire02.gif',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '550'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Moire_Circles.svg/248px-Moire_Circles.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '551'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Moire_Lines.svg/188px-Moire_Lines.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '552'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Moire_Lines_and_Circles.svg/164px-Moire_Lines_and_Circles.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '553'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Moire_on_parrot_feathers.jpg/304px-Moire_on_parrot_feathers.jpg',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '554'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Moir%C3%A9_fringes_IMG_3712.jpg/304px-Moir%C3%A9_fringes_IMG_3712.jpg',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '555'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4d/Moire_extensometrie.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '556'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Graphene_moire_on_Ir%28111%29_-_schematic.svg/424px-Graphene_moire_on_Ir%28111%29_-_schematic.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '557'
        },
        {
        title: 'Moiré pattern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Moire_of_twisted_bilayer_graphene.svg/424px-Moire_of_twisted_bilayer_graphene.svg.png',
        description: 'In mathematics, physics, and art, moiré patterns (UK: /ˈmwɑːreɪ/ MWAR-ay, US: /mwɑːˈreɪ/ mwar-AY, French: [mwaʁe] (listen)) or moiré fringes are large-scale interference patterns that can be produced when an opaque ruled pattern with transparent gaps is overlaid on another similar pattern. For the moiré interference pattern to appear, the two patterns must not be completely identical, but rather displaced, rotated, or have slightly different pitch.',
        id: '558'
        },
        {
        title: 'Gamma correction ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/GammaCorrection_demo.jpg/440px-GammaCorrection_demo.jpg',
        description: 'Gamma correction or gamma is a nonlinear operation used to encode and decode luminance or tristimulus values in video or still image systems. Gamma correction is, in the simplest cases, defined by the following power-law expression:',
        id: '559'
        },
        {
        title: 'Gamma correction ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Foto-wiki-Characteristic-Curve.svg/440px-Foto-wiki-Characteristic-Curve.svg.png',
        description: 'Gamma correction or gamma is a nonlinear operation used to encode and decode luminance or tristimulus values in video or still image systems. Gamma correction is, in the simplest cases, defined by the following power-law expression:',
        id: '560'
        },
        {
        title: 'Gamma correction ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/SRGB_gamma.svg/454px-SRGB_gamma.svg.png',
        description: 'Gamma correction or gamma is a nonlinear operation used to encode and decode luminance or tristimulus values in video or still image systems. Gamma correction is, in the simplest cases, defined by the following power-law expression:',
        id: '561'
        },
        {
        title: 'Gamma correction ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e5/Gamma_correction_test_picture.png',
        description: 'Gamma correction or gamma is a nonlinear operation used to encode and decode luminance or tristimulus values in video or still image systems. Gamma correction is, in the simplest cases, defined by the following power-law expression:',
        id: '562'
        },
        {
        title: 'Saliency map ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Saliencymap_example.jpg/952px-Saliencymap_example.jpg',
        description: 'In computer vision, a saliency map is an image that highlights the region on which peoples eyes focus first. The goal of a saliency map is to reflect the degree of importance of a pixel to the human visual system. For example, in this image, a person first looks at the fort and light clouds, so they should be highlighted on the saliency map.  Saliency maps engineered in artificial or computer vision are typically not the same as the actual saliency map constructed by biological or natural vision.',
        id: '563'
        },
        {
        title: 'Saliency map ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Wiki102.png/440px-Wiki102.png',
        description: 'In computer vision, a saliency map is an image that highlights the region on which peoples eyes focus first. The goal of a saliency map is to reflect the degree of importance of a pixel to the human visual system. For example, in this image, a person first looks at the fort and light clouds, so they should be highlighted on the saliency map.  Saliency maps engineered in artificial or computer vision are typically not the same as the actual saliency map constructed by biological or natural vision.',
        id: '564'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d3/LangtonsAnt.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '565'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/09/LangtonsAntAnimated.gif',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '566'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/LangtonsAnt-nColor_RLR_13937.png/240px-LangtonsAnt-nColor_RLR_13937.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '567'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/LangtonsAnt-nColor_LLRR_123157.png/240px-LangtonsAnt-nColor_LLRR_123157.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '568'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/LangtonsAnt-nColor_LRRRRRLLR_70273.png/240px-LangtonsAnt-nColor_LRRRRRLLR_70273.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '569'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/LangtonsAnt-nColor_LLRRRLRLRLLR_36437.png/240px-LangtonsAnt-nColor_LLRRRLRLRLLR_36437.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '570'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/LangtonsAnt-nColor_RRLLLRLLLRRR_32734.png/240px-LangtonsAnt-nColor_RRLLLRLLLRRR_32734.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '571'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/CA3061-81k7.png/240px-CA3061-81k7.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '572'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/CA174906.png/240px-CA174906.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '573'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/CA50338_animation.gif/229px-CA50338_animation.gif',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '574'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/2e/Turmite-111180121010-12536.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '575'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0c/Turmite-120121010011-8342.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '576'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4b/Turmite-121021110111-27731.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '577'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d2/Turmite-121181121020-65932.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '578'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/aa/Turmite-180121020081-223577.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '579'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9b/Turmite-181181121010-10211.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '580'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d5/Turmite_creating_a_growing_diamond.png',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '581'
        },
        {
        title: 'Langtons ant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/82/Langton%27s_Ant_colony.gif',
        description: 'Langtons ant is a two-dimensional universal Turing machine with a very simple set of rules but complex emergent behavior. It was invented by Chris Langton in 1986 and runs on a square lattice of black and white cells. The universality of Langtons ant was proven in 2000. The idea has been generalized in several different ways, such as turmites which add more colors and more states',
        id: '582'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e5/Gospers_glider_gun.gif',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '583'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/CA-Moore.svg/400px-CA-Moore.svg.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '584'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/CA-von-Neumann.svg/400px-CA-von-Neumann.svg.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '585'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Torus.png/440px-Torus.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '586'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/John_von_Neumann_ID_badge.png/340px-John_von_Neumann_ID_badge.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '587'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/86/Oscillator.gif',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '588'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/One-d-cellular-automate-rule-30.gif/440px-One-d-cellular-automate-rule-30.gif',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '589'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/CA_rule30s.png/440px-CA_rule30s.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '590'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/CA_rule110s.png/440px-CA_rule110s.png',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '591'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Textile_cone.JPG/440px-Textile_cone.JPG',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '592'
        },
        {
        title: 'Cellular automaton ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4d/Gas_velocity.gif',
        description: 'A cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model of computation studied in automata theory. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays. Cellular automata have found application in various areas, including physics, theoretical biology and microstructure modeling',
        id: '593'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Gibbs_phenomenon_10.svg/440px-Gibbs_phenomenon_10.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '594'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Gibbs_phenomenon_50.svg/440px-Gibbs_phenomenon_50.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '595'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Gibbs_phenomenon_250.svg/440px-Gibbs_phenomenon_250.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '596'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Sinc_function_%28both%29.svg/440px-Sinc_function_%28both%29.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '597'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Sine_integral.svg/440px-Sine_integral.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '598'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Gibbs_phenomenon_10.svg/570px-Gibbs_phenomenon_10.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '599'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Gibbs_phenomenon_50.svg/570px-Gibbs_phenomenon_50.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '600'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/SquareWave.gif/900px-SquareWave.gif',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '601'
        },
        {
        title: 'Gibbs phenomenon ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The functions lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the functions actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.[3]',
        id: '602'
        },
        {
        title: 'Medial axis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Ellipse_symmetry_set.svg/500px-Ellipse_symmetry_set.svg.png',
        description: 'The medial axis of an object is the set of all points having more than one closest point on the objects boundary.  Originally referred to as the topological skeleton, it was introduced in 1967 by Harry Blum as a tool for biological shape recognition. In mathematics the closure of the medial axis is known as the cut locus.',
        id: '603'
        },
        {
        title: 'Medial axis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/MedialAxisTransformOf3dObject.png/170px-MedialAxisTransformOf3dObject.png',
        description: 'The medial axis of an object is the set of all points having more than one closest point on the objects boundary.  Originally referred to as the topological skeleton, it was introduced in 1967 by Harry Blum as a tool for biological shape recognition. In mathematics the closure of the medial axis is known as the cut locus.',
        id: '604'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Schlegel_wireframe_8-cell.png/480px-Schlegel_wireframe_8-cell.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '605'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Hexahedron.png/40px-Hexahedron.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '606'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/8-cell_verf.png/160px-8-cell_verf.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '607'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/8-cell_net.png/440px-8-cell_net.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '608'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ef/Net_of_tesseract.gif',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '609'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/From_Point_to_Tesseract_%28Looped_Version%29.gif/220px-From_Point_to_Tesseract_%28Looped_Version%29.gif',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '610'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Dimension_levels.svg/960px-Dimension_levels.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '611'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Tesseract_graph_nonplanar_visual_proof.svg/300px-Tesseract_graph_nonplanar_visual_proof.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '612'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Orthogonal_projection_envelopes_tesseract.png/440px-Orthogonal_projection_envelopes_tesseract.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '613'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Hypercubeorder_binary.svg/440px-Hypercubeorder_binary.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '614'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Orthogonal_Tesseract_Gif.gif/440px-Orthogonal_Tesseract_Gif.gif',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '615'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/4-cube_t0.svg/300px-4-cube_t0.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '616'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/4-cube_t0_B3.svg/300px-4-cube_t0_B3.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '617'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/4-cube_t0_B2.svg/300px-4-cube_t0_B2.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '618'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/4-cube_column_graph.svg/300px-4-cube_column_graph.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '619'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/4-cube_t0_F4.svg/300px-4-cube_t0_F4.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '620'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/4-cube_t0_A3.svg/300px-4-cube_t0_A3.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '621'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d7/8-cell.gif',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '622'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d6/8-cell-orig.gif',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '623'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Tesseract-perspective-vertex-first-PSPclarify.png/200px-Tesseract-perspective-vertex-first-PSPclarify.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '624'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Tesseract_tetrahedron_shadow_matrices.svg/400px-Tesseract_tetrahedron_shadow_matrices.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '625'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Stereographic_polytope_8cell.png/400px-Stereographic_polytope_8cell.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '626'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/3D_stereographic_projection_tesseract.PNG/360px-3D_stereographic_projection_tesseract.PNG',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '627'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Hypercube_Disarmed.PNG/720px-Hypercube_Disarmed.PNG',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '628'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/4-simplex_t0.svg/240px-4-simplex_t0.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '629'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/4-cube_t3.svg/240px-4-cube_t3.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '630'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/4-cube_t0.svg/240px-4-cube_t0.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '631'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/24-cell_t0_F4.svg/240px-24-cell_t0_F4.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '632'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/600-cell_graph_H4.svg/240px-600-cell_graph_H4.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '633'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/120-cell_graph_H4.svg/240px-120-cell_graph_H4.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '634'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/4-generalized-2-cube.svg/320px-4-generalized-2-cube.svg.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '635'
        },
        {
        title: 'Tesseract ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Complex_polygon_4-4-2-stereographic3.png/320px-Complex_polygon_4-4-2-stereographic3.png',
        description: 'In geometry, the tesseract is the four-dimensional analogue of the cube; the tesseract is to the cube as the cube is to the square. Just as the surface of the cube consists of six square faces, the hypersurface of the tesseract consists of eight cubical cells. The tesseract is one of the six convex regular 4-polytopes.',
        id: '636'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Bayes%27_Theorem_MMB_01.jpg/440px-Bayes%27_Theorem_MMB_01.jpg',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '637'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Bayes_icon.svg/160px-Bayes_icon.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '638'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '639'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Bayes-rule3.png/440px-Bayes-rule3.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '640'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Bayes_theorem_assassin.svg/384px-Bayes_theorem_assassin.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '641'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Bayes_theorem_tree_diagrams.svg/440px-Bayes_theorem_tree_diagrams.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '642'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Bayes_theorem_simple_example_tree.svg/440px-Bayes_theorem_simple_example_tree.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '643'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Bayes_continuous_diagram.svg/440px-Bayes_continuous_diagram.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '644'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Continuous_event_space_specification.svg/440px-Continuous_event_space_specification.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '645'
        },
        {
        title: 'Bayes theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In probability theory and statistics, Bayes theorem (alternatively Bayes law or Bayes rule; recently Bayes–Price theorem: 44, 45, 46 and 67 ), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.',
        id: '646'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '647'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/A_Recent_Entrance_to_Paradise.jpg/440px-A_Recent_Entrance_to_Paradise.jpg',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '648'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Audio_curves_graph.png/440px-Audio_curves_graph.png',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '649'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/440px-Woman_1.jpg',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '650'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/GAN_deepfake_white_girl.jpg/440px-GAN_deepfake_white_girl.jpg',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '651'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/47px-Ballerina-icon.jpg',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '652'
        },
        {
        title: 'Generative adversarial network ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agents gain is another agents loss)',
        id: '653'
        },
        {
        title: 'ASCII ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/USASCII_code_chart.png/500px-USASCII_code_chart.png',
        description: 'ASCII (/ˈæskiː/ (listen) ASS-kee),[3]: 6  abbreviated from American Standard Code for Information Interchange, is a character encoding standard for electronic communication. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters',
        id: '654'
        },
        {
        title: 'ASCII ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/ASCII1963-infobox-paths.svg/560px-ASCII1963-infobox-paths.svg.png',
        description: 'ASCII (/ˈæskiː/ (listen) ASS-kee),[3]: 6  abbreviated from American Standard Code for Information Interchange, is a character encoding standard for electronic communication. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters',
        id: '655'
        },
        {
        title: 'Modulo operation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Divmod_truncated.svg/520px-Divmod_truncated.svg.png',
        description: 'In computing, the modulo operation returns the remainder or signed remainder of a division, after one number is divided by another (called the modulus of the operation).',
        id: '656'
        },
        {
        title: 'Modulo operation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Divmod_floored.svg/520px-Divmod_floored.svg.png',
        description: 'In computing, the modulo operation returns the remainder or signed remainder of a division, after one number is divided by another (called the modulus of the operation).',
        id: '657'
        },
        {
        title: 'Modulo operation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Divmod_Euclidean.svg/520px-Divmod_Euclidean.svg.png',
        description: 'In computing, the modulo operation returns the remainder or signed remainder of a division, after one number is divided by another (called the modulus of the operation).',
        id: '658'
        },
        {
        title: 'Modulo operation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Divmod_rounding.svg/520px-Divmod_rounding.svg.png',
        description: 'In computing, the modulo operation returns the remainder or signed remainder of a division, after one number is divided by another (called the modulus of the operation).',
        id: '659'
        },
        {
        title: 'Modulo operation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Divmod_ceiling.svg/520px-Divmod_ceiling.svg.png',
        description: 'In computing, the modulo operation returns the remainder or signed remainder of a division, after one number is divided by another (called the modulus of the operation).',
        id: '660'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d9/Truchet_base_tiles_bordered.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '661'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Truchet_ordered_tiling.svg/1124px-Truchet_ordered_tiling.svg.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '662'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Truchet_base_tiling.svg/500px-Truchet_base_tiling.svg.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '663'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Truchet_tile.svg/240px-Truchet_tile.svg.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '664'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Truchet_tile_inverse.svg/240px-Truchet_tile_inverse.svg.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '665'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Truchet_tiling.svg/500px-Truchet_tiling.svg.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '666'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/41/Truchet_labyrinth.png',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '667'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Marble_floor_mosaic_Basilica_of_St_Mark_Vencice.jpg/180px-Marble_floor_mosaic_Basilica_of_St_Mark_Vencice.jpg',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '668'
        },
        {
        title: 'Truchet tiles ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/2C_3_1979.JPG/180px-2C_3_1979.JPG',
        description: 'In information visualization and graphic design, Truchet tiles are square tiles decorated with patterns that are not rotationally symmetric. When placed in a square tiling of the plane, they can form varied patterns, and the orientation of each tile can be used to visualize information associated with the tiles position within the tiling.',
        id: '669'
        },
        {
        title: 'Haar-like feature ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Prm_VJ_fig3_computeRectangleWithAlpha.png/440px-Prm_VJ_fig3_computeRectangleWithAlpha.png',
        description: 'Haar-like features are digital image features used in object recognition. They owe their name to their intuitive similarity with Haar wavelets and were used in the first real-time face detector.',
        id: '670'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Barnsley_fern_1024x1024.png/440px-Barnsley_fern_1024x1024.png',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '671'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/Barnsley_fern_2000x2000.png/440px-Barnsley_fern_2000x2000.png',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '672'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Sa-fern.jpg/440px-Sa-fern.jpg',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '673'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Barnsley_Fern_fractals_-_4_states.PNG/440px-Barnsley_Fern_fractals_-_4_states.PNG',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '674'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Barnsley_fern_with_different_coefficients_plotted_with_VisSim.PNG/440px-Barnsley_fern_with_different_coefficients_plotted_with_VisSim.PNG',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '675'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Barnsley_fern_mutated_-Leptosporangiate_fern.PNG/440px-Barnsley_fern_mutated_-Leptosporangiate_fern.PNG',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '676'
        },
        {
        title: 'Barnsley fern ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Edmond_de_Belamy.png/230px-Edmond_de_Belamy.png',
        description: 'The Barnsley fern is a fractal named after the British mathematician Michael Barnsley who first described it in his book Fractals Everywhere. He made it to resemble the black spleenwort, Asplenium adiantum-nigrum.',
        id: '677'
        },
        {
        title: 'Gradient noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/05/Synaptic.png',
        description: 'Gradient noise is a type of noise commonly used as a procedural texture primitive in computer graphics. It is conceptually different[further explanation needed], and often confused with value noise. This method consists of a creation of a lattice of random (or typically pseudorandom) gradients, dot products of which are then interpolated to obtain values in between the lattices. An artifact of some implementations of this noise is that the returned value at the lattice points is 0. Unlike the value noise, gradient noise has more energy in the high frequencies.',
        id: '678'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Menger-Schwamm-farbig.png/620px-Menger-Schwamm-farbig.png',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '679'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/de/Menger_sponge_%28Level_0-3%29.jpg',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '680'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Megamenger_Bath.jpg/399px-Megamenger_Bath.jpg',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '681'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Cmglee_Cambridge_Science_Festival_2015_Menger_sponge.jpg/399px-Cmglee_Cambridge_Science_Festival_2015_Menger_sponge.jpg',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '682'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Cube_de_J%C3%A9rusalem%2C_it%C3%A9ration_3.png/361px-Cube_de_J%C3%A9rusalem%2C_it%C3%A9ration_3.png',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '683'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Jerusalem_Cube.jpg/400px-Jerusalem_Cube.jpg',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '684'
        },
        {
        title: 'Menger sponge ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/8e/Sierpinskisnowflake.gif',
        description: 'In mathematics, the Menger sponge (also known as the Menger cube, Menger universal curve, Sierpinski cube, or Sierpinski sponge)[3] is a fractal curve. It is a three-dimensional generalization of the one-dimensional Cantor set and two-dimensional Sierpinski carpet. It was first described by Karl Menger in 1926, in his studies of the concept of topological dimension.[4][5]',
        id: '685'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '686'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Lissajous_figure_-_sand_on_paper.jpg/440px-Lissajous_figure_-_sand_on_paper.jpg',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '687'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Lissajous-Figur_1_zu_3_%28Oszilloskop%29.jpg/500px-Lissajous-Figur_1_zu_3_%28Oszilloskop%29.jpg',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '688'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Harmonie-circulaire.gif/440px-Harmonie-circulaire.gif',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '689'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5d/Lissajous_animation.gif',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '690'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Lissajous_curve_1by2.svg/240px-Lissajous_curve_1by2.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '691'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Lissajous_curve_3by2.svg/240px-Lissajous_curve_3by2.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '692'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Lissajous_curve_3by4.svg/240px-Lissajous_curve_3by4.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '693'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Lissajous_curve_5by4.svg/240px-Lissajous_curve_5by4.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '694'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Lissajous_relaciones.png/154px-Lissajous_relaciones.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '695'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/LissajousTechnion.png/500px-LissajousTechnion.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '696'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Circular_Lissajous.gif/250px-Circular_Lissajous.gif',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '697'
        },
        {
        title: 'Lissajous curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Lissajous_phase.svg/1200px-Lissajous_phase.svg.png',
        description: 'A Lissajous curve /ˈlɪsəʒuː/, also known as Lissajous figure or Bowditch curve /ˈbaʊdɪtʃ/, is the graph of a system of parametric equations',
        id: '698'
        },
        {
        title: 'Poisson distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/650px-Poisson_pmf.svg.png',
        description: 'In probability theory and statistics, the Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. It is named after French mathematician Siméon Denis Poisson (/ˈpwɑːsɒn/; French pronunciation: ​[pwasɔ̃]). The Poisson distribution can also be used for the number of events in other specified interval types such as distance, area or volume',
        id: '699'
        },
        {
        title: 'Poisson distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Poisson_cdf.svg/650px-Poisson_cdf.svg.png',
        description: 'In probability theory and statistics, the Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. It is named after French mathematician Siméon Denis Poisson (/ˈpwɑːsɒn/; French pronunciation: ​[pwasɔ̃]). The Poisson distribution can also be used for the number of events in other specified interval types such as distance, area or volume',
        id: '700'
        },
        {
        title: 'Poisson distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In probability theory and statistics, the Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. It is named after French mathematician Siméon Denis Poisson (/ˈpwɑːsɒn/; French pronunciation: ​[pwasɔ̃]). The Poisson distribution can also be used for the number of events in other specified interval types such as distance, area or volume',
        id: '701'
        },
        {
        title: 'Poisson distribution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Binomial_versus_poisson.svg/660px-Binomial_versus_poisson.svg.png',
        description: 'In probability theory and statistics, the Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. It is named after French mathematician Siméon Denis Poisson (/ˈpwɑːsɒn/; French pronunciation: ​[pwasɔ̃]). The Poisson distribution can also be used for the number of events in other specified interval types such as distance, area or volume',
        id: '702'
        },
        {
        title: 'Lacunarity ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Rotational_Invariance_Example.gif/440px-Rotational_Invariance_Example.gif',
        description: 'Lacunarity, from the Latin lacuna, meaning "gap" or "lake", is a specialized term in geometry referring to a measure of how patterns, especially fractals, fill space, where patterns having more or larger gaps generally have higher lacunarity. Beyond being an intuitive measure of gappiness, lacunarity can quantify additional features of patterns such as "rotational invariance" and more generally, heterogeneity.[3] This is illustrated in Figure 1 showing three fractal patterns. When rotated 90°, the first two fairly homogeneous patterns do not appear to change, but the third more heterogeneous figure does change and has correspondingly higher lacunarity. The earliest reference to the term in geometry is usually attributed to Mandelbrot, who, in 1983 or perhaps as early as 1977, introduced it as, in essence, an adjunct to fractal analysis.[4] Lacunarity analysis is now used to characterize patterns in a wide variety of fields and has application in multifractal analysis[5][6] in particular (see Applications)',
        id: '703'
        },
        {
        title: 'Lacunarity ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Rotational_Invariance_rotated.gif/440px-Rotational_Invariance_rotated.gif',
        description: 'Lacunarity, from the Latin lacuna, meaning "gap" or "lake", is a specialized term in geometry referring to a measure of how patterns, especially fractals, fill space, where patterns having more or larger gaps generally have higher lacunarity. Beyond being an intuitive measure of gappiness, lacunarity can quantify additional features of patterns such as "rotational invariance" and more generally, heterogeneity.[3] This is illustrated in Figure 1 showing three fractal patterns. When rotated 90°, the first two fairly homogeneous patterns do not appear to change, but the third more heterogeneous figure does change and has correspondingly higher lacunarity. The earliest reference to the term in geometry is usually attributed to Mandelbrot, who, in 1983 or perhaps as early as 1977, introduced it as, in essence, an adjunct to fractal analysis.[4] Lacunarity analysis is now used to characterize patterns in a wide variety of fields and has application in multifractal analysis[5][6] in particular (see Applications)',
        id: '704'
        },
        {
        title: 'Lacunarity ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/53/Fixedstack.gif',
        description: 'Lacunarity, from the Latin lacuna, meaning "gap" or "lake", is a specialized term in geometry referring to a measure of how patterns, especially fractals, fill space, where patterns having more or larger gaps generally have higher lacunarity. Beyond being an intuitive measure of gappiness, lacunarity can quantify additional features of patterns such as "rotational invariance" and more generally, heterogeneity.[3] This is illustrated in Figure 1 showing three fractal patterns. When rotated 90°, the first two fairly homogeneous patterns do not appear to change, but the third more heterogeneous figure does change and has correspondingly higher lacunarity. The earliest reference to the term in geometry is usually attributed to Mandelbrot, who, in 1983 or perhaps as early as 1977, introduced it as, in essence, an adjunct to fractal analysis.[4] Lacunarity analysis is now used to characterize patterns in a wide variety of fields and has application in multifractal analysis[5][6] in particular (see Applications)',
        id: '705'
        },
        {
        title: 'Lacunarity ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ef/Slidestack.gif',
        description: 'Lacunarity, from the Latin lacuna, meaning "gap" or "lake", is a specialized term in geometry referring to a measure of how patterns, especially fractals, fill space, where patterns having more or larger gaps generally have higher lacunarity. Beyond being an intuitive measure of gappiness, lacunarity can quantify additional features of patterns such as "rotational invariance" and more generally, heterogeneity.[3] This is illustrated in Figure 1 showing three fractal patterns. When rotated 90°, the first two fairly homogeneous patterns do not appear to change, but the third more heterogeneous figure does change and has correspondingly higher lacunarity. The earliest reference to the term in geometry is usually attributed to Mandelbrot, who, in 1983 or perhaps as early as 1977, introduced it as, in essence, an adjunct to fractal analysis.[4] Lacunarity analysis is now used to characterize patterns in a wide variety of fields and has application in multifractal analysis[5][6] in particular (see Applications)',
        id: '706'
        },
        {
        title: 'Error diffusion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/33/Neighborhood_watch_bw.png',
        description: 'Error diffusion is a type of halftoning in which the quantization residual is distributed to neighboring pixels that have not yet been processed. Its main use is to convert a multi-level image into a binary image, though it has other applications.',
        id: '707'
        },
        {
        title: 'Error diffusion ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Error diffusion is a type of halftoning in which the quantization residual is distributed to neighboring pixels that have not yet been processed. Its main use is to convert a multi-level image into a binary image, though it has other applications.',
        id: '708'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Halftoning_introduction.svg/260px-Halftoning_introduction.svg.png',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '709'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Canadian_Illustrated_News_Volume_1_Number_1_Cover.jpg/340px-Canadian_Illustrated_News_Volume_1_Number_1_Cover.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '710'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Julemotiv_tegnet_av_Jenny_Nystr%C3%B8m_%2824207693358%29.jpg/340px-Julemotiv_tegnet_av_Jenny_Nystr%C3%B8m_%2824207693358%29.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '711'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Halftoningcolor.svg/408px-Halftoningcolor.svg.png',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '712'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a1/CMYK_raster_print.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '713'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/CMYK_screen_angles.svg/440px-CMYK_screen_angles.svg.png',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '714'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Grayscale_Cat.jpg/476px-Grayscale_Cat.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '715'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Dithered_Cat.jpg/476px-Dithered_Cat.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '716'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Descreened_Cat.jpg/476px-Descreened_Cat.jpg',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '717'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/16/Risingstar_test_crop.png',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '718'
        },
        {
        title: 'Halftone ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'Halftone is the reprographic technique that simulates continuous-tone imagery through the use of dots, varying either in size or in spacing, thus generating a gradient-like effect. "Halftone" can also be used to refer specifically to the image that is produced by this process.[1',
        id: '719'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/PWM%2C_3-level.svg/700px-PWM%2C_3-level.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '720'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Modulation_categorization.svg/600px-Modulation_categorization.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '721'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b8/Duty_Cycle_Examples.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '722'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Duty_cycle_general.svg/700px-Duty_cycle_general.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '723'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Pwm.svg/700px-Pwm.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '724'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Delta_PWM.svg/700px-Delta_PWM.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '725'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigma-delta_PWM.svg/700px-Sigma-delta_PWM.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '726'
        },
        {
        title: 'Pulse-width modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Three_PWM_types.svg/700px-Three_PWM_types.svg.png',
        description: 'Pulse-width modulation (PWM), or pulse-duration modulation (PDM), is a method of reducing the average power delivered by an electrical signal, by effectively chopping it up into discrete parts. The average value of voltage (and current) fed to the load is controlled by turning the switch between supply and load on and off at a fast rate. The longer the switch is on compared to the off periods, the higher the total power supplied to the load. Along with maximum power point tracking (MPPT), it is one of the primary methods of reducing the output of solar panels to that which can be utilized by a battery. PWM is particularly suited for running inertial loads such as motors, which are not as easily affected by this discrete switching, because their inertia causes them to react slowly. The PWM switching frequency has to be high enough not to affect the load, which is to say that the resultant waveform perceived by the load must be as smooth as possible. ',
        id: '727'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Modulation_categorization.svg/600px-Modulation_categorization.svg.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '728'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Amfm3-en-de.gif/250px-Amfm3-en-de.gif',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '729'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/f0/GE_FM_radio_antistatic_demonstration_1940.jpg',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '730'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '731'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Waterfall_FM.jpg/440px-Waterfall_FM.jpg',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '732'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/FM_Modulation_-_en.png/440px-FM_Modulation_-_en.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '733'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/FM_Broadcast_Transmitter_High_Power.jpg/400px-FM_Broadcast_Transmitter_High_Power.jpg',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '734'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/130px-Telecom-icon.svg.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '735'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/56px-Telecom-icon.svg.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '736'
        },
        {
        title: 'Frequency modulation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/1d/Radio_icon.png',
        description: 'Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and computing.',
        id: '737'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Volume_ray_casting.svg/800px-Volume_ray_casting.svg.png',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '738'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Croc.5.3.10.a_gb1.jpg/600px-Croc.5.3.10.a_gb1.jpg',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '739'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Croc.5.3.10.a_gb1.jpg/240px-Croc.5.3.10.a_gb1.jpg',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '740'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Croc.5.3.10.b_gb1.jpg/240px-Croc.5.3.10.b_gb1.jpg',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '741'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Croc.5.3.10.h_gb1.jpg/240px-Croc.5.3.10.h_gb1.jpg',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '742'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/High_Definition_Volume_Rendering.JPG/240px-High_Definition_Volume_Rendering.JPG',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '743'
        },
        {
        title: 'Volume ray casting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Visualization_of_SDF_ray_marching_algorithm.png/440px-Visualization_of_SDF_ray_marching_algorithm.png',
        description: 'Volume ray casting, sometimes called volumetric ray casting, volumetric ray tracing, or volume ray marching, is an image-based volume rendering technique. It computes 2D images from 3D volumetric data sets (3D scalar fields). Volume ray casting, which processes volume data, must not be mistaken with ray casting in the sense used in ray tracing, which processes surface data. In the volumetric variant, the computation doesnt stop at the surface but "pushes through" the object, sampling the object along the ray. Unlike ray tracing, volume ray casting does not spawn secondary rays. When the context/application is clear, some authors simply call it ray casting.  Because raymarching does not necessarily require an exact solution to ray intersection and collisions, it is suitable for real time computing for many applications for which ray tracing is unsuitable.',
        id: '744'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/LCD_layers.svg/440px-LCD_layers.svg.png',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '745'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Amersfoort_LCD_Display_Valleilijn.jpg/400px-Amersfoort_LCD_Display_Valleilijn.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '746'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/LCDneg.jpg/440px-LCDneg.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '747'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Casio_W-59_digital_watch.jpg/440px-Casio_W-59_digital_watch.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '748'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/LCD-Glass-sizes-generation.svg/970px-LCD-Glass-sizes-generation.svg.png',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '749'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/LCD-TV_Backlight_with_CCFL.jpg/440px-LCD-TV_Backlight_with_CCFL.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '750'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Zebra_connector.jpg/440px-Zebra_connector.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '751'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/BBC_STN_Matrixanzeige_540x270.jpg/440px-BBC_STN_Matrixanzeige_540x270.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '752'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Passive_Matrix_vs_Active_Matrix.jpg/440px-Passive_Matrix_vs_Active_Matrix.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '753'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Casio_LCD_screen_for_digital_camera.jpg/440px-Casio_LCD_screen_for_digital_camera.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '754'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/LCD_structure.JPG/440px-LCD_structure.JPG',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '755'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/IPS_LCD_panel.jpg/440px-IPS_LCD_panel.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '756'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Wiki_dell_lcd.jpg/440px-Wiki_dell_lcd.jpg',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '757'
        },
        {
        title: 'Liquid-crystal display ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'A liquid-crystal display (LCD) is a flat-panel display or other electronically modulated optical device that uses the light-modulating properties of liquid crystals combined with polarizers. Liquid crystals do not emit light directly, instead using a backlight or reflector to produce images in color or monochrome. LCDs are available to display arbitrary images (as in a general-purpose computer display) or fixed images with low information content, which can be displayed or hidden. For instance: preset words, digits, and seven-segment displays, as in a digital clock, are all good examples of devices with these displays. They use the same basic technology, except that arbitrary images are made from a matrix of small pixels, while other displays have larger elements. LCDs can either be normally on (positive) or off (negative), depending on the polarizer arrangement. For example, a character positive LCD with a backlight will have black lettering on a background that is the color of the backlight, and a character negative LCD will have a black background with the letters being of the same color as the backlight. Optical filters are added to white on blue LCDs to give them their characteristic appearance',
        id: '758'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Hsl-hsv_models.svg/580px-Hsl-hsv_models.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '759'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/HSL_color_solid_cylinder_saturation_gray.png/394px-HSL_color_solid_cylinder_saturation_gray.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '760'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/HSV_color_solid_cylinder_saturation_gray.png/394px-HSV_color_solid_cylinder_saturation_gray.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '761'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/HSL_color_solid_dblcone_chroma_gray.png/394px-HSL_color_solid_dblcone_chroma_gray.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '762'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/HSV_color_solid_cone_chroma_gray.png/394px-HSV_color_solid_cone_chroma_gray.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '763'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Color_circle_%28RGB%29.svg/440px-Color_circle_%28RGB%29.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '764'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Tint-tone-shade.svg/400px-Tint-tone-shade.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '765'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Ostwald.svg/400px-Ostwald.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '766'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/RGB_Cube_Show_lowgamma_cutout_a.png/400px-RGB_Cube_Show_lowgamma_cutout_a.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '767'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/RGB_Cube_Show_lowgamma_cutout_b.png/400px-RGB_Cube_Show_lowgamma_cutout_b.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '768'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Tektronix-hsl-patent-diagram.png/600px-Tektronix-hsl-patent-diagram.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '769'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5d/Unintuitive-rgb.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '770'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Hsl-and-hsv.svg/600px-Hsl-and-hsv.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '771'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/HSL-HSV_hue_and_chroma.svg/600px-HSL-HSV_hue_and_chroma.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '772'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Hsv-hexagons-to-circles.svg/600px-Hsv-hexagons-to-circles.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '773'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Hsv-polar-coord-hue-chroma.svg/600px-Hsv-polar-coord-hue-chroma.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '774'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Hsl-hsv_chroma-lightness_slices.svg/600px-Hsl-hsv_chroma-lightness_slices.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '775'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Hsl-hsv_saturation-lightness_slices.svg/600px-Hsl-hsv_saturation-lightness_slices.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '776'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Hsi_saturation-intensity_slices.svg/600px-Hsi_saturation-intensity_slices.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '777'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/ea/Hsl-hsv-colorpickers.svg/600px-Hsl-hsv-colorpickers.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '778'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/c/cf/Xv_hsv-modification.png/200px-Xv_hsv-modification.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '779'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/en/2/28/PS_2.5_hue-saturation_tool.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '780'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Srgb-in-cielab.png/394px-Srgb-in-cielab.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '781'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Adobergb-in-cielab.png/394px-Adobergb-in-cielab.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '782'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Fire_breathing_2_Luc_Viatour.jpg/440px-Fire_breathing_2_Luc_Viatour.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '783'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Fire-breather_CIELAB_L%2A.jpg/440px-Fire-breather_CIELAB_L%2A.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '784'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Fire-breather_601_Luma_Y%27.jpg/440px-Fire-breather_601_Luma_Y%27.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '785'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Fire-breather_mean%28R%2CG%2CB%29_I.jpg/440px-Fire-breather_mean%28R%2CG%2CB%29_I.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '786'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Fire-breather_HSV_V.jpg/440px-Fire-breather_HSV_V.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '787'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Fire-breather_HSL_L.jpg/440px-Fire-breather_HSL_L.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '788'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Hawaii_turtle_2.JPG/440px-Hawaii_turtle_2.JPG',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '789'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Hawaii-turtle_hue_shifted.jpg/440px-Hawaii-turtle_hue_shifted.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '790'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Hawaii-turtle_hue_shifted_with_constant_L%2A.jpg/440px-Hawaii-turtle_hue_shifted_with_constant_L%2A.jpg',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '791'
        },
        {
        title: 'HSL and HSV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/HSV-RGB-comparison.svg/600px-HSV-RGB-comparison.svg.png',
        description: 'HSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.',
        id: '792'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '793'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/YUV_UV_plane.svg/600px-YUV_UV_plane.svg.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '794'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Barn-yuv.png/300px-Barn-yuv.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '795'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/CIExy1931_Rec_2020_and_Rec_709.svg/440px-CIExy1931_Rec_2020_and_Rec_709.svg.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '796'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/YUV_plane_0.png/240px-YUV_plane_0.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '797'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/YUV_plane_0p5.png/240px-YUV_plane_0p5.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '798'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/YUV_plane_0p5_gamut.png/240px-YUV_plane_0p5_gamut.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '799'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/YUV_plane_1.png/240px-YUV_plane_1.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '800'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Yuv422_yuy2.svg/440px-Yuv422_yuy2.svg.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '801'
        },
        {
        title: 'YUV ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Yuv420.svg/1600px-Yuv420.svg.png',
        description: 'YUV is a color model typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, allowing reduced bandwidth for chrominance components, compared to a "direct" RGB-representation. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems. Today, the term YUV is commonly used in the computer industry to describe file-formats (pixel formats) that are encoded using YCbCr',
        id: '802'
        },
        {
        title: 'Chrominance ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Luma_Chroma_both.png/440px-Luma_Chroma_both.png',
        description: 'Chrominance (chroma or C for short) is the signal used in video systems to convey the color information of the picture (see YUV color model), separately from the accompanying luma signal (or Y for short). Chrominance is usually represented as two color-difference components: U = B′ − Y′ (blue − luma) and V = R′ − Y′ (red − luma).  Each of these difference components may have scale factors and offsets applied to it, as specified by the applicable video standard.  ',
        id: '803'
        },
        {
        title: 'Chrominance ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'Chrominance (chroma or C for short) is the signal used in video systems to convey the color information of the picture (see YUV color model), separately from the accompanying luma signal (or Y for short). Chrominance is usually represented as two color-difference components: U = B′ − Y′ (blue − luma) and V = R′ − Y′ (red − luma).  Each of these difference components may have scale factors and offsets applied to it, as specified by the applicable video standard.  ',
        id: '804'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Sierpinski_triangle.svg/440px-Sierpinski_triangle.svg.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '805'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/ad/Random_Sierpinski_Triangle_animation.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '806'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Multigrade_operator_AND.svg/440px-Multigrade_operator_AND.svg.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '807'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Sierpinski_triangle_evolution.svg/1024px-Sierpinski_triangle_evolution.svg.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '808'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Sierpinski_triangle_evolution_square.svg/1024px-Sierpinski_triangle_evolution_square.svg.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '809'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Tri%C3%A2ngulo_de_Sierpinski.gif/200px-Tri%C3%A2ngulo_de_Sierpinski.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '810'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Animated_construction_of_Sierpinski_Triangle.gif/400px-Animated_construction_of_Sierpinski_Triangle.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '811'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a9/Fractal_tree.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '812'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Sierpinski_triangle_with_tree_diagram_addresses.png/440px-Sierpinski_triangle_with_tree_diagram_addresses.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '813'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/31/Sierpinski1.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '814'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Animated-sierpinski-arrowhead.gif/440px-Animated-sierpinski-arrowhead.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '815'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Arrowhead_curve_1_through_6.png/440px-Arrowhead_curve_1_through_6.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '816'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Sierpinski_Pascal_triangle.svg/440px-Sierpinski_Pascal_triangle.svg.png',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '817'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Sierpinskitetrahedron.gif/250px-Sierpinskitetrahedron.gif',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '818'
        },
        {
        title: 'Sierpiński triangle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Sierpi%C5%84ski_Pyramid_from_Above.PNG/440px-Sierpi%C5%84ski_Pyramid_from_Above.PNG',
        description: 'The Sierpiński triangle (sometimes spelled Sierpinski), also called the Sierpiński gasket or Sierpiński sieve,  is a fractal attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets—that is, it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński.',
        id: '819'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '820'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Droste_Cacao_Alcalinise_blikje%2C_foto4.JPG/440px-Droste_Cacao_Alcalinise_blikje%2C_foto4.JPG',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '821'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Serpiente_alquimica.jpg/440px-Serpiente_alquimica.jpg',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '822'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Sourdough.jpg/440px-Sourdough.jpg',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '823'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Web_Page.png/440px-Web_Page.png',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '824'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Sierpinski_triangle.svg/500px-Sierpinski_triangle.svg.png',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '825'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/First_matryoshka_museum_doll_open.jpg/440px-First_matryoshka_museum_doll_open.jpg',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '826'
        },
        {
        title: 'Recursion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Polittico_stefaneschi%2C_verso.jpg/440px-Polittico_stefaneschi%2C_verso.jpg',
        description: 'Recursion (adjective: recursive) occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references ("crock recursion") can occur',
        id: '827'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Cantor_Zoom.gif/1200px-Cantor_Zoom.gif',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '828'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Cantor_set_in_seven_iterations.svg/1458px-Cantor_set_in_seven_iterations.svg.png',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '829'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Cantor_set_binary_tree.svg/800px-Cantor_set_binary_tree.svg.png',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '830'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Cantorcubes.gif/250px-Cantorcubes.gif',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '831'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Cantor_dust.svg/440px-Cantor_dust.svg.png',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '832'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Cantors_cube.jpg/440px-Cantors_cube.jpg',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '833'
        },
        {
        title: 'Cantor set ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Cantor-like_Column_Capital_Ile_de_Philae_Description_d%27Egypte_1809.jpg/440px-Cantor-like_Column_Capital_Ile_de_Philae_Description_d%27Egypte_1809.jpg',
        description: 'In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties.  It was discovered in 1874 by Henry John Stephen Smith[3][4] and introduced by German mathematician Georg Cantor in 1883.[5][6]',
        id: '834'
        },
        {
        title: 'Huffman coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Huffman_tree_2.svg/440px-Huffman_tree_2.svg.png',
        description: 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes".',
        id: '835'
        },
        {
        title: 'Huffman coding ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes".',
        id: '836'
        },
        {
        title: 'Huffman coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/HuffmanCodeAlg.png/440px-HuffmanCodeAlg.png',
        description: 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes".',
        id: '837'
        },
        {
        title: 'Huffman coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Huffman_coding_visualisation.svg/720px-Huffman_coding_visualisation.svg.png',
        description: 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes".',
        id: '838'
        },
        {
        title: 'Huffman coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Huffman_coding_example.svg/440px-Huffman_coding_example.svg.png',
        description: 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes".',
        id: '839'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/KochFlake.svg/520px-KochFlake.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '840'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/fd/Von_Koch_curve.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '841'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/65/Kochsim.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '842'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Koch_antisnowflake_1_through_4.svg/400px-Koch_antisnowflake_1_through_4.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '843'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/KochAntiSnowflake.svg/400px-KochAntiSnowflake.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '844'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Koch_rough_surface.png/440px-Koch_rough_surface.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '845'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Koch_similarity_tiling.svg/440px-Koch_similarity_tiling.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '846'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Koch_Curve_85degrees.png/300px-Koch_Curve_85degrees.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '847'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Ces%C3%A0ro_fractal_outlines_1-4.svg/900px-Ces%C3%A0ro_fractal_outlines_1-4.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '848'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Quadratic_Koch_2.svg/300px-Quadratic_Koch_2.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '849'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Quadratic_Koch_curve_type1_iterations.png/900px-Quadratic_Koch_curve_type1_iterations.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '850'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Quadratic_Koch.svg/300px-Quadratic_Koch.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '851'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Quadratic_Koch_curve_type2_iterations.png/900px-Quadratic_Koch_curve_type2_iterations.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '852'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Minkowski_island_3.svg/300px-Minkowski_island_3.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '853'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Minkowski_island_1-3.svg/900px-Minkowski_island_1-3.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '854'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Karperienflake.gif/300px-Karperienflake.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '855'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Karperienflakeani2.gif/900px-Karperienflakeani2.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '856'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Anticross-stitch_curve_0-4.svg/300px-Anticross-stitch_curve_0-4.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '857'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Quadriccross.gif/300px-Quadriccross.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '858'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Koch_quadratic_island_L7_3.svg/300px-Koch_quadratic_island_L7_3.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '859'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Koch_quadratic_L7_curves_0-2.svg/900px-Koch_quadratic_L7_curves_0-2.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '860'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Koch_surface_3.png/300px-Koch_surface_3.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '861'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Koch_surface_0_through_3.png/450px-Koch_surface_0_through_3.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '862'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Koch_quadratic_3d_fractal.svg/300px-Koch_quadratic_3d_fractal.svg.png',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '863'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/KochCube_Animation_Gray.gif/600px-KochCube_Animation_Gray.gif',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '864'
        },
        {
        title: 'Koch snowflake ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Koch_Curve_in_Three_Dimensions_%28%22Delta%22_fractal%29.jpg/300px-Koch_Curve_in_Three_Dimensions_%28%22Delta%22_fractal%29.jpg',
        description: 'The Koch snowflake (also known as the Koch curve, Koch star, or Koch island) is a fractal curve and one of the earliest fractals to have been described. It is based on the Koch curve, which appeared in a 1904 paper titled "On a Continuous Curve Without Tangents, Constructible from Elementary Geometry"[3] by the Swedish mathematician Helge von Koch.',
        id: '865'
        },
        {
        title: 'Advanced Video Coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/H.264%2C_MPEG-4_AVC_logo.svg/440px-H.264%2C_MPEG-4_AVC_logo.svg.png',
        description: 'Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, is a video compression standard based on block-oriented, motion-compensated coding. It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019[update].[3][4] It supports resolutions up to and  including 8K UHD.[5][6',
        id: '866'
        },
        {
        title: 'Advanced Video Coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/H.264_block_diagram_with_quality_score.jpg/440px-H.264_block_diagram_with_quality_score.jpg',
        description: 'Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, is a video compression standard based on block-oriented, motion-compensated coding. It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019[update].[3][4] It supports resolutions up to and  including 8K UHD.[5][6',
        id: '867'
        },
        {
        title: 'Advanced Video Coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/H.264_block_diagram_with_quality_score.jpg/300px-H.264_block_diagram_with_quality_score.jpg',
        description: 'Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, is a video compression standard based on block-oriented, motion-compensated coding. It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019[update].[3][4] It supports resolutions up to and  including 8K UHD.[5][6',
        id: '868'
        },
        {
        title: 'Advanced Video Coding ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/YouTube_H264_video_with_Opus_audio_stat_screenshot.png/260px-YouTube_H264_video_with_Opus_audio_stat_screenshot.png',
        description: 'Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, is a video compression standard based on block-oriented, motion-compensated coding. It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019[update].[3][4] It supports resolutions up to and  including 8K UHD.[5][6',
        id: '869'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Cross_product_vector.svg/440px-Cross_product_vector.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '870'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Right_hand_rule_cross_product.svg/440px-Right_hand_rule_cross_product.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '871'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6e/Cross_product.gif',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '872'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Sarrus_rule.svg/560px-Sarrus_rule.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '873'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/3D_Vector.svg/600px-3D_Vector.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '874'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Sarrus_rule_cross_product_ab.svg/440px-Sarrus_rule_cross_product_ab.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '875'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Cross_product_parallelogram.svg/440px-Cross_product_parallelogram.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '876'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Parallelepiped_volume.svg/480px-Parallelepiped_volume.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '877'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Cross_product_scalar_multiplication.svg/700px-Cross_product_scalar_multiplication.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '878'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Cross_product_distributivity.svg/700px-Cross_product_distributivity.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '879'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Cross_product_triple.svg/700px-Cross_product_triple.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '880'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Cross_product_mnemonic.svg/440px-Cross_product_mnemonic.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '881'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/Exterior_calc_cross_product.svg/440px-Exterior_calc_cross_product.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '882'
        },
        {
        title: 'Cross product ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, the cross product or vector product (occasionally directed area product, to emphasize its geometric significance) is a binary operation on two vectors in a three-dimensional oriented Euclidean vector space (named here  Given two linearly independent vectors a and b, the cross product, a × b (read "a cross b"), is a vector that is perpendicular to both a and b, and thus normal to the plane containing them. It has many applications in mathematics, physics, engineering, and computer programming. It should not be confused with the dot product (projection product).',
        id: '883'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '884'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Focal-length.svg/440px-Focal-length.svg.png',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '885'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Thick_Lens_Diagram.svg/660px-Thick_Lens_Diagram.svg.png',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '886'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/12/Angleofview_28mm_f4.jpg',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '887'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9c/Angleofview_50mm_f4.jpg',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '888'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/68/Angleofview_70mm_f4.jpg',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '889'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/fd/Angleofview_210mm_f4.jpg',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '890'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Thin_lens_images.svg/660px-Thin_lens_images.svg.png',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '891'
        },
        {
        title: 'Focal length ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d3/Camera_focal_length_distance_house_animation.gif',
        description: 'The focal length of an optical system is a measure of how strongly the system converges or diverges light; it is the inverse of the systems optical power. A positive focal length indicates that a system converges light, while a negative focal length indicates that the system diverges light. A system with a shorter focal length bends the rays more sharply, bringing them to a focus in a shorter distance or diverging them more quickly. For the special case of a thin lens in air, a positive focal length is the distance over which initially collimated (parallel) rays are brought to a focus, or alternatively a negative focal length indicates how far in front of the lens a point source must be located to form a collimated beam. For more general optical systems, the focal length has no intuitive meaning; it is simply the inverse of the systems optical power.',
        id: '892'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '893'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Venn0110.svg/300px-Venn0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '894'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/XOR_ANSI.svg/140px-XOR_ANSI.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '895'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Venn_0110_1001.svg/440px-Venn_0110_1001.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '896'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Multigrade_operator_XOR.svg/440px-Multigrade_operator_XOR.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '897'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/X-or.svg/48px-X-or.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '898'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Venn0110.svg/100px-Venn0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '899'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Venn0110.svg/100px-Venn0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '900'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Venn_0101_0101.svg/100px-Venn_0101_0101.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '901'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Venn_0011_1100.svg/100px-Venn_0011_1100.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '902'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Venn_0110_1001.svg/100px-Venn_0110_1001.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '903'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Venn_0110_0110.svg/100px-Venn_0110_0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '904'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Venn_0000_1111.svg/100px-Venn_0000_1111.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '905'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Venn01.svg/72px-Venn01.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '906'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Venn01.svg/72px-Venn01.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '907'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Venn00.svg/72px-Venn00.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '908'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Venn01.svg/72px-Venn01.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '909'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Venn_1011_1011.svg/100px-Venn_1011_1011.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '910'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Venn_1011_1101.svg/100px-Venn_1011_1101.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '911'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Venn_0101_1010.svg/100px-Venn_0101_1010.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '912'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Venn_0011_1100.svg/100px-Venn_0011_1100.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '913'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Venn0001.svg/100px-Venn0001.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '914'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Venn0110.svg/120px-Venn0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '915'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Venn0110.svg/120px-Venn0110.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '916'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Venn0111.svg/100px-Venn0111.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '917'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/XOR_ANSI_Labelled.svg/228px-XOR_ANSI_Labelled.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '918'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Z2%5E4%3B_Cayley_table%3B_binary.svg/440px-Z2%5E4%3B_Cayley_table%3B_binary.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '919'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Logical_connectives_Hasse_diagram.svg/160px-Logical_connectives_Hasse_diagram.svg.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '920'
        },
        {
        title: 'Exclusive or ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/36px-Socrates.png',
        description: 'Exclusive or or exclusive disjunction is a logical operation that is true if and only if its arguments differ (one is true, the other is false).[1',
        id: '921'
        },
        {
        title: 'Displacement mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Displacement mapping is an alternative computer graphics technique in contrast to bump mapping, normal mapping, and parallax mapping, using a (procedural-) texture- or height map to cause an effect where the actual geometric position of points over the textured surface are displaced, often along the local surface normal, according to the value the texture function evaluates to at each point on the surface. It gives surfaces a great sense of depth and detail, permitting in particular self-occlusion, self-shadowing and silhouettes; on the other hand, it is the most costly of this class of techniques owing to the large amount of additional geometry.',
        id: '922'
        },
        {
        title: 'Displacement mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a4/Displacement.jpg',
        description: 'Displacement mapping is an alternative computer graphics technique in contrast to bump mapping, normal mapping, and parallax mapping, using a (procedural-) texture- or height map to cause an effect where the actual geometric position of points over the textured surface are displaced, often along the local surface normal, according to the value the texture function evaluates to at each point on the surface. It gives surfaces a great sense of depth and detail, permitting in particular self-occlusion, self-shadowing and silhouettes; on the other hand, it is the most costly of this class of techniques owing to the large amount of additional geometry.',
        id: '923'
        },
        {
        title: 'Displacement mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Displace_Map.svg/320px-Displace_Map.svg.png',
        description: 'Displacement mapping is an alternative computer graphics technique in contrast to bump mapping, normal mapping, and parallax mapping, using a (procedural-) texture- or height map to cause an effect where the actual geometric position of points over the textured surface are displaced, often along the local surface normal, according to the value the texture function evaluates to at each point on the surface. It gives surfaces a great sense of depth and detail, permitting in particular self-occlusion, self-shadowing and silhouettes; on the other hand, it is the most costly of this class of techniques owing to the large amount of additional geometry.',
        id: '924'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Out-of-focus_image_of_a_spoke_target..svg/80px-Out-of-focus_image_of_a_spoke_target..svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '925'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/HartmannShack_1lenslet.svg/80px-HartmannShack_1lenslet.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '926'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Spherical_aberration_3.svg/80px-Spherical_aberration_3.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '927'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Astigmatism.svg/80px-Astigmatism.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '928'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Lens_coma.svg/80px-Lens_coma.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '929'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Barrel_distortion.svg/80px-Barrel_distortion.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '930'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Field_curvature.svg/80px-Field_curvature.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '931'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Chromatic_aberration_lens_diagram.svg/80px-Chromatic_aberration_lens_diagram.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '932'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Barrel_distortion.svg/200px-Barrel_distortion.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '933'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Pincushion_distortion.svg/200px-Pincushion_distortion.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '934'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Mustache_distortion.svg/200px-Mustache_distortion.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '935'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Globe_effect.gif/440px-Globe_effect.gif',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '936'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/WA_80_cm_archery_target.svg/440px-WA_80_cm_archery_target.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '937'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Barrel_%28PSF%29.png/288px-Barrel_%28PSF%29.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '938'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Cushion.jpg/300px-Cushion.jpg',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '939'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Handlebar-moustache.svg/300px-Handlebar-moustache.svg.png',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '940'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/ENIAC_at_Ft._Sill%2C_OK%2C_US%2C_with_barrel_distortion.jpg/440px-ENIAC_at_Ft._Sill%2C_OK%2C_US%2C_with_barrel_distortion.jpg',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '941'
        },
        {
        title: 'Distortion (optics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/ENIAC%2C_Ft._Sill%2C_OK%2C_US_%2878%29.jpg/440px-ENIAC%2C_Ft._Sill%2C_OK%2C_US_%2878%29.jpg',
        description: 'In geometric optics, distortion is a deviation from rectilinear projection; a projection in which straight lines in a scene remain straight in an image. It is a form of optical aberration',
        id: '942'
        },
        {
        title: 'Gaussian blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Cappadocia_Gaussian_Blur.svg/500px-Cappadocia_Gaussian_Blur.svg.png',
        description: 'In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function (named after mathematician and scientist Carl Friedrich Gauss). ',
        id: '943'
        },
        {
        title: 'Gaussian blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/d7/Halftone%2C_Gaussian_Blur.jpg',
        description: 'In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function (named after mathematician and scientist Carl Friedrich Gauss). ',
        id: '944'
        },
        {
        title: 'Gaussian blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/cc/Gaussian_blur_before_downscaling.png',
        description: 'In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function (named after mathematician and scientist Carl Friedrich Gauss). ',
        id: '945'
        },
        {
        title: 'Gaussian blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function (named after mathematician and scientist Carl Friedrich Gauss). ',
        id: '946'
        },
        {
        title: 'Gaussian blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/73/Edge_Image.gif',
        description: 'In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function (named after mathematician and scientist Carl Friedrich Gauss). ',
        id: '947'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/50/Vd-Orig.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '948'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/20/Vd-Rige1.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '949'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0b/Vd-Rige2.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '950'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4e/Vd-Sharp.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '951'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/04/Vd-Blur2.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '952'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/28/Vd-Blur1.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '953'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/04/Vd-Blur_Gaussian_5x5.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '954'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ef/Vd-Unsharp_5x5.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '955'
        },
        {
        title: 'Kernel (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4f/Extend_Edge-Handling.png',
        description: 'In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.',
        id: '956'
        },
        {
        title: 'Change of basis ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In mathematics, an ordered basis of a vector space of finite dimension n allows representing uniquely any element of the vector space by a coordinate vector, which is a sequence of n scalars called coordinates. If two different bases are considered, the coordinate vector that represents a vector v on one basis is, in general, different from the coordinate vector that represents v on the other basis. A change of basis consists of converting every assertion expressed in terms of coordinates relative to one basis into an assertion expressed in terms of coordinates relative to the other basis.[3]',
        id: '957'
        },
        {
        title: 'Change of basis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/3d_basis_transformation.svg/580px-3d_basis_transformation.svg.png',
        description: 'In mathematics, an ordered basis of a vector space of finite dimension n allows representing uniquely any element of the vector space by a coordinate vector, which is a sequence of n scalars called coordinates. If two different bases are considered, the coordinate vector that represents a vector v on one basis is, in general, different from the coordinate vector that represents v on the other basis. A change of basis consists of converting every assertion expressed in terms of coordinates relative to one basis into an assertion expressed in terms of coordinates relative to the other basis.[3]',
        id: '958'
        },
        {
        title: 'Change of basis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/3d_two_bases_same_vector.svg/244px-3d_two_bases_same_vector.svg.png',
        description: 'In mathematics, an ordered basis of a vector space of finite dimension n allows representing uniquely any element of the vector space by a coordinate vector, which is a sequence of n scalars called coordinates. If two different bases are considered, the coordinate vector that represents a vector v on one basis is, in general, different from the coordinate vector that represents v on the other basis. A change of basis consists of converting every assertion expressed in terms of coordinates relative to one basis into an assertion expressed in terms of coordinates relative to the other basis.[3]',
        id: '959'
        },
        {
        title: 'Change of basis ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, an ordered basis of a vector space of finite dimension n allows representing uniquely any element of the vector space by a coordinate vector, which is a sequence of n scalars called coordinates. If two different bases are considered, the coordinate vector that represents a vector v on one basis is, in general, different from the coordinate vector that represents v on the other basis. A change of basis consists of converting every assertion expressed in terms of coordinates relative to one basis into an assertion expressed in terms of coordinates relative to the other basis.[3]',
        id: '960'
        },
        {
        title: 'Normal (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Normal_vectors2.svg/440px-Normal_vectors2.svg.png',
        description: 'In geometry, a normal is an object such as a line, ray, or vector that is perpendicular to a given object. For example, the normal line to a plane curve at a given point is the (infinite) line perpendicular to the tangent line to the curve at the point.A normal vector may have length one (a unit vector) or its length may represent the curvature of the object (a curvature vector); its algebraic sign may indicate sides (interior or exterior).',
        id: '961'
        },
        {
        title: 'Normal (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Surface_normal_illustration.svg/440px-Surface_normal_illustration.svg.png',
        description: 'In geometry, a normal is an object such as a line, ray, or vector that is perpendicular to a given object. For example, the normal line to a plane curve at a given point is the (infinite) line perpendicular to the tangent line to the curve at the point.A normal vector may have length one (a unit vector) or its length may represent the curvature of the object (a curvature vector); its algebraic sign may indicate sides (interior or exterior).',
        id: '962'
        },
        {
        title: 'Normal (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Normal_vectors_on_a_curved_surface.svg/620px-Normal_vectors_on_a_curved_surface.svg.png',
        description: 'In geometry, a normal is an object such as a line, ray, or vector that is perpendicular to a given object. For example, the normal line to a plane curve at a given point is the (infinite) line perpendicular to the tangent line to the curve at the point.A normal vector may have length one (a unit vector) or its length may represent the curvature of the object (a curvature vector); its algebraic sign may indicate sides (interior or exterior).',
        id: '963'
        },
        {
        title: 'Normal (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Surface_normals.svg/600px-Surface_normals.svg.png',
        description: 'In geometry, a normal is an object such as a line, ray, or vector that is perpendicular to a given object. For example, the normal line to a plane curve at a given point is the (infinite) line perpendicular to the tangent line to the curve at the point.A normal vector may have length one (a unit vector) or its length may represent the curvature of the object (a curvature vector); its algebraic sign may indicate sides (interior or exterior).',
        id: '964'
        },
        {
        title: 'Normal (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Reflection_angles.svg/170px-Reflection_angles.svg.png',
        description: 'In geometry, a normal is an object such as a line, ray, or vector that is perpendicular to a given object. For example, the normal line to a plane curve at a given point is the (infinite) line perpendicular to the tangent line to the curve at the point.A normal vector may have length one (a unit vector) or its length may represent the curvature of the object (a curvature vector); its algebraic sign may indicate sides (interior or exterior).',
        id: '965'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Inner-product-angle.svg/440px-Inner-product-angle.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '966'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Tetrahedral_angle_calculation.svg/432px-Tetrahedral_angle_calculation.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '967'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/440px-Dot_Product.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '968'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Dot_product_distributive_law.svg/440px-Dot_product_distributive_law.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '969'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Wiki_dot.png/440px-Wiki_dot.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '970'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Dot_product_cosine_rule.svg/200px-Dot_product_cosine_rule.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '971'
        },
        {
        title: 'Dot product ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number.  In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called "the" inner product (or rarely projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see  Inner product space for more).',
        id: '972'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/2D_Direction_Vectors.svg/440px-2D_Direction_Vectors.svg.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '973'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/3D_Direction_Vectors.tiff/lossless-page1-440px-3D_Direction_Vectors.tiff.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '974'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Tangent_normal_binormal_unit_vectors.svg/400px-Tangent_normal_binormal_unit_vectors.svg.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '975'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Polar_coord_unit_vectors_and_normal.svg/400px-Polar_coord_unit_vectors_and_normal.svg.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '976'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Perpendicular_and_parallel_unit_vectors.svg/400px-Perpendicular_and_parallel_unit_vectors.svg.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '977'
        },
        {
        title: 'Unit vector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Angular_unit_vector.svg/400px-Angular_unit_vector.svg.png',
        description: 'In mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or "hat", as in .',
        id: '978'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Butterfly_transcendental_curve.svg/600px-Butterfly_transcendental_curve.svg.png',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '979'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Lissajous_curve_3by2.svg/440px-Lissajous_curve_3by2.svg.png',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '980'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/12/2-circles_hypotrochoid.gif',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '981'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/HypotrochoidOutThreeFifths.gif/240px-HypotrochoidOutThreeFifths.gif',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '982'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/Param_02.jpg/360px-Param_02.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '983'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Param_03.jpg/240px-Param_03.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '984'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Param33_1.jpg/240px-Param33_1.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '985'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Param34_1.jpg/240px-Param34_1.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '986'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Param34_2.jpg/240px-Param34_2.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '987'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Param34_3.jpg/240px-Param34_3.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '988'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Param_st_01.jpg/240px-Param_st_01.jpg',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '989'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Parametric_Helix.png/600px-Parametric_Helix.png',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '990'
        },
        {
        title: 'Parametric equation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Torus.png/240px-Torus.png',
        description: 'In mathematics, a parametric equation defines a group of quantities as functions of one or more independent variables called parameters. Parametric equations are commonly used to express the coordinates of the points that make up a geometric object such as a curve or surface, in which case the equations are collectively called a parametric representation or parameterization (alternatively spelled as parametrisation) of the object.[3]',
        id: '991'
        },
        {
        title: 'stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Stereographic_projection_in_3D.svg/440px-Stereographic_projection_in_3D.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '992'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Axonometric_projection.svg/300px-Axonometric_projection.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '993'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/RubensAguilonStereographic.jpg/440px-RubensAguilonStereographic.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '994'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Stereoprojzero.svg/440px-Stereoprojzero.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '995'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Stereoprojnegone.svg/440px-Stereoprojnegone.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '996'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/StereographicGeneric.svg/440px-StereographicGeneric.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '997'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/CartesianStereoProj.png/440px-CartesianStereoProj.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '998'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/PolarStereoProj.png/440px-PolarStereoProj.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '999'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/7/7a/Riemann_Sphere.jpg/350px-Riemann_Sphere.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1000'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a8/Inversion_by_Stereographic.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1001'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Wulffnet.svg/440px-Wulffnet.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1002'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Sphere-stgrpr-wn.svg/800px-Sphere-stgrpr-wn.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1003'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Wulffnetanimation.gif/440px-Wulffnetanimation.gif',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1004'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Wulff_net_central_angle_1.jpg/328px-Wulff_net_central_angle_1.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1005'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Wulff_net_central_angle_2.jpg/343px-Wulff_net_central_angle_2.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1006'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Riemann_sphere1.svg/600px-Riemann_sphere1.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1007'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9e/Sfsp111.gif',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1008'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Stereographic_projection_of_rational_points.svg/440px-Stereographic_projection_of_rational_points.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1009'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/WeierstrassSubstitution.svg/440px-WeierstrassSubstitution.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1010'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Stereographic_projection_SW.JPG/500px-Stereographic_projection_SW.JPG',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1011'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Stereographic_with_Tissot%27s_Indicatrices_of_Distortion.svg/500px-Stereographic_with_Tissot%27s_Indicatrices_of_Distortion.svg.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1012'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/LRO_WAC_North_Pole_Mosaic_%28PIA14024%29.jpg/440px-LRO_WAC_North_Pole_Mosaic_%28PIA14024%29.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1013'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/DiamondPoleFigure111.png/440px-DiamondPoleFigure111.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1014'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Stero_projection_structural_geology.png/600px-Stero_projection_structural_geology.png',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1015'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Cmglee_Wikimania2016_Esino_Lario_Last_Supper_tinyplanet.jpg/500px-Cmglee_Wikimania2016_Esino_Lario_Last_Supper_tinyplanet.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1016'
        },
        {
        title: 'Stereographic projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Vue_circulaire_des_montagnes_qu_%E2%80%98on_decouvre_du_sommet_du_Glacier_de_Buet%2C_from_Horace-Benedict_de_Saussure%2C_Voyage_dans_les_Alpes%2C_pr%C3%A9c%C3%A9d%C3%A9s_d%27un_essai_sur_l%27histoire_naturelle_des_environs_de_Geneve._Neuchatel%2C_l779-96%2C_pl._8.jpg/440px-thumbnail.jpg',
        description: 'In geometry, the stereographic projection is a particular mapping (function) that projects a sphere onto a plane. The projection is defined on the entire sphere, except at one point: the projection point. Where it is defined, the mapping is smooth and bijective. It is conformal, meaning that it preserves angles at which curves meet.  It is neither isometric nor area-preserving: that is, it preserves neither distances nor the areas of figures.',
        id: '1017'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1018'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/49/Gimbal_Lock_Plane.gif',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1019'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Gimbal_lock_still_occurs_with_4_axis.png/220px-Gimbal_lock_still_occurs_with_4_axis.png',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1020'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Gimbal_3_axes_rotation.gif/220px-Gimbal_3_axes_rotation.gif',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1021'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/No_gimbal_lock.png/440px-No_gimbal_lock.png',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1022'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Gimbal_lock.png/440px-Gimbal_lock.png',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1023'
        },
        {
        title: 'Gimbal lock ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/8a/Automation_of_foundry_with_robot.jpg',
        description: 'Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, "locking" the system into rotation in a degenerate two-dimensional space.',
        id: '1024'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Triangle.Centroid.svg/440px-Triangle.Centroid.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1025'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Center_gravity_0.svg/294px-Center_gravity_0.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1026'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Center_gravity_1.svg/366px-Center_gravity_1.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1027'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Center_gravity_2.svg/314px-Center_gravity_2.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1028'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/COG_1.svg/400px-COG_1.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1029'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/COG_2.svg/400px-COG_2.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1030'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/COG_3.svg/400px-COG_3.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1031'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/CoG_of_L_shape.svg/600px-CoG_of_L_shape.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1032'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Triangle_centroid_1.svg/332px-Triangle_centroid_1.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1033'
        },
        {
        title: 'Centroid ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Triangle_centroid_2.svg/400px-Triangle_centroid_2.svg.png',
        description: 'In mathematics and physics, the centroid or geometric center of a plane figure is the arithmetic mean position of all the points in the figure. Informally, it is the point at which a cutout of the shape (with uniformly distributed mass) could be perfectly balanced on the tip of a pin.  The same definition extends to any object in n-dimensional space.',
        id: '1034'
        },
        {
        title: 'Euler numbers ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Leonhard_Euler.jpg/180px-Leonhard_Euler.jpg',
        description: 'In mathematics, the Euler numbers are a sequence En of integers (sequence A122045 in the OEIS) defined by the Taylor series expansio',
        id: '1035'
        },
        {
        title: 'Euler numbers ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, the Euler numbers are a sequence En of integers (sequence A122045 in the OEIS) defined by the Taylor series expansio',
        id: '1036'
        },
        {
        title: 'Scale-invariant feature transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Sift_keypoints_filtering.jpg/440px-Sift_keypoints_filtering.jpg',
        description: 'The scale-invariant feature transform (SIFT) is a computer vision algorithm to detect, describe, and match local features in images, invented by David Lowe in 1999.Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual identification of wildlife and match moving.',
        id: '1037'
        },
        {
        title: 'Hough transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/R_theta_line.GIF/213px-R_theta_line.GIF',
        description: 'The Hough transform is a feature extraction technique used in image analysis, computer vision, and digital image processing.  The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform.',
        id: '1038'
        },
        {
        title: 'Hough transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Hough_transform_diagram.svg/1600px-Hough_transform_diagram.svg.png',
        description: 'The Hough transform is a feature extraction technique used in image analysis, computer vision, and digital image processing.  The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform.',
        id: '1039'
        },
        {
        title: 'Hough transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Hough-example-result-en.png/1600px-Hough-example-result-en.png',
        description: 'The Hough transform is a feature extraction technique used in image analysis, computer vision, and digital image processing.  The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform.',
        id: '1040'
        },
        {
        title: 'Hash table ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Hash_table_3_1_1_0_1_0_0_SP.svg/630px-Hash_table_3_1_1_0_1_0_0_SP.svg.png',
        description: 'In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored',
        id: '1041'
        },
        {
        title: 'Hash table ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Hash_table_5_0_1_1_1_1_1_LL.svg/900px-Hash_table_5_0_1_1_1_1_1_LL.svg.png',
        description: 'In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored',
        id: '1042'
        },
        {
        title: 'Hash table ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Hash_table_5_0_1_1_1_1_0_LL.svg/1000px-Hash_table_5_0_1_1_1_1_0_LL.svg.png',
        description: 'In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored',
        id: '1043'
        },
        {
        title: 'Hash table ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Hash_table_5_0_1_1_1_1_0_SP.svg/760px-Hash_table_5_0_1_1_1_1_0_SP.svg.png',
        description: 'In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored',
        id: '1044'
        },
        {
        title: 'Hash table ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Hash_table_average_insertion_time.png/724px-Hash_table_average_insertion_time.png',
        description: 'In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored',
        id: '1045'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Mplwp_factorial_stirling_loglog2.svg/440px-Mplwp_factorial_stirling_loglog2.svg.png',
        description: '',
        id: '1046'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Stirling_series_relative_error.svg/700px-Stirling_series_relative_error.svg.png',
        description: '',
        id: '1047'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Generalized_factorial_function_more_infos.svg/700px-Generalized_factorial_function_more_infos.svg.png',
        description: '',
        id: '1048'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Gamma_abs_3D.png/440px-Gamma_abs_3D.png',
        description: '',
        id: '1049'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Vintage_Texas_Instruments_Model_SR-50A_Handheld_LED_Electronic_Calculator%2C_Made_in_the_USA%2C_Price_Was_%24109.50_in_1975_%288715012843%29.jpg/440px-Vintage_Texas_Instruments_Model_SR-50A_Handheld_LED_Electronic_Calculator%2C_Made_in_the_USA%2C_Price_Was_%24109.50_in_1975_%288715012843%29.jpg',
        description: '',
        id: '1050'
        },
        {
        title: 'Factorial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: '',
        id: '1051'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Partial_transmittance.gif/250px-Partial_transmittance.gif',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1052'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Hospital_corridor_2.jpg/384px-Hospital_corridor_2.jpg',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1053'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Sea_and_Sun_%28cropped%29_2.jpg/384px-Sea_and_Sun_%28cropped%29_2.jpg',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1054'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plane_of_incidence.svg/850px-Plane_of_incidence.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1055'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Fresnel1.svg/600px-Fresnel1.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1056'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Fresnel_power_air-to-glass.svg/440px-Fresnel_power_air-to-glass.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1057'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Fresnel_power_glass-to-air.svg/440px-Fresnel_power_glass-to-air.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1058'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Fresnel_amplitudes_air-to-glass.svg/440px-Fresnel_amplitudes_air-to-glass.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1059'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Fresnel_amplitudes_glass-to-air.svg/440px-Fresnel_amplitudes_glass-to-air.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1060'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Wave_vectors_n1_to_n2.svg/610px-Wave_vectors_n1_to_n2.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1061'
        },
        {
        title: 'Fresnel equations ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg/34px-Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg.png',
        description: 'The Fresnel equations (or Fresnel coefficients) describe the reflection and transmission of light (or electromagnetic radiation in general) when incident on an interface between different optical media. They were deduced by Augustin-Jean Fresnel (/freɪˈnɛl/) who was the first to understand that light is a transverse wave, even though no one realized that the "vibrations" of the wave were electric and magnetic fields. For the first time, polarization could be understood quantitatively, as Fresnels equations correctly predicted the differing behaviour of waves of the s and p polarizations incident upon a material interface.',
        id: '1062'
        },
        {
        title: 'Fourier analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Bass_Guitar_Time_Signal_of_open_string_A_note_%2855_Hz%29.png/800px-Bass_Guitar_Time_Signal_of_open_string_A_note_%2855_Hz%29.png',
        description: '',
        id: '1063'
        },
        {
        title: 'Fourier analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Fourier_Transform_of_bass_guitar_time_signal.png/800px-Fourier_Transform_of_bass_guitar_time_signal.png',
        description: '',
        id: '1064'
        },
        {
        title: 'Fourier analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Fourier_transform%2C_Fourier_series%2C_DTFT%2C_DFT.svg/800px-Fourier_transform%2C_Fourier_series%2C_DTFT%2C_DFT.svg.png',
        description: '',
        id: '1065'
        },
        {
        title: 'Optical flow ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Opticfloweg.png/800px-Opticfloweg.png',
        description: 'Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. Optical flow can also be defined as the distribution of apparent velocities of movement of brightness pattern in an image.[3] The concept of optical flow was introduced by the American psychologist James J. Gibson in the 1940s to describe the visual stimulus provided to animals moving through the world.[4] Gibson stressed the importance of optic flow for affordance perception, the ability to discern possibilities for action within the environment.  Followers of Gibson and his ecological approach to psychology have further demonstrated the role of the optical flow stimulus for the perception of movement by the observer in the world; perception of the shape, distance and movement of objects in the world; and the control of locomotion.[5]',
        id: '1066'
        },
        {
        title: 'Optical flow ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Optical_flow_example_v2.png/440px-Optical_flow_example_v2.png',
        description: 'Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. Optical flow can also be defined as the distribution of apparent velocities of movement of brightness pattern in an image.[3] The concept of optical flow was introduced by the American psychologist James J. Gibson in the 1940s to describe the visual stimulus provided to animals moving through the world.[4] Gibson stressed the importance of optic flow for affordance perception, the ability to discern possibilities for action within the environment.  Followers of Gibson and his ecological approach to psychology have further demonstrated the role of the optical flow stimulus for the perception of movement by the observer in the world; perception of the shape, distance and movement of objects in the world; and the control of locomotion.[5]',
        id: '1067'
        },
        {
        title: 'Scaling (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In Euclidean geometry, uniform scaling (or isotropic scaling) is a linear transformation that enlarges (increases) or shrinks (diminishes) objects by a scale factor that is the same in all directions. The result of uniform scaling is similar (in the geometric sense) to the original.  A scale factor of 1 is normally allowed, so that congruent shapes are also classed as similar.  Uniform scaling happens, for example, when enlarging or reducing a photograph, or when creating a scale model of a building, car, airplane, etc',
        id: '1068'
        },
        {
        title: 'Scaling (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Sierpinski_triangle_evolution.svg/440px-Sierpinski_triangle_evolution.svg.png',
        description: 'In Euclidean geometry, uniform scaling (or isotropic scaling) is a linear transformation that enlarges (increases) or shrinks (diminishes) objects by a scale factor that is the same in all directions. The result of uniform scaling is similar (in the geometric sense) to the original.  A scale factor of 1 is normally allowed, so that congruent shapes are also classed as similar.  Uniform scaling happens, for example, when enlarging or reducing a photograph, or when creating a scale model of a building, car, airplane, etc',
        id: '1069'
        },
        {
        title: 'Scaling (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Sierpinski_triangle_evolution.svg/440px-Sierpinski_triangle_evolution.svg.png',
        description: 'In Euclidean geometry, uniform scaling (or isotropic scaling) is a linear transformation that enlarges (increases) or shrinks (diminishes) objects by a scale factor that is the same in all directions. The result of uniform scaling is similar (in the geometric sense) to the original.  A scale factor of 1 is normally allowed, so that congruent shapes are also classed as similar.  Uniform scaling happens, for example, when enlarging or reducing a photograph, or when creating a scale model of a building, car, airplane, etc',
        id: '1070'
        },
        {
        title: 'Scaling (geometry) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In Euclidean geometry, uniform scaling (or isotropic scaling) is a linear transformation that enlarges (increases) or shrinks (diminishes) objects by a scale factor that is the same in all directions. The result of uniform scaling is similar (in the geometric sense) to the original.  A scale factor of 1 is normally allowed, so that congruent shapes are also classed as similar.  Uniform scaling happens, for example, when enlarging or reducing a photograph, or when creating a scale model of a building, car, airplane, etc',
        id: '1071'
        },
        {
        title: 'Linear span ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Basis_for_a_plane.svg/560px-Basis_for_a_plane.svg.png',
        description: 'In mathematics, the linear span (also called the linear hull or just span) of a set S of vectors (from a vector space), denoted span(S), is the smallest linear subspace that contains the set.[3] It can be characterized either as the intersection of all linear subspaces that contain S, or as the set of linear combinations of elements of S. The linear span of a set of vectors is therefore a vector space. Spans can be generalized to matroids and modules.',
        id: '1072'
        },
        {
        title: 'Linear span ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, the linear span (also called the linear hull or just span) of a set S of vectors (from a vector space), denoted span(S), is the smallest linear subspace that contains the set.[3] It can be characterized either as the intersection of all linear subspaces that contain S, or as the set of linear combinations of elements of S. The linear span of a set of vectors is therefore a vector space. Spans can be generalized to matroids and modules.',
        id: '1073'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Refraction_photo.png/440px-Refraction_photo.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1074'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Refraction_at_interface.svg/340px-Refraction_at_interface.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1075'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Thomas_Young_%28scientist%29.jpg/240px-Thomas_Young_%28scientist%29.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1076'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Brillanten.jpg/440px-Brillanten.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1077'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Split-ring_resonator_array_10K_sq_nm.jpg/250px-Split-ring_resonator_array_10K_sq_nm.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1078'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Thin_section_scan_crossed_polarizers_Siilinj%C3%A4rvi_R636-105.90.jpg/440px-Thin_section_scan_crossed_polarizers_Siilinj%C3%A4rvi_R636-105.90.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1079'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/WhereRainbowRises.jpg/300px-WhereRainbowRises.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1080'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Prism-rainbow.svg/440px-Prism-rainbow.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1081'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Mplwp_dispersion_curves.svg/640px-Mplwp_dispersion_curves.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1082'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Soap_bubble_sky.jpg/440px-Soap_bubble_sky.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1083'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Snells_law.svg/440px-Snells_law.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1084'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Total_internal_reflection_of_Chelonia_mydas.jpg/440px-Total_internal_reflection_of_Chelonia_mydas.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1085'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Lupa.na.encyklopedii.jpg/440px-Lupa.na.encyklopedii.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1086'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/3/3b/Density-nd.GIF/740px-Density-nd.GIF',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1087'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Calcite.jpg/440px-Calcite.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1088'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Plastic_Protractor_Polarized_05375.jpg/440px-Plastic_Protractor_Polarized_05375.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1089'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/2c/Grin-lens.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1090'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pulfrich_refraktometer_en.png/440px-Pulfrich_refraktometer_en.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1091'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Refractometer.jpg/440px-Refractometer.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1092'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/S_cerevisiae_under_DIC_microscopy.jpg/440px-S_cerevisiae_under_DIC_microscopy.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1093'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1094'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg/34px-Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1095'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Dragon-149393.svg/37px-Dragon-149393.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1096'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/38px-Nuvola_apps_kalzium.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1097'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/38px-Telecom-icon.svg.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1098'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Helmet_logo_for_Underwater_Diving_portal.png/27px-Helmet_logo_for_Underwater_Diving_portal.png',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1099'
        },
        {
        title: 'Refractive index ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Am%C3%A9thystre_sceptre2.jpg/31px-Am%C3%A9thystre_sceptre2.jpg',
        description: 'In optics, the refractive index (also known as refraction index or index of refraction) of a material is a dimensionless number that describes how fast light  travels through the material. It is defined as',
        id: '1100'
        },
        {
        title: 'Median filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Median_filter_example.jpg/400px-Median_filter_example.jpg',
        description: 'The median filter is a non-linear digital filtering technique, often used to remove noise from an image or signal. Such noise reduction is a typical pre-processing step to improve the results of later processing (for example, edge detection on an image). Median filtering is very widely used in digital image processing because, under certain conditions, it preserves edges while removing noise (but see the discussion below), also having applications in signal processing.',
        id: '1101'
        },
        {
        title: 'Median filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/1d/Medianfilterp.png',
        description: 'The median filter is a non-linear digital filtering technique, often used to remove noise from an image or signal. Such noise reduction is a typical pre-processing step to improve the results of later processing (for example, edge detection on an image). Median filtering is very widely used in digital image processing because, under certain conditions, it preserves edges while removing noise (but see the discussion below), also having applications in signal processing.',
        id: '1102'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Valve_original_%281%29.PNG/600px-Valve_original_%281%29.PNG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1103'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Valve_sobel_%283%29.PNG/600px-Valve_sobel_%283%29.PNG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1104'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Bikesgray.jpg/400px-Bikesgray.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1105'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Bikesgraysobel.jpg/400px-Bikesgraysobel.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1106'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Bikesgraygv.jpg/400px-Bikesgraygv.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1107'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Bikesgraygh.jpg/400px-Bikesgraygh.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1108'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Black_Circle.jpg/300px-Black_Circle.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1109'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Sobel_Operator_Gradient_Angle.JPG/360px-Sobel_Operator_Gradient_Angle.JPG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1110'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Bikesgray.jpg/400px-Bikesgray.jpg',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1111'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Bikesgray_sobel.JPG/400px-Bikesgray_sobel.JPG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1112'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Bikesgray-scharr.png/400px-Bikesgray-scharr.png',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1113'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Bikesgray_roberts.JPG/400px-Bikesgray_roberts.JPG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1114'
        },
        {
        title: 'Sobel operator ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Bikesgray_prewitt.JPG/400px-Bikesgray_prewitt.JPG',
        description: 'The Sobel operator, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an "Isotropic 3 × 3 Image Gradient Operator" at a talk at SAIL in 1968. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image.',
        id: '1115'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/4b/Fractal_fern_explained.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1116'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Checkerboard_identity.svg/320px-Checkerboard_identity.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1117'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Checkerboard_identity.svg/320px-Checkerboard_identity.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1118'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Checkerboard_reflection.svg/320px-Checkerboard_reflection.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1119'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Checkerboard_scale.svg/480px-Checkerboard_scale.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1120'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Checkerboard_rotate.svg/320px-Checkerboard_rotate.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1121'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Checkerboard_shear.svg/320px-Checkerboard_shear.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1122'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/a/a7/White_on_black_circle_image_256_by_256.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1123'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/7/7a/Affine_transform_sheared_circle.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1124'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Central_dilation.svg/600px-Central_dilation.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1125'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Geometric_affine_transformation_example.png/440px-Geometric_affine_transformation_example.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1126'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/2D_affine_transformation_matrix.svg/500px-2D_affine_transformation_matrix.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1127'
        },
        {
        title: 'Affine transformation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).',
        id: '1128'
        },
        {
        title: 'Quadtree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Point_quadtree.svg/600px-Point_quadtree.svg.png',
        description: 'A quadtree is a tree data structure in which each internal node has exactly four children. Quadtrees are the two-dimensional analog of octrees and are most often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. The data associated with a leaf cell varies by application, but the leaf cell represents a "unit of interesting spatial information".',
        id: '1129'
        },
        {
        title: 'Quadtree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Quadtree_compression_of_an_image.gif/600px-Quadtree_compression_of_an_image.gif',
        description: 'A quadtree is a tree data structure in which each internal node has exactly four children. Quadtrees are the two-dimensional analog of octrees and are most often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. The data associated with a leaf cell varies by application, but the leaf cell represents a "unit of interesting spatial information".',
        id: '1130'
        },
        {
        title: 'Quadtree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Quad_tree_bitmap.svg/760px-Quad_tree_bitmap.svg.png',
        description: 'A quadtree is a tree data structure in which each internal node has exactly four children. Quadtrees are the two-dimensional analog of octrees and are most often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. The data associated with a leaf cell varies by application, but the leaf cell represents a "unit of interesting spatial information".',
        id: '1131'
        },
        {
        title: 'Quadtree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Fig-mesh-gen-balanced-leaves.svg/440px-Fig-mesh-gen-balanced-leaves.svg.png',
        description: 'A quadtree is a tree data structure in which each internal node has exactly four children. Quadtrees are the two-dimensional analog of octrees and are most often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. The data associated with a leaf cell varies by application, but the leaf cell represents a "unit of interesting spatial information".',
        id: '1132'
        },
        {
        title: 'UV mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/04/UVMapping.png',
        description: 'UV mapping is the 3D modeling process of projecting a 2D image to a 3D models surface for texture mapping. The letters "U" and "V" denote the axes of the 2D texture because "X", "Y", and "Z" are already used to denote the axes of the 3D object in model space, while "W" (in addition to XYZ) is used in calculating quaternion rotations, a common operation in computer graphics.',
        id: '1133'
        },
        {
        title: 'UV mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Cube_Representative_UV_Unwrapping.png/440px-Cube_Representative_UV_Unwrapping.png',
        description: 'UV mapping is the 3D modeling process of projecting a 2D image to a 3D models surface for texture mapping. The letters "U" and "V" denote the axes of the 2D texture because "X", "Y", and "Z" are already used to denote the axes of the 3D object in model space, while "W" (in addition to XYZ) is used in calculating quaternion rotations, a common operation in computer graphics.',
        id: '1134'
        },
        {
        title: 'UV mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/UV_mapping_checkered_sphere.png/440px-UV_mapping_checkered_sphere.png',
        description: 'UV mapping is the 3D modeling process of projecting a 2D image to a 3D models surface for texture mapping. The letters "U" and "V" denote the axes of the 2D texture because "X", "Y", and "Z" are already used to denote the axes of the 3D object in model space, while "W" (in addition to XYZ) is used in calculating quaternion rotations, a common operation in computer graphics.',
        id: '1135'
        },
        {
        title: 'UV mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/UV_checker_Map_byValle.jpg/440px-UV_checker_Map_byValle.jpg',
        description: 'UV mapping is the 3D modeling process of projecting a 2D image to a 3D models surface for texture mapping. The letters "U" and "V" denote the axes of the 2D texture because "X", "Y", and "Z" are already used to denote the axes of the 3D object in model space, while "W" (in addition to XYZ) is used in calculating quaternion rotations, a common operation in computer graphics.',
        id: '1136'
        },
        {
        title: 'Color quantization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e3/Dithering_example_undithered.png',
        description: 'In computer graphics, color quantization or color image quantization is quantization applied to color spaces; it is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image. Computer algorithms to perform color quantization on bitmaps have been studied since the 1970s. Color quantization is critical for displaying images with many colors on devices that can only display a limited number of colors, usually due to memory limitations, and enables efficient compression of certain types of images.',
        id: '1137'
        },
        {
        title: 'Color quantization ',
        url: 'https://upload.wikimedia.org/wikipedia/en/4/48/Dithering_example_undithered_16color_palette.png',
        description: 'In computer graphics, color quantization or color image quantization is quantization applied to color spaces; it is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image. Computer algorithms to perform color quantization on bitmaps have been studied since the 1970s. Color quantization is critical for displaying images with many colors on devices that can only display a limited number of colors, usually due to memory limitations, and enables efficient compression of certain types of images.',
        id: '1138'
        },
        {
        title: 'Color quantization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/82/Rosa_Gold_Glow_2_small_noblue.png',
        description: 'In computer graphics, color quantization or color image quantization is quantization applied to color spaces; it is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image. Computer algorithms to perform color quantization on bitmaps have been studied since the 1970s. Color quantization is critical for displaying images with many colors on devices that can only display a limited number of colors, usually due to memory limitations, and enables efficient compression of certain types of images.',
        id: '1139'
        },
        {
        title: 'Color quantization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Rosa_Gold_Glow_2_small_noblue_color_space.png/600px-Rosa_Gold_Glow_2_small_noblue_color_space.png',
        description: 'In computer graphics, color quantization or color image quantization is quantization applied to color spaces; it is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image. Computer algorithms to perform color quantization on bitmaps have been studied since the 1970s. Color quantization is critical for displaying images with many colors on devices that can only display a limited number of colors, usually due to memory limitations, and enables efficient compression of certain types of images.',
        id: '1140'
        },
        {
        title: 'Color quantization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c5/Spatial_color_quantization_-_rainbow%2C_4_colors.png',
        description: 'In computer graphics, color quantization or color image quantization is quantization applied to color spaces; it is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image. Computer algorithms to perform color quantization on bitmaps have been studied since the 1970s. Color quantization is critical for displaying images with many colors on devices that can only display a limited number of colors, usually due to memory limitations, and enables efficient compression of certain types of images.',
        id: '1141'
        },
        {
        title: 'Gift wrapping algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/9c/Animation_depicting_the_gift_wrapping_algorithm.gif',
        description: 'In computational geometry, the gift wrapping algorithm is an algorithm for computing the convex hull of a given set of points.',
        id: '1142'
        },
        {
        title: 'Gift wrapping algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Jarvis_march_convex_hull_algorithm_diagram.svg/560px-Jarvis_march_convex_hull_algorithm_diagram.svg.png',
        description: 'In computational geometry, the gift wrapping algorithm is an algorithm for computing the convex hull of a given set of points.',
        id: '1143'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Valve_monochrome_canny_%286%29.PNG/400px-Valve_monochrome_canny_%286%29.PNG',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1144'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Valve_original_%281%29.PNG/400px-Valve_original_%281%29.PNG',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1145'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Valve_gaussian_%282%29.PNG/400px-Valve_gaussian_%282%29.PNG',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1146'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/%C3%84%C3%A4retuvastuse_n%C3%A4ide.png/800px-%C3%84%C3%A4retuvastuse_n%C3%A4ide.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1147'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Large_Scaled_Forest_Lizard.jpg/400px-Large_Scaled_Forest_Lizard.jpg',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1148'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Canny_Walkthrough_1_Gaussian_Blur.png/400px-Canny_Walkthrough_1_Gaussian_Blur.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1149'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Canny_Walkthrough_2_Intensity_Gradient.png/400px-Canny_Walkthrough_2_Intensity_Gradient.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1150'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Canny_Walkthrough_3_Non-maximum_suppression.png/400px-Canny_Walkthrough_3_Non-maximum_suppression.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1151'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Canny_Walkthrough_4_Double_Threshold.png/400px-Canny_Walkthrough_4_Double_Threshold.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1152'
        },
        {
        title: 'Canny edge detector ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Canny_Walkthrough_5_Hysteresis.png/400px-Canny_Walkthrough_5_Hysteresis.png',
        description: 'The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.',
        id: '1153'
        },
        {
        title: 'Difference of Gaussians ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/DOG_vs_MHF.png/300px-DOG_vs_MHF.png',
        description: 'In imaging science, difference of Gaussians (DoG) is a feature enhancement algorithm that involves the subtraction of one Gaussian blurred version of an original image from another, less blurred version of the original. In the simple case of grayscale images, the blurred images are obtained by convolving the original grayscale images with Gaussian kernels having differing width (standard deviations). Blurring an image using a Gaussian kernel suppresses only high-frequency spatial information. Subtracting one image from the other preserves spatial information that lies between the range of frequencies that are preserved in the two blurred images. Thus, the DoG is a spatial band-pass filter that attenuates frequencies in the original grayscale image that are far from the band center.',
        id: '1154'
        },
        {
        title: 'Difference of Gaussians ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Flowers_before_difference_of_gaussians.jpg/300px-Flowers_before_difference_of_gaussians.jpg',
        description: 'In imaging science, difference of Gaussians (DoG) is a feature enhancement algorithm that involves the subtraction of one Gaussian blurred version of an original image from another, less blurred version of the original. In the simple case of grayscale images, the blurred images are obtained by convolving the original grayscale images with Gaussian kernels having differing width (standard deviations). Blurring an image using a Gaussian kernel suppresses only high-frequency spatial information. Subtracting one image from the other preserves spatial information that lies between the range of frequencies that are preserved in the two blurred images. Thus, the DoG is a spatial band-pass filter that attenuates frequencies in the original grayscale image that are far from the band center.',
        id: '1155'
        },
        {
        title: 'Difference of Gaussians ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Flowers_after_difference_of_gaussians_grayscale.jpg/300px-Flowers_after_difference_of_gaussians_grayscale.jpg',
        description: 'In imaging science, difference of Gaussians (DoG) is a feature enhancement algorithm that involves the subtraction of one Gaussian blurred version of an original image from another, less blurred version of the original. In the simple case of grayscale images, the blurred images are obtained by convolving the original grayscale images with Gaussian kernels having differing width (standard deviations). Blurring an image using a Gaussian kernel suppresses only high-frequency spatial information. Subtracting one image from the other preserves spatial information that lies between the range of frequencies that are preserved in the two blurred images. Thus, the DoG is a spatial band-pass filter that attenuates frequencies in the original grayscale image that are far from the band center.',
        id: '1156'
        },
        {
        title: 'Constructive solid geometry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Csg_tree.png/600px-Csg_tree.png',
        description: 'Constructive solid geometry (CSG; formerly called computational binary solid geometry) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine simpler objects, potentially generating visually complex objects by combining a few primitive ones.[3]',
        id: '1157'
        },
        {
        title: 'Constructive solid geometry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Boolean_union.PNG/240px-Boolean_union.PNG',
        description: 'Constructive solid geometry (CSG; formerly called computational binary solid geometry) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine simpler objects, potentially generating visually complex objects by combining a few primitive ones.[3]',
        id: '1158'
        },
        {
        title: 'Constructive solid geometry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Boolean_difference.PNG/240px-Boolean_difference.PNG',
        description: 'Constructive solid geometry (CSG; formerly called computational binary solid geometry) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine simpler objects, potentially generating visually complex objects by combining a few primitive ones.[3]',
        id: '1159'
        },
        {
        title: 'Constructive solid geometry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Boolean_intersect.PNG/240px-Boolean_intersect.PNG',
        description: 'Constructive solid geometry (CSG; formerly called computational binary solid geometry) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine simpler objects, potentially generating visually complex objects by combining a few primitive ones.[3]',
        id: '1160'
        },
        {
        title: 'Constructive solid geometry ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Boolean_raytrace.svg/550px-Boolean_raytrace.svg.png',
        description: 'Constructive solid geometry (CSG; formerly called computational binary solid geometry) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine simpler objects, potentially generating visually complex objects by combining a few primitive ones.[3]',
        id: '1161'
        },
        {
        title: 'Bounding volume ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/BoundingBox.jpg/220px-BoundingBox.jpg',
        description: 'In computer graphics and computational geometry, a bounding volume for a set of objects is a closed volume that completely contains the union of the objects in the set. Bounding volumes are used to improve the efficiency of geometrical operations by using simple volumes to contain more complex objects. Normally, simpler volumes have simpler ways to test for overlap.',
        id: '1162'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1163'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Klein_bottle.svg/480px-Klein_bottle.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1164'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Surface_of_Klein_bottle_with_traced_line.svg/300px-Surface_of_Klein_bottle_with_traced_line.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1165'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Klein_Bottle_Folding_1.svg/300px-Klein_Bottle_Folding_1.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1166'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Klein_Bottle_Folding_1.svg/240px-Klein_Bottle_Folding_1.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1167'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Klein_Bottle_Folding_2.svg/120px-Klein_Bottle_Folding_2.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1168'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Klein_Bottle_Folding_3.svg/180px-Klein_Bottle_Folding_3.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1169'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Klein_Bottle_Folding_4.svg/180px-Klein_Bottle_Folding_4.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1170'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Klein_Bottle_Folding_5.svg/180px-Klein_Bottle_Folding_5.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1171'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Klein_Bottle_Folding_6.svg/180px-Klein_Bottle_Folding_6.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1172'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Science_Museum_London_1110529_nevit.jpg/300px-Science_Museum_London_1110529_nevit.jpg',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1173'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Acme_klein_bottle.jpg/300px-Acme_klein_bottle.jpg',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1174'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/24/Klein_bottle_time_evolution_in_xyzt-space.gif',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1175'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Klein_bottle_colouring.svg/340px-Klein_bottle_colouring.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1176'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/KleinBottle-cut.svg/300px-KleinBottle-cut.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1177'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/KleinBottle-Figure8-01.svg/440px-KleinBottle-Figure8-01.svg.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1178'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Kleinbagel_cross_section.png/220px-Kleinbagel_cross_section.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1179'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Pinched_Torus_Klein_bottle.jpg/440px-Pinched_Torus_Klein_bottle.jpg',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1180'
        },
        {
        title: 'Klein bottle ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Klein_bottle_translucent.png/440px-Klein_bottle_translucent.png',
        description: 'In topology, a branch of mathematics, the Klein bottle (/ˈklaɪn/) is an example of a non-orientable surface; it is a two-dimensional manifold against which a system for determining a normal vector cannot be consistently defined.  Informally, it is a one-sided surface which, if traveled upon, could be followed back to the point of origin while flipping the traveler upside down.  Other related non-orientable objects include the Möbius strip and the real projective plane. While a Möbius strip is a surface with boundary, a Klein bottle has no boundary. For comparison, a sphere is an orientable surface with no boundary.',
        id: '1181'
        },
        {
        title: 'Persistence of vision ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/LED_rotor_display.jpg/440px-LED_rotor_display.jpg',
        description: 'Persistence of vision traditionally refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye.     The illusion has also been described as "retinal persistence", "persistence of impressions",[3] simply "persistence" and other variations. A very commonly given example of the phenomenon is the appearant fiery trail of a glowing coal or burning stick while it is whirled around in the dark.',
        id: '1182'
        },
        {
        title: 'Persistence of vision ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/42/1820-12-01_j.m._-_an_optical_deception_-_wood-cut.jpg',
        description: 'Persistence of vision traditionally refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye.     The illusion has also been described as "retinal persistence", "persistence of impressions",[3] simply "persistence" and other variations. A very commonly given example of the phenomenon is the appearant fiery trail of a glowing coal or burning stick while it is whirled around in the dark.',
        id: '1183'
        },
        {
        title: 'Persistence of vision ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/1824_roget.jpg/440px-1824_roget.jpg',
        description: 'Persistence of vision traditionally refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye.     The illusion has also been described as "retinal persistence", "persistence of impressions",[3] simply "persistence" and other variations. A very commonly given example of the phenomenon is the appearant fiery trail of a glowing coal or burning stick while it is whirled around in the dark.',
        id: '1184'
        },
        {
        title: 'Persistence of vision ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Illustrations_of_Michael_Faraday%27s_paper_%22On_a_Peculiar_Class_of_Optical_Deceptions%22_%281831%29.jpg/440px-Illustrations_of_Michael_Faraday%27s_paper_%22On_a_Peculiar_Class_of_Optical_Deceptions%22_%281831%29.jpg',
        description: 'Persistence of vision traditionally refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye.     The illusion has also been described as "retinal persistence", "persistence of impressions",[3] simply "persistence" and other variations. A very commonly given example of the phenomenon is the appearant fiery trail of a glowing coal or burning stick while it is whirled around in the dark.',
        id: '1185'
        },
        {
        title: 'Persistence of vision ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Optical_Illustion-Ambiguous_Patterns.svg/60px-Optical_Illustion-Ambiguous_Patterns.svg.png',
        description: 'Persistence of vision traditionally refers to the optical illusion that occurs when visual perception of an object does not cease for some time after the rays of light proceeding from it have ceased to enter the eye.     The illusion has also been described as "retinal persistence", "persistence of impressions",[3] simply "persistence" and other variations. A very commonly given example of the phenomenon is the appearant fiery trail of a glowing coal or burning stick while it is whirled around in the dark.',
        id: '1186'
        },
        {
        title: 'Scanline rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Scan-line_algorithm.svg/440px-Scan-line_algorithm.svg.png',
        description: 'Scanline rendering (also scan line rendering and scan-line rendering) is an algorithm for visible surface determination, in 3D computer graphics, that works on a row-by-row basis rather than a polygon-by-polygon or pixel-by-pixel basis.  All of the polygons to be rendered are first sorted by the top y coordinate at which they first appear, then each row or scan line of the image is computed using the intersection of a scanline with the polygons on the front of the sorted list, while the sorted list is updated to discard no-longer-visible polygons as the active scan line is advanced down the picture.',
        id: '1187'
        },
        {
        title: 'Barycentric coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Barycentric_subdivision_of_a_3-simplex.png/440px-Barycentric_subdivision_of_a_3-simplex.png',
        description: 'In geometry, a barycentric coordinate system is a coordinate system in which the location of a point is specified by reference to a simplex (a triangle for points in a plane, a tetrahedron for points in three-dimensional space, etc.). The barycentric coordinates of a point can be interpreted as masses placed at the vertices of the simplex, such that the point is the center of mass (or barycenter) of these masses. These masses can be zero or negative; they are all positive if and only if the point is inside the simplex.',
        id: '1188'
        },
        {
        title: 'Barycentric coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/TriangleBarycentricCoordinates.svg/640px-TriangleBarycentricCoordinates.svg.png',
        description: 'In geometry, a barycentric coordinate system is a coordinate system in which the location of a point is specified by reference to a simplex (a triangle for points in a plane, a tetrahedron for points in three-dimensional space, etc.). The barycentric coordinates of a point can be interpreted as masses placed at the vertices of the simplex, such that the point is the center of mass (or barycenter) of these masses. These masses can be zero or negative; they are all positive if and only if the point is inside the simplex.',
        id: '1189'
        },
        {
        title: 'Barycentric coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/3_jugs_puzzle_barycentric_plot.svg/500px-3_jugs_puzzle_barycentric_plot.svg.png',
        description: 'In geometry, a barycentric coordinate system is a coordinate system in which the location of a point is specified by reference to a simplex (a triangle for points in a plane, a tetrahedron for points in three-dimensional space, etc.). The barycentric coordinates of a point can be interpreted as masses placed at the vertices of the simplex, such that the point is the center of mass (or barycenter) of these masses. These masses can be zero or negative; they are all positive if and only if the point is inside the simplex.',
        id: '1190'
        },
        {
        title: 'Barycentric coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Piecewise_linear_function2D.svg/600px-Piecewise_linear_function2D.svg.png',
        description: 'In geometry, a barycentric coordinate system is a coordinate system in which the location of a point is specified by reference to a simplex (a triangle for points in a plane, a tetrahedron for points in three-dimensional space, etc.). The barycentric coordinates of a point can be interpreted as masses placed at the vertices of the simplex, such that the point is the center of mass (or barycenter) of these masses. These masses can be zero or negative; they are all positive if and only if the point is inside the simplex.',
        id: '1191'
        },
        {
        title: 'Barycentric coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In geometry, a barycentric coordinate system is a coordinate system in which the location of a point is specified by reference to a simplex (a triangle for points in a plane, a tetrahedron for points in three-dimensional space, etc.). The barycentric coordinates of a point can be interpreted as masses placed at the vertices of the simplex, such that the point is the center of mass (or barycenter) of these masses. These masses can be zero or negative; they are all positive if and only if the point is inside the simplex.',
        id: '1192'
        },
        {
        title: 'Phong shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Phong-shading-sample_%28cropped%29.jpg/580px-Phong-shading-sample_%28cropped%29.jpg',
        description: 'In 3D computer graphics, Phong shading, Phong interpolation, or normal-vector interpolation shading is an interpolation technique for surface shading invented by computer graphics pioneer Bui Tuong Phong. Phong shading interpolates surface normals across rasterized polygons and computes pixel colors based on the interpolated normals and a reflection model. Phong shading may also refer to the specific combination of Phong interpolation and the Phong reflection model.',
        id: '1193'
        },
        {
        title: 'Phong shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6d/Activemarker2.PNG',
        description: 'In 3D computer graphics, Phong shading, Phong interpolation, or normal-vector interpolation shading is an interpolation technique for surface shading invented by computer graphics pioneer Bui Tuong Phong. Phong shading interpolates surface normals across rasterized polygons and computes pixel colors based on the interpolated normals and a reflection model. Phong shading may also refer to the specific combination of Phong interpolation and the Phong reflection model.',
        id: '1194'
        },
        {
        title: 'Phong shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Phong_components_version_4.png/655px-Phong_components_version_4.png',
        description: 'In 3D computer graphics, Phong shading, Phong interpolation, or normal-vector interpolation shading is an interpolation technique for surface shading invented by computer graphics pioneer Bui Tuong Phong. Phong shading interpolates surface normals across rasterized polygons and computes pixel colors based on the interpolated normals and a reflection model. Phong shading may also refer to the specific combination of Phong interpolation and the Phong reflection model.',
        id: '1195'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Subpixel_rendering.png/300px-Subpixel_rendering.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1196'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Subpixel_demonstration_%28Quartz%29.png/600px-Subpixel_demonstration_%28Quartz%29.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1197'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Pixel_geometry_01_Pengo.jpg/440px-Pixel_geometry_01_Pengo.jpg',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1198'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b2/SubPixel.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1199'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/da/SubPixel.gif',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1200'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/57/Subpixel-rendering-RGB.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1201'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1202'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Subpixel_arrangement-RGB-GBR.svg/146px-Subpixel_arrangement-RGB-GBR.svg.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1203'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Subpixel_arrangement-RG-B-GR.svg/146px-Subpixel_arrangement-RG-B-GR.svg.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1204'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Subpixel_rendering_LCD_photo_3e_composite.jpg/400px-Subpixel_rendering_LCD_photo_3e_composite.jpg',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1205'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Subpixel_Rendering_LCD_photo_3is_composite.jpg/400px-Subpixel_Rendering_LCD_photo_3is_composite.jpg',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1206'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Subpixel_rendering_LCD_photo_3w_composite.jpg/400px-Subpixel_rendering_LCD_photo_3w_composite.jpg',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1207'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/f3/Subpixel_e.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1208'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/19/Subpixel_is.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1209'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/eb/Subpixel_w.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1210'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Subpixel-Renderingactivated.JPG/600px-Subpixel-Renderingactivated.JPG',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1211'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Subpixel-RenderingDEactivated.JPG/600px-Subpixel-RenderingDEactivated.JPG',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1212'
        },
        {
        title: 'Subpixel rendering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/LCD_RGB_Subpixel-Accurate_Gradient.png/498px-LCD_RGB_Subpixel-Accurate_Gradient.png',
        description: 'Subpixel rendering is a way to increase the apparent resolution of a computers liquid crystal display (LCD) or organic light-emitting diode (OLED) display by rendering pixels to take into account the screen types physical properties. It takes advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue or other color subpixels to anti-alias text with greater detail or to increase the resolution of all image types on layouts which are specifically designed to be compatible with subpixel rendering.',
        id: '1213'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1214'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6d/Activemarker2.PNG',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1215'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Direct_lighting.png/400px-Direct_lighting.png',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1216'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Global_illumination1.png/400px-Global_illumination1.png',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1217'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Alexexterior2.jpg/440px-Alexexterior2.jpg',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1218'
        },
        {
        title: 'Global illumination ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Show_how_3D_real_time_ambient_occlusion_works_2013-11-23_10-45.jpeg/340px-Show_how_3D_real_time_ambient_occlusion_works_2013-11-23_10-45.jpeg',
        description: 'Global illumination (GI), or indirect illumination, is a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light that comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).',
        id: '1219'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Area_parallellogram_as_determinant.svg/440px-Area_parallellogram_as_determinant.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1220'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Determinant_parallelepiped.svg/600px-Determinant_parallelepiped.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1221'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Schema_sarrus-regel.png/400px-Schema_sarrus-regel.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1222'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Jacobian_determinant_and_distortion.svg/700px-Jacobian_determinant_and_distortion.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1223'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Determinant_as_a_natural_transformation.svg/600px-Determinant_as_a_natural_transformation.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1224'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1225'
        },
        {
        title: 'Determinant ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics, the determinant is a scalar value that is a function of the entries of a square matrix. It allows characterizing some properties of the matrix and the linear map represented by the matrix. In particular, the determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism. The determinant of a product of matrices is the product of their determinants (the preceding property is a corollary of this one).    The determinant of a matrix A is denoted det(A), det A, or |A|.',
        id: '1226'
        },
        {
        title: 'Tessellation (computer graphics) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Tesselation_pipeline.svg/580px-Tesselation_pipeline.svg.png',
        description: 'In computer graphics, tessellation refers to the dividing of datasets of polygons (sometimes called vertex sets) presenting objects in a scene into suitable structures for rendering. Especially for real-time rendering, data is tessellated into triangles, for example in OpenGL 4.0 and Direct3D 11.',
        id: '1227'
        },
        {
        title: 'Tensor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Components_stress_tensor.svg/600px-Components_stress_tensor.svg.png',
        description: 'In mathematics, a tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors. There are many types of tensors, including scalars and vectors (which are the simplest tensors), dual vectors, multilinear maps between vector spaces, and even some operations such as the dot product. Tensors are defined independent of any basis, although they are often referred to by their components in a basis related to a particular coordinate system.',
        id: '1228'
        },
        {
        title: 'Tensor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/N_vector_positive.svg/440px-N_vector_positive.svg.png',
        description: 'In mathematics, a tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors. There are many types of tensors, including scalars and vectors (which are the simplest tensors), dual vectors, multilinear maps between vector spaces, and even some operations such as the dot product. Tensors are defined independent of any basis, although they are often referred to by their components in a basis related to a particular coordinate system.',
        id: '1229'
        },
        {
        title: 'Tensor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/N_vector_negative.svg/440px-N_vector_negative.svg.png',
        description: 'In mathematics, a tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors. There are many types of tensors, including scalars and vectors (which are the simplest tensors), dual vectors, multilinear maps between vector spaces, and even some operations such as the dot product. Tensors are defined independent of any basis, although they are often referred to by their components in a basis related to a particular coordinate system.',
        id: '1230'
        },
        {
        title: 'Bézier surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/B%C3%A9zier_surface_example.svg/600px-B%C3%A9zier_surface_example.svg.png',
        description: 'Bézier surfaces are a species of mathematical spline used in computer graphics, computer-aided design, and finite element modeling.     As with Bézier curves, a Bézier surface is defined by a set of control points. Similar to interpolation in many respects, a key difference is that the surface does not, in general, pass through the central control points; rather, it  is "stretched" toward them as though each were an attractive force. They are  visually intuitive, and for many applications, mathematically convenient.',
        id: '1231'
        },
        {
        title: 'Bézier surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Bicubic_Patches.png/500px-Bicubic_Patches.png',
        description: 'Bézier surfaces are a species of mathematical spline used in computer graphics, computer-aided design, and finite element modeling.     As with Bézier curves, a Bézier surface is defined by a set of control points. Similar to interpolation in many respects, a key difference is that the surface does not, in general, pass through the central control points; rather, it  is "stretched" toward them as though each were an attractive force. They are  visually intuitive, and for many applications, mathematically convenient.',
        id: '1232'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Bezier_curve.svg/440px-Bezier_curve.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1233'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Bezier_basis.svg/440px-Bezier_basis.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1234'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Quadratic_Beziers_in_string_art.svg/340px-Quadratic_Beziers_in_string_art.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1235'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Quadratic_to_cubic_Bezier_curve.svg/340px-Quadratic_to_cubic_Bezier_curve.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1236'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Quadratic_Bezier_parabola_equivalence.svg/340px-Quadratic_Bezier_parabola_equivalence.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1237'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/B%C3%A9zier_1_big.gif/240px-B%C3%A9zier_1_big.gif',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1238'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/B%C3%A9zier_2_big.svg/480px-B%C3%A9zier_2_big.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1239'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/B%C3%A9zier_2_big.gif/240px-B%C3%A9zier_2_big.gif',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1240'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/B%C3%A9zier_3_big.svg/480px-B%C3%A9zier_3_big.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1241'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/B%C3%A9zier_3_big.gif/240px-B%C3%A9zier_3_big.gif',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1242'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/B%C3%A9zier_4_big.svg/480px-B%C3%A9zier_4_big.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1243'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/B%C3%A9zier_4_big.gif/240px-B%C3%A9zier_4_big.gif',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1244'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0b/BezierCurve.gif',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1245'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Rational_Bezier_curve-conic_sections.svg/440px-Rational_Bezier_curve-conic_sections.svg.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1246'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b8/B%C3%A9zier_curve_in_Adobe_Illustrator_CS2.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1247'
        },
        {
        title: 'Bézier curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Bezier_curves_composition_ray-traced_in_3D.png/440px-Bezier_curves_composition_ray-traced_in_3D.png',
        description: 'A Bézier curve (/ˈbɛz.i.eɪ/ BEH-zee-ay) is a parametric curve used in computer graphics and related fields. A set of discrete "control points" defines a smooth, continuous curve by means of a formula. Usually the curve is intended to approximate a real-world shape that otherwise has no mathematical representation or whose representation is unknown or too complicated. Bézier curve is named after French engineer Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars.[3] Other uses include the design of computer fonts and animation.[3] Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces.[3] The Bézier triangle is a special case of the latter.',
        id: '1248'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Catmull-Clark_subdivision_of_a_cube.svg/440px-Catmull-Clark_subdivision_of_a_cube.svg.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1249'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Catmull-Clark_limit_surface_of_Cube_%28compare_sphere%29.png/440px-Catmull-Clark_limit_surface_of_Cube_%28compare_sphere%29.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1250'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Catmull-Clark_Recursive_Step_1.png/440px-Catmull-Clark_Recursive_Step_1.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1251'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Catmull-Clark_Recursive_Step_2.png/440px-Catmull-Clark_Recursive_Step_2.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1252'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Catmull-Clark_Recursive_Step_3.png/440px-Catmull-Clark_Recursive_Step_3.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1253'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Catmull-Clark_Recursive_Step_4.png/440px-Catmull-Clark_Recursive_Step_4.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1254'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Catmull-Clark_Recursive_Step_5.png/440px-Catmull-Clark_Recursive_Step_5.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1255'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Catmull-Clark_recursive_step_6.png/440px-Catmull-Clark_recursive_step_6.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1256'
        },
        {
        title: 'Catmull–Clark subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The Catmull–Clark algorithm is a technique used in 3D computer graphics to create curved surfaces by using subdivision surface modeling. It was devised by Edwin Catmull and Jim Clark in 1978 as a generalization of bi-cubic uniform B-spline surfaces to arbitrary topology.',
        id: '1257'
        },
        {
        title: 'Inverse kinematics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/FWDvsINV_Kinematics_HighResTransp.png/700px-FWDvsINV_Kinematics_HighResTransp.png',
        description: 'In computer animation and robotics, inverse kinematics is the mathematical process of calculating the variable joint parameters needed to place the end of a kinematic chain, such as a robot manipulator or animation characters skeleton, in a given position and orientation relative to the start of the chain. Given joint parameters, the position and orientation of the chains end, e.g. the hand of the character or robot, can typically be calculated directly using multiple applications of trigonometric formulas, a process known as forward kinematics. However, the reverse operation is, in general, much more challenging.',
        id: '1258'
        },
        {
        title: 'Inverse kinematics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Modele_cinematique_corps_humain.svg/340px-Modele_cinematique_corps_humain.svg.png',
        description: 'In computer animation and robotics, inverse kinematics is the mathematical process of calculating the variable joint parameters needed to place the end of a kinematic chain, such as a robot manipulator or animation characters skeleton, in a given position and orientation relative to the start of the chain. Given joint parameters, the position and orientation of the chain end, e.g. the hand of the character or robot, can typically be calculated directly using multiple applications of trigonometric formulas, a process known as forward kinematics. However, the reverse operation is, in general, much more challenging.',
        id: '1259'
        },
        {
        title: 'Inverse kinematics ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg/49px-Stylised_atom_with_three_Bohr_model_orbits_and_stylised_nucleus.svg.png',
        description: 'In computer animation and robotics, inverse kinematics is the mathematical process of calculating the variable joint parameters needed to place the end of a kinematic chain, such as a robot manipulator or animation characters skeleton, in a given position and orientation relative to the start of the chain. Given joint parameters, the position and orientation of the chains end, e.g. the hand of the character or robot, can typically be calculated directly using multiple applications of trigonometric formulas, a process known as forward kinematics. However, the reverse operation is, in general, much more challenging.',
        id: '1260'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/GaussianScatterPCA.svg/600px-GaussianScatterPCA.svg.png',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1261'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/PCA_of_Haplogroup_J_using_37_STRs.png/440px-PCA_of_Haplogroup_J_using_37_STRs.png',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1262'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Fractional_Residual_Variances_comparison%2C_PCA_and_NMF.pdf/page1-1000px-Fractional_Residual_Variances_comparison%2C_PCA_and_NMF.pdf.jpg',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1263'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/AirMerIconographyCorrelation.jpg/440px-AirMerIconographyCorrelation.jpg',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1264'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/84/Elmap_breastcancer_wiki.png',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1265'
        },
        {
        title: 'Principal component analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'The principal components of a collection of points in a real coordinate space are a sequence of vectors. Here, a best-fitting line is defined as one that minimizes the average squared distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.',
        id: '1266'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/St_Kentigerns_Church_HDR_%288226826999%29.jpg/520px-St_Kentigerns_Church_HDR_%288226826999%29.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1267'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1268'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/StLouisArchMultExpEV-4.72.JPG/320px-StLouisArchMultExpEV-4.72.JPG',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1269'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/StLouisArchMultExpEV-1.82.JPG/320px-StLouisArchMultExpEV-1.82.JPG',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1270'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/StLouisArchMultExpEV%2B1.51.JPG/320px-StLouisArchMultExpEV%2B1.51.JPG',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1271'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/StLouisArchMultExpEV%2B4.09.JPG/320px-StLouisArchMultExpEV%2B4.09.JPG',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1272'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/StLouisArchMultExpCDR.jpg/320px-StLouisArchMultExpCDR.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1273'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/StLouisArchMultExpToneMapped.jpg/320px-StLouisArchMultExpToneMapped.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1274'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/StLouisArchMultExpEV_SNS-HDR.jpg/319px-StLouisArchMultExpEV_SNS-HDR.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1275'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/HDRI_Sample_Scene_Window_-_01.jpg/320px-HDRI_Sample_Scene_Window_-_01.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1276'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/HDRI_Sample_Scene_Window_-_02.jpg/320px-HDRI_Sample_Scene_Window_-_02.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1277'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/HDRI_Sample_Scene_Window_-_03.jpg/320px-HDRI_Sample_Scene_Window_-_03.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1278'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/HDRI_Sample_Scene_Window_-_04.jpg/320px-HDRI_Sample_Scene_Window_-_04.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1279'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/HDRI_Sample_Scene_Window_-_05.jpg/320px-HDRI_Sample_Scene_Window_-_05.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1280'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/HDRI_Sample_Scene_Window_-_06.jpg/320px-HDRI_Sample_Scene_Window_-_06.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1281'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/HDRI_Sample_Scene_Window_-_07.jpg/320px-HDRI_Sample_Scene_Window_-_07.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1282'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/HDRI_Sample_Scene_Window_-_08.jpg/320px-HDRI_Sample_Scene_Window_-_08.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1283'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/HDRI_Sample_Scene_Window_-_09.jpg/320px-HDRI_Sample_Scene_Window_-_09.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1284'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/HDRI_Sample_Scene_Window_-_10.jpg/320px-HDRI_Sample_Scene_Window_-_10.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1285'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/HDRI_Sample_Scene_Window_-_11.jpg/320px-HDRI_Sample_Scene_Window_-_11.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1286'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/HDRI_Sample_Scene_Window_-_12.jpg/320px-HDRI_Sample_Scene_Window_-_12.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1287'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/HDRI_Sample_Scene_Window.jpg/320px-HDRI_Sample_Scene_Window.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1288'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Hdr_capture_golf_swing_ghost_effect.jpg/800px-Hdr_capture_golf_swing_ghost_effect.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1289'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Gustave_Le_Gray_-_Brig_upon_the_Water_-_Google_Art_Project.jpg/520px-Gustave_Le_Gray_-_Brig_upon_the_Water_-_Google_Art_Project.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1290'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Wyckoff_HDR_Curve.tif/lossy-page1-1060px-Wyckoff_HDR_Curve.tif.jpg',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1291'
        },
        {
        title: 'Multi-exposure HDR capture ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In photography and videography, multi-exposure HDR capture is a technique allowing to capture high dynamic range (HDR) images by taking and then combining several different exposures of the same subject matter. ',
        id: '1292'
        },
        {
        title: 'Lagrangian particle tracking ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In experimental fluid mechanics, Lagrangian Particle Tracking refers to the process of determining trajectories of small neutrally buoyant particles (flow tracers) that are freely suspended within a turbulent flow field. These are usually obtained by 3-D Particle Tracking Velocimetry. A collection of such particle trajectories can be used for analyzing the Lagrangian dynamics of the fluid motion, for performing Lagrangian statistics of various flow quantities etc.    ',
        id: '1293'
        },
        {
        title: 'Lagrangian particle tracking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Streamlines_relative_to_airfoil.png/90px-Streamlines_relative_to_airfoil.png',
        description: 'In experimental fluid mechanics, Lagrangian Particle Tracking refers to the process of determining trajectories of small neutrally buoyant particles (flow tracers) that are freely suspended within a turbulent flow field. These are usually obtained by 3-D Particle Tracking Velocimetry. A collection of such particle trajectories can be used for analyzing the Lagrangian dynamics of the fluid motion, for performing Lagrangian statistics of various flow quantities etc.    ',
        id: '1294'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/1/1f/Graph_of_Lenanrd-Jones_potential.png/640px-Graph_of_Lenanrd-Jones_potential.png',
        description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1295'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Rayleigh-Taylor_instability.jpg/440px-Rayleigh-Taylor_instability.jpg',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1296'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/5/56/LJ_PhaseDiagram.png/694px-LJ_PhaseDiagram.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1297'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d8/CharacteristicCurves.png/631px-CharacteristicCurves.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1298'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a1/VirialCoeff.png/658px-VirialCoeff.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1299'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/0/08/Vapor_liquid_equilibrium_properties_of_LJ_potential.png/582px-Vapor_liquid_equilibrium_properties_of_LJ_potential.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1300'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/3/3c/LJ_mixtures.png/880px-LJ_mixtures.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1301'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/c/c9/ExpemplaricObservable.png/636px-ExpemplaricObservable.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1302'
        },
        {
        title: 'Lennard-Jones potential ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d6/Vapor_liquid_equilibrium_properties_of_LJ_and_LJTS_potential.png/633px-Vapor_liquid_equilibrium_properties_of_LJ_and_LJTS_potential.png',
         description: 'Finite element · Boundary element Lattice Boltzmann · Riemann solverDissipative particle dynamicsSmoothed particle hydrodynamics',
        id: '1303'
        },
        {
        title: 'Boids ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Rule_separation.gif/200px-Rule_separation.gif',
        description: 'Boids is an artificial life program, developed by Craig Reynolds in 1986, which simulates the flocking behaviour of birds. His paper on this topic was published in 1987 in the proceedings of the ACM SIGGRAPH conference.     The name "boid" corresponds to a shortened version of "bird-oid object", which refers to a bird-like object. "Boid" is also a New York Metropolitan dialect pronunciation for "bird.',
        id: '1304'
        },
        {
        title: 'Boids ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Rule_alignment.gif/200px-Rule_alignment.gif',
        description: 'Boids is an artificial life program, developed by Craig Reynolds in 1986, which simulates the flocking behaviour of birds. His paper on this topic was published in 1987 in the proceedings of the ACM SIGGRAPH conference.     The name "boid" corresponds to a shortened version of "bird-oid object", which refers to a bird-like object. "Boid" is also a New York Metropolitan dialect pronunciation for "bird.',
        id: '1305'
        },
        {
        title: 'Boids ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Rule_cohesion.gif/200px-Rule_cohesion.gif',
        description: 'Boids is an artificial life program, developed by Craig Reynolds in 1986, which simulates the flocking behaviour of birds. His paper on this topic was published in 1987 in the proceedings of the ACM SIGGRAPH conference.     The name "boid" corresponds to a shortened version of "bird-oid object", which refers to a bird-like object. "Boid" is also a New York Metropolitan dialect pronunciation for "bird.',
        id: '1306'
        },
        {
        title: 'Boids ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Auklet_flock_Shumagins_1986.jpg/280px-Auklet_flock_Shumagins_1986.jpg',
        description: 'Boids is an artificial life program, developed by Craig Reynolds in 1986, which simulates the flocking behaviour of birds. His paper on this topic was published in 1987 in the proceedings of the ACM SIGGRAPH conference.     The name "boid" corresponds to a shortened version of "bird-oid object", which refers to a bird-like object. "Boid" is also a New York Metropolitan dialect pronunciation for "bird.',
        id: '1307'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Utah_teapot_%28solid%29.stl/440px-Utah_teapot_%28solid%29.stl.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1308'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Utah_teapot_simple_2.png/440px-Utah_teapot_simple_2.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1309'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Original_Utah_Teapot.jpg/440px-Original_Utah_Teapot.jpg',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1310'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Beos_teapot.png/220px-Beos_teapot.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1311'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d5/The_Six_Platonic_Solids.png/220px-The_Six_Platonic_Solids.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1312'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Utah_teapot.png/222px-Utah_teapot.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1313'
        },
        {
        title: 'Utah teapot ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Environment_mapping.png/641px-Environment_mapping.png',
        description: 'The Utah teapot, or the Newell teapot, is a 3D test model that has become a standard reference object and an in-joke within the computer graphics community. It is a mathematical model of an ordinary Melitta-brand teapot that appears solid with a nearly rotationally symmetrical body. Using a teapot model is considered the 3D equivalent of a "Hello, World!" program, a way to create an easy 3D scene with a somewhat complex model acting as the basic geometry for a scene with a light setup. Some programming libraries, such as the OpenGL Utility Toolkit, even have functions dedicated to drawing teapots',
        id: '1314'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Necker_cube.svg/250px-Necker_cube.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1315'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Cube1.svg/250px-Cube1.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1316'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Cube2.svg/250px-Cube2.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1317'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Necker_cube_and_impossible_cube.svg/402px-Necker_cube_and_impossible_cube.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1318'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/2_necker_cubes.svg/600px-2_necker_cubes.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1319'
        },
        {
        title: 'Necker cube ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Optical_Illustion-Ambiguous_Patterns.svg/60px-Optical_Illustion-Ambiguous_Patterns.svg.png',
        description: 'The Necker cube is an optical illusion that was first published as a Rhomboid in 1832 by Swiss crystallographer Louis Albert Necker. It is a simple wire-frame, two dimensional drawing of a cube with no visual cues as to its orientation, so it can be interpreted to have either the lower-left or the upper-right square as its front side.',
        id: '1320'
        },
        {
        title: 'Path tracing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Path_tracing_001.png/700px-Path_tracing_001.png',
        description: 'Path tracing is a computer graphics Monte Carlo method of rendering images of three-dimensional scenes such that the global illumination is faithful to reality. Fundamentally, the algorithm is integrating over all the illuminance arriving to a single point on the surface of an object. This illuminance is then reduced by a surface reflectance function (BRDF) to determine how much of it will go towards the viewpoint camera. This integration procedure is repeated for every pixel in the output image. When combined with physically accurate models of surfaces, accurate models of real light sources (light bulbs), and optically correct cameras, path tracing can produce still images that are indistinguishable from photographs.',
        id: '1321'
        },
        {
        title: 'Path tracing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Path_tracing_sampling_values.png/440px-Path_tracing_sampling_values.png',
        description: 'Path tracing is a computer graphics Monte Carlo method of rendering images of three-dimensional scenes such that the global illumination is faithful to reality. Fundamentally, the algorithm is integrating over all the illuminance arriving to a single point on the surface of an object. This illuminance is then reduced by a surface reflectance function (BRDF) to determine how much of it will go towards the viewpoint camera. This integration procedure is repeated for every pixel in the output image. When combined with physically accurate models of surfaces, accurate models of real light sources (light bulbs), and optically correct cameras, path tracing can produce still images that are indistinguishable from photographs.',
        id: '1322'
        },
        {
        title: 'Path tracing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Bidirectional_scattering_distribution_function.svg/440px-Bidirectional_scattering_distribution_function.svg.png',
        description: 'Path tracing is a computer graphics Monte Carlo method of rendering images of three-dimensional scenes such that the global illumination is faithful to reality. Fundamentally, the algorithm is integrating over all the illuminance arriving to a single point on the surface of an object. This illuminance is then reduced by a surface reflectance function (BRDF) to determine how much of it will go towards the viewpoint camera. This integration procedure is repeated for every pixel in the output image. When combined with physically accurate models of surfaces, accurate models of real light sources (light bulbs), and optically correct cameras, path tracing can produce still images that are indistinguishable from photographs.',
        id: '1323'
        },
        {
        title: 'Photon mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Glas-1000-enery.jpg/440px-Glas-1000-enery.jpg',
        description: 'In computer graphics, photon mapping is a two-pass global illumination rendering algorithm developed by Henrik Wann Jensen between 1995 and 2001 that approximately solves the rendering equation for integrating light radiance at a given point in space. Rays from the light source (like photons) and rays from the camera are traced independently until some termination criterion is met, then they are connected in a second step to produce a radiance value. The algorithm is used to realistically simulate the interaction of light with different types of objects (similar to other photorealistic rendering techniques). Specifically, it is capable of simulating the refraction of light through a transparent substance such as glass or water (including caustics), diffuse interreflection between illuminated objects, the subsurface scattering of light in translucent materials, and some of the effects caused by particulate matter such as smoke or water vapor.  Photon mapping can also be extended to more accurate simulations of light, such as spectral rendering. Progressive photon mapping (PPM) starts with ray tracing and then adds more and more photon mapping passes to provide a progressively more accurate render.',
        id: '1324'
        },
        {
        title: 'Subsurface scattering ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Subsurface scattering (SSS), also known as subsurface light transport (SSLT), is a mechanism of light transport in which light that penetrates the surface of a translucent object is scattered by interacting with the material and exits the surface at a different point. The light will generally penetrate the surface and be reflected a number of times at irregular angles inside the material before passing back out of the material at a different angle than it would have had if it had been reflected directly off the surface. Subsurface scattering is important for realistic 3D computer graphics, being necessary for the rendering of materials such as marble, skin, leaves, wax and milk. If subsurface scattering is not implemented, the material may look unnatural, like plastic or metal.',
        id: '1325'
        },
        {
        title: 'Subsurface scattering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/7e/ShellOpticalDescattering.png',
        description: 'Subsurface scattering (SSS), also known as subsurface light transport (SSLT), is a mechanism of light transport in which light that penetrates the surface of a translucent object is scattered by interacting with the material and exits the surface at a different point. The light will generally penetrate the surface and be reflected a number of times at irregular angles inside the material before passing back out of the material at a different angle than it would have had if it had been reflected directly off the surface. Subsurface scattering is important for realistic 3D computer graphics, being necessary for the rendering of materials such as marble, skin, leaves, wax and milk. If subsurface scattering is not implemented, the material may look unnatural, like plastic or metal.',
        id: '1326'
        },
        {
        title: 'Subsurface scattering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Subsurface_scattering.png/440px-Subsurface_scattering.png',
        description: 'Subsurface scattering (SSS), also known as subsurface light transport (SSLT), is a mechanism of light transport in which light that penetrates the surface of a translucent object is scattered by interacting with the material and exits the surface at a different point. The light will generally penetrate the surface and be reflected a number of times at irregular angles inside the material before passing back out of the material at a different angle than it would have had if it had been reflected directly off the surface. Subsurface scattering is important for realistic 3D computer graphics, being necessary for the rendering of materials such as marble, skin, leaves, wax and milk. If subsurface scattering is not implemented, the material may look unnatural, like plastic or metal.',
        id: '1327'
        },
        {
        title: 'Subsurface scattering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Skin_Subsurface_Scattering.jpg/440px-Skin_Subsurface_Scattering.jpg',
        description: 'Subsurface scattering (SSS), also known as subsurface light transport (SSLT), is a mechanism of light transport in which light that penetrates the surface of a translucent object is scattered by interacting with the material and exits the surface at a different point. The light will generally penetrate the surface and be reflected a number of times at irregular angles inside the material before passing back out of the material at a different angle than it would have had if it had been reflected directly off the surface. Subsurface scattering is important for realistic 3D computer graphics, being necessary for the rendering of materials such as marble, skin, leaves, wax and milk. If subsurface scattering is not implemented, the material may look unnatural, like plastic or metal.',
        id: '1328'
        },
        {
        title: 'Subsurface scattering ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Sub-surface_scattering_depth_map.svg/440px-Sub-surface_scattering_depth_map.svg.png',
        description: 'Subsurface scattering (SSS), also known as subsurface light transport (SSLT), is a mechanism of light transport in which light that penetrates the surface of a translucent object is scattered by interacting with the material and exits the surface at a different point. The light will generally penetrate the surface and be reflected a number of times at irregular angles inside the material before passing back out of the material at a different angle than it would have had if it had been reflected directly off the surface. Subsurface scattering is important for realistic 3D computer graphics, being necessary for the rendering of materials such as marble, skin, leaves, wax and milk. If subsurface scattering is not implemented, the material may look unnatural, like plastic or metal.',
        id: '1329'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Hilbert-curve_rounded-gradient-animated.gif/440px-Hilbert-curve_rounded-gradient-animated.gif',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1330'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Hilbert_curve_1.svg/240px-Hilbert_curve_1.svg.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1331'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Hilbert_curve_2.svg/240px-Hilbert_curve_2.svg.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1332'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Hilbert_curve_3.svg/240px-Hilbert_curve_3.svg.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1333'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Hilbert_curve_production_rules%21.svg/132px-Hilbert_curve_production_rules%21.svg.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1334'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Hilbert.png/240px-Hilbert.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1335'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Hilbert3d-step3.png/239px-Hilbert3d-step3.png',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1336'
        },
        {
        title: 'Hilbert curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Courbe_de_Hilbert.jpg/240px-Courbe_de_Hilbert.jpg',
        description: 'The Hilbert curve (also known as the Hilbert space-filling curve) is a continuous fractal space-filling curve first described by the German mathematician David Hilbert in 1891, as a variant of the space-filling Peano curves discovered by Giuseppe Peano in 1890.',
        id: '1337'
        },
        {
        title: 'OpenGL Shading Language ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Linux_kernel_and_OpenGL_video_games.svg/600px-Linux_kernel_and_OpenGL_video_games.svg.png',
        description: 'OpenGL Shading Language (GLSL) is a high-level shading language with a syntax based on the C programming language. It was created by the OpenGL ARB (OpenGL Architecture Review Board) to give developers more direct control of the graphics pipeline without having to use ARB assembly language or hardware-specific languages.',
        id: '1338'
        },
        {
        title: 'Alpha compositing ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.',
        id: '1339'
        },
        {
        title: 'Alpha compositing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Hue_alpha_falloff.svg/440px-Hue_alpha_falloff.svg.png',
        description: 'In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.',
        id: '1340'
        },
        {
        title: 'Alpha compositing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Alpha_compositing.svg/1284px-Alpha_compositing.svg.png',
        description: 'In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.',
        id: '1341'
        },
        {
        title: 'Alpha compositing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Mix_lazy.png/440px-Mix_lazy.png',
        description: 'In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.',
        id: '1342'
        },
        {
        title: 'Alpha compositing ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Mix_precise.png/440px-Mix_precise.png',
        description: 'In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.',
        id: '1343'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/32/7fin.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1344'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/74/3noshadow.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1345'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/1light.png/300px-1light.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1346'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/2shadowmap.png/300px-2shadowmap.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1347'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/4overmap.png/300px-4overmap.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1348'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/5failed.png/300px-5failed.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1349'
        },
        {
        title: 'Shadow mapping ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/7fin.png/300px-7fin.png',
        description: 'Shadow mapping or shadowing projection is a process by which shadows are added to 3D computer graphics.  This concept was introduced by Lance Williams in 1978, in a paper entitled "Casting curved shadows on curved surfaces." Since then, it has been used both in pre-rendered and realtime scenes in many console and PC games.',
        id: '1350'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Usm-unsharp-mask.png/440px-Usm-unsharp-mask.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1351'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Unsharp_mask_principle.svg/440px-Unsharp_mask_principle.svg.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1352'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/4/43/Unsharped_eye.jpg',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1353'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1354'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/SharpenCarExample.png/800px-SharpenCarExample.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1355'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/SharpenCarExample2.png/795px-SharpenCarExample2.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1356'
        },
        {
        title: 'Unsharp masking ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or "unsharp", negative image to create a mask of the original image. The unsharp mask is then combined with the original positive image, creating an image that is less blurry than the original. The resulting image, although clearer, may be a less accurate representation of the images subject. ',
        id: '1357'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Delta-Doped_Charged_Coupled_Devices_%28CCD%29_for_Ultra-Violet_and_Visible_Detection.jpg/440px-Delta-Doped_Charged_Coupled_Devices_%28CCD%29_for_Ultra-Violet_and_Visible_Detection.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1358'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Nobel_Prize_2009-Press_Conference_KVA-19.jpg/480px-Nobel_Prize_2009-Press_Conference_KVA-19.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1359'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/CCD_charge_transfer_animation.gif/250px-CCD_charge_transfer_animation.gif',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1360'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/CCD_SONY_ICX493AQA_sensor_side.jpg/440px-CCD_SONY_ICX493AQA_sensor_side.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1361'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/ArgusCCD.jpg/440px-ArgusCCD.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1362'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/CCD_line_sensor.JPG/440px-CCD_line_sensor.JPG',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1363'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/IECCD55-20.jpg/440px-IECCD55-20.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1364'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/EMCCD2_color_en.svg/440px-EMCCD2_color_en.svg.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1365'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Output_vs_input_electrons.png/440px-Output_vs_input_electrons.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1366'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/96/SDSSFaceplate.gif',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1367'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Bayer_pattern_on_sensor.svg/440px-Bayer_pattern_on_sensor.svg.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1368'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/An_RGGB_Bayer_Colour_Filter_on_a_1980%27s_vintage_Sony_PAL_Camcorder_CCD.png/440px-An_RGGB_Bayer_Colour_Filter_on_a_1980%27s_vintage_Sony_PAL_Camcorder_CCD.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1369'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Vertical_smear.jpg/600px-Vertical_smear.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1370'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Nuvola_apps_ksim.png/38px-Nuvola_apps_ksim.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1371'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/38px-Telecom-icon.svg.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1372'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Crab_Nebula.jpg/38px-Crab_Nebula.jpg',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1373'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/RocketSunIcon.svg/38px-RocketSunIcon.svg.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1374'
        },
        {
        title: 'Charge-coupled device ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/38px-Nuvola_apps_kalzium.svg.png',
        description: 'A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.',
        id: '1375'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Bandlimited.svg/500px-Bandlimited.svg.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1376'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Sinc_function_%28normalized%29.svg/500px-Sinc_function_%28normalized%29.svg.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1377'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/CPT-sound-nyquist-thereom-1.5percycle.svg/500px-CPT-sound-nyquist-thereom-1.5percycle.svg.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1378'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/AliasedSpectrum.png/800px-AliasedSpectrum.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1379'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/ReconstructFilter.png/800px-ReconstructFilter.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1380'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Nyquist_sampling.gif/500px-Nyquist_sampling.gif',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1381'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/fb/Moire_pattern_of_bricks_small.jpg',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1382'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Moire_pattern_of_bricks.jpg/410px-Moire_pattern_of_bricks.jpg',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1383'
        },
        {
        title: 'Nyquist–Shannon sampling theorem ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/CriticalFrequencyAliasing.svg/440px-CriticalFrequencyAliasing.svg.png',
        description: 'The Nyquist–Shannon sampling theorem is a theorem in the field of signal processing which serves as a fundamental bridge between continuous-time signals and discrete-time signals. It establishes a sufficient condition for a sample rate that permits a discrete sequence of samples to capture all the information from a continuous-time signal of finite bandwidth.',
        id: '1384'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1385'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Piecewise_linear_function.svg/440px-Piecewise_linear_function.svg.png',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1386'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Finite_element_method_1D_illustration1.svg/440px-Finite_element_method_1D_illustration1.svg.png',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1387'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Piecewise_linear_function2D.svg/440px-Piecewise_linear_function2D.svg.png',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1388'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/R-3VAR1.JPG/440px-R-3VAR1.JPG',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1389'
        },
        {
        title: 'Piecewise linear function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Mustard_segm_regr_no_effect.png/440px-Mustard_segm_regr_no_effect.png',
        description: 'In mathematics and statistics, a piecewise linear, PL or segmented function is a real-valued function of a real variable, whose graph is composed of straight-line segments.',
        id: '1390'
        },
        {
        title: 'Spline interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Cubic_spline.svg/440px-Cubic_spline.svg.png',
        description: 'In the mathematical field of numerical analysis, spline interpolation is a form of interpolation where the interpolant is a special type of piecewise polynomial called a spline. That is, instead of fitting a single, high-degree polynomial to all of the values at once, spline interpolation fits low-degree polynomials to small subsets of the values, for example, fitting nine cubic polynomials between each of the pairs of ten points, instead of fitting a single degree-ten polynomial to all of them. Spline interpolation is often preferred over polynomial interpolation because the interpolation error can be made small even when using low-degree polynomials for the spline. Spline interpolation also avoids the problem of Runges phenomenon, in which oscillation can occur between points when interpolating using high-degree polynomials.',
        id: '1391'
        },
        {
        title: 'Spline interpolation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Cubic_splines_three_points.svg/600px-Cubic_splines_three_points.svg.png',
        description: 'In the mathematical field of numerical analysis, spline interpolation is a form of interpolation where the interpolant is a special type of piecewise polynomial called a spline. That is, instead of fitting a single, high-degree polynomial to all of the values at once, spline interpolation fits low-degree polynomials to small subsets of the values, for example, fitting nine cubic polynomials between each of the pairs of ten points, instead of fitting a single degree-ten polynomial to all of them. Spline interpolation is often preferred over polynomial interpolation because the interpolation error can be made small even when using low-degree polynomials for the spline. Spline interpolation also avoids the problem of Runges phenomenon, in which oscillation can occur between points when interpolating using high-degree polynomials.',
        id: '1392'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Gradient_descent.svg/700px-Gradient_descent.svg.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1393'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Okanogan-Wenatchee_National_Forest%2C_morning_fog_shrouds_trees_%2837171636495%29.jpg/440px-Okanogan-Wenatchee_National_Forest%2C_morning_fog_shrouds_trees_%2837171636495%29.jpg',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1394'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/60/Banana-SteepDesc.gif',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1395'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Gradient_ascent_%28contour%29.png/700px-Gradient_ascent_%28contour%29.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1396'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/68/Gradient_ascent_%28surface%29.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1397'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Steepest_descent.png/760px-Steepest_descent.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1398'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b5/Gradient_Descent_Example_Nonlinear_Equations.gif',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1399'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1400'
        },
        {
        title: 'Gradient descent ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Max_paraboloid.svg/300px-Max_paraboloid.svg.png',
        description: 'In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.',
        id: '1401'
        },
        {
        title: 'Greeble ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'A greeble (/ˈɡriːbliː/ GREE-blee) or "nurnies", is a part harvested from plastic modeling kits to be applied to an original model as a detail element. The practice of using parts in this manner is called "kitbashing".',
        id: '1402'
        },
        {
        title: 'Greeble ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/39/Greeble.png',
        description: 'A greeble (/ˈɡriːbliː/ GREE-blee) or "nurnies", is a part harvested from plastic modeling kits to be applied to an original model as a detail element. The practice of using parts in this manner is called "kitbashing".',
        id: '1403'
        },
        {
        title: 'Greeble ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Brickcon_2011_spaceship_%286209344182%29.jpg/440px-Brickcon_2011_spaceship_%286209344182%29.jpg',
        description: 'A greeble (/ˈɡriːbliː/ GREE-blee) or "nurnies", is a part harvested from plastic modeling kits to be applied to an original model as a detail element. The practice of using parts in this manner is called "kitbashing".',
        id: '1404'
        },
        {
        title: 'Greeble ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Smithsonian_NASM_-_Close_Encounters_of_the_Third_Kind_Mother_Ship_spacecraft_model_%285144012861%29.jpg/440px-Smithsonian_NASM_-_Close_Encounters_of_the_Third_Kind_Mother_Ship_spacecraft_model_%285144012861%29.jpg',
        description: 'A greeble (/ˈɡriːbliː/ GREE-blee) or "nurnies", is a part harvested from plastic modeling kits to be applied to an original model as a detail element. The practice of using parts in this manner is called "kitbashing".',
        id: '1405'
        },
        {
        title: 'Signed distance function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Signed_distance1.png/440px-Signed_distance1.png',
        description: 'In mathematics and its applications, the signed distance function (or oriented distance function) of a set Ω in a metric space determines the distance of a given point x from the boundary of Ω, with the sign determined by whether x is in Ω. The function has positive values at points x inside Ω, it decreases in value as x approaches the boundary of Ω where the signed distance function is zero, and it takes negative values outside of Ω. However, the alternative convention is also sometimes taken instead (i.e., negative inside Ω and positive outside).',
        id: '1406'
        },
        {
        title: 'Signed distance function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Signed_distance2.png/440px-Signed_distance2.png',
        description: 'In mathematics and its applications, the signed distance function (or oriented distance function) of a set Ω in a metric space determines the distance of a given point x from the boundary of Ω, with the sign determined by whether x is in Ω. The function has positive values at points x inside Ω, it decreases in value as x approaches the boundary of Ω where the signed distance function is zero, and it takes negative values outside of Ω. However, the alternative convention is also sometimes taken instead (i.e., negative inside Ω and positive outside).',
        id: '1407'
        },
        {
        title: 'Signed distance function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Signed_distance_field_duck.svg/440px-Signed_distance_field_duck.svg.png',
        description: 'In mathematics and its applications, the signed distance function (or oriented distance function) of a set Ω in a metric space determines the distance of a given point x from the boundary of Ω, with the sign determined by whether x is in Ω. The function has positive values at points x inside Ω, it decreases in value as x approaches the boundary of Ω where the signed distance function is zero, and it takes negative values outside of Ω. However, the alternative convention is also sometimes taken instead (i.e., negative inside Ω and positive outside).',
        id: '1408'
        },
        {
        title: 'Markov random field ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/f/f7/Markov_random_field_example.png/220px-Markov_random_field_example.png',
        description: 'In the domain of physics and probability, a Markov random field (MRF), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph. In other words, a random field is said to be a Markov random field if it satisfies Markov properties. The concept originates from the Sherrington–Kirkpatrick model.',
        id: '1409'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Josefina_with_Bokeh.jpg/440px-Josefina_with_Bokeh.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1410'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Katherine_Maher.jpg/440px-Katherine_Maher.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1411'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Aperture_and_bokeh.jpg/440px-Aperture_and_bokeh.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1412'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Circles_of_confusion_lens_diagram.svg/560px-Circles_of_confusion_lens_diagram.svg.png',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1413'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/DOF-ShallowDepthofField.jpg/440px-DOF-ShallowDepthofField.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1414'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Thumbs_up_for_bokeh.JPG/213px-Thumbs_up_for_bokeh.JPG',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1415'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Bahnhof_Dortmund_Brackel_Spiegeltele_DSC02359_smial_wp.jpg/440px-Bahnhof_Dortmund_Brackel_Spiegeltele_DSC02359_smial_wp.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1416'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Bokeh_Example.jpg/440px-Bokeh_Example.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1417'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Donut_bokeh.jpg/369px-Donut_bokeh.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1418'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Christmas_Tree_Lights_Bokeh.jpg/211px-Christmas_Tree_Lights_Bokeh.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1419'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Bokeh.JPG/440px-Bokeh.JPG',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1420'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Bokeh1_DSC_0959.jpg/440px-Bokeh1_DSC_0959.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1421'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Photography_by_Victor_Albert_Grigas_%281919-2017%29_000172050002_%2837159721864%29.jpg/325px-Photography_by_Victor_Albert_Grigas_%281919-2017%29_000172050002_%2837159721864%29.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1422'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Christmas_Tree_out_of_focus_copy.jpg/440px-Christmas_Tree_out_of_focus_copy.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1423'
        },
        {
        title: 'Bokeh ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Faux-bokeh-comparison.jpg/620px-Faux-bokeh-comparison.jpg',
        description: 'In photography, bokeh (/ˈboʊkə/ BOH-kə or /ˈboʊkeɪ/ BOH-kay; Japanese: [boke]) is the aesthetic quality of the blur produced in out-of-focus parts of an image.[3][4] Bokeh has also been defined as "the way the lens renders out-of-focus points of light".[5] Differences in lens aberrations and aperture shape cause very different bokeh effects.[6] Some lens designs blur the image in a way that is pleasing to the eye, while others produce distracting or unpleasant blurring  ("good" and "bad" bokeh, respectively).[6] Photographers may deliberately use a shallow focus technique to create images with prominent out-of-focus regions, accentuating their lenss bokeh',
        id: '1424'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/NURBstatic.svg/500px-NURBstatic.svg.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1425'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/NURBS_surface.png/500px-NURBS_surface.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1426'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Spline_%28PSF%29.png/440px-Spline_%28PSF%29.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1427'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Surface_modelling.svg/500px-Surface_modelling.svg.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1428'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ea/NURBS_3-D_surface.gif',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1429'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Nurbsbasisconstruct.svg/440px-Nurbsbasisconstruct.svg.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1430'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/en/5/5f/Nurbsbasislin2.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1431'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/en/3/35/Nurbsbasisquad2.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1432'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Motoryacht_design_i.png/500px-Motoryacht_design_i.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1433'
        },
        {
        title: 'Non-uniform rational B-spline ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/NURBS-circle-3D.svg/600px-NURBS-circle-3D.svg.png',
        description: 'Non-uniform rational basis spline (NURBS) is a mathematical model using basis splines (B-splines) that is commonly used in computer graphics for representing curves and surfaces. It offers great flexibility and precision for handling both analytic (defined by common mathematical formulae) and modeled shapes. It is a type of curve modeling, as opposed to polygonal modeling or digital sculpting. NURBS curves are commonly used in computer-aided design (CAD), manufacturing (CAM), and engineering (CAE). They are part of numerous industry-wide standards, such as IGES, STEP, ACIS, and PHIGS. Tools for creating and editing NURBS surfaces are found in various 3D graphics and animation software packages.',
        id: '1434'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1435'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1436'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/6d/Activemarker2.PNG',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1437'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Gouraudshading00.png/600px-Gouraudshading00.png',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1438'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/D3D_Shading_Modes.png/300px-D3D_Shading_Modes.png',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1439'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Gouraud_low_anim.gif/360px-Gouraud_low_anim.gif',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1440'
        },
        {
        title: 'Gouraud shading ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/69/Gouraud_high.gif',
        description: 'Gouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle meshes by computing the lighting at the corners of each triangle and linearly interpolating the resulting colours for each pixel covered by the triangle. Gouraud first published the technique in 1971.[3]',
        id: '1441'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/ab/Interlace_zoom.gif',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1442'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/CRT_image_creation_animation.gif/440px-CRT_image_creation_animation.gif',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1443'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Deinterlaced_vs_interlaced_image.gif/440px-Deinterlaced_vs_interlaced_image.gif',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1444'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/19/Interlaced_video_frame_%28car_wheel%29.jpg',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1445'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a0/Interlaced_video_frame_%28car_wheel%29Xcorr.png',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1446'
        },
        {
        title: 'Interlaced video ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/f0/Indian_Head_interlace.gif',
        description: 'Interlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the phi phenomenon.[citation needed',
        id: '1447'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Quaternion_2.svg/440px-Quaternion_2.svg.png',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1448'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Inscription_on_Broom_Bridge_%28Dublin%29_regarding_the_discovery_of_Quaternions_multiplication_by_Sir_William_Rowan_Hamilton.jpg/440px-Inscription_on_Broom_Bridge_%28Dublin%29_regarding_the_discovery_of_Quaternions_multiplication_by_Sir_William_Rowan_Hamilton.jpg',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1449'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Cayley_graph_Q8.svg/440px-Cayley_graph_Q8.svg.png',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1450'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Quaternion-multiplication-cayley-3d-with-legend.png/440px-Quaternion-multiplication-cayley-3d-with-legend.png',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1451'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Quaternion_Julia_x%3D-0%2C75_y%3D-0%2C14.jpg/440px-Quaternion_Julia_x%3D-0%2C75_y%3D-0%2C14.jpg',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1452'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1453'
        },
        {
        title: 'Quaternion ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In mathematics, the quaternion number system extends the complex numbers. Quaternions were first described by Irish mathematician William Rowan Hamilton in 1843 and applied to mechanics in three-dimensional space. Hamilton defined a quaternion as the quotient of two directed lines in a three-dimensional space,[3] or, equivalently, as the quotient of two vectors.[4] Multiplication of quaternions is noncommutative.',
        id: '1454'
        },
        {
        title: 'Python Imaging Library ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/32px-Wikibooks-logo-en-noslogan.svg.png',
        description: 'Python Imaging Library is a free and open-source additional library for the Python programming language that adds support for opening, manipulating, and saving many different image file formats. It is available for Windows, Mac OS X and Linux. The latest version of PIL is 1.1.7, was released in September 2009 and supports Python 1.5.2–2.7.[3]',
        id: '1455'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Asymptotic_curve_hvo1.svg/500px-Asymptotic_curve_hvo1.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1456'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Asymptote02_vectorial.svg/500px-Asymptote02_vectorial.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1457'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Hyperbola_one_over_x.svg/600px-Hyperbola_one_over_x.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1458'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/8a/Asymptote03.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1459'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/1-over-x-plus-x.svg/440px-1-over-x-plus-x.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1460'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/SlantAsymptoteError.svg/640px-SlantAsymptoteError.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1461'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Graph_of_sect_csct.svg/400px-Graph_of_sect_csct.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1462'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Nonlinear_asymptote.svg/400px-Nonlinear_asymptote.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1463'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Folium_Of_Descartes.svg/440px-Folium_Of_Descartes.svg.png',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1464'
        },
        {
        title: 'Asymptote ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/2b/Conic_section_hyperbola.gif',
        description: 'In analytic geometry, an asymptote (/ˈæsɪmptoʊt/) of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity. In projective geometry and related contexts, an asymptote of a curve is a line which is tangent to the curve at a point at infinity.',
        id: '1465'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1466'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Roessler_attractor.png/440px-Roessler_attractor.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1467'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/RosslerStereo.png/440px-RosslerStereo.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1468'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/RosslerAttractor.svg/440px-RosslerAttractor.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1469'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Eigenvectors.png/440px-Eigenvectors.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1470'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/RosslerAttractor3D.svg/440px-RosslerAttractor3D.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1471'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/f/fd/Poincare2.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1472'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/63/Tentmap.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1473'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Bifurcation_DiagramB.png/440px-Bifurcation_DiagramB.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1474'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/RosslerVaryC.svg/440px-RosslerVaryC.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1475'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/RosslerC4.svg/520px-RosslerC4.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1476'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/RosslerC6.svg/520px-RosslerC6.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1477'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/RosslerC85.svg/520px-RosslerC85.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1478'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/RosslerC87.svg/520px-RosslerC87.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1479'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/RosslerC9.svg/520px-RosslerC9.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1480'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/RosslerC12.svg/520px-RosslerC12.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1481'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/RosslerC126.svg/520px-RosslerC126.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1482'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/RosslerC13.svg/520px-RosslerC13.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1483'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/RosslerC18.svg/520px-RosslerC18.svg.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1484'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Rossler_Periodic_Orbit_Winding_2.gif/520px-Rossler_Periodic_Orbit_Winding_2.gif',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1485'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Rossler_Periodic_Orbit_w2.gif/520px-Rossler_Periodic_Orbit_w2.gif',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1486'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Rossler_Periodic_W3.gif/520px-Rossler_Periodic_W3.gif',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1487'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/C%C3%B4ne_textileII.png/200px-C%C3%B4ne_textileII.png',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1488'
        },
        {
        title: 'Rössler attractor ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Circle_map_poincare_recurrence.jpeg/200px-Circle_map_poincare_recurrence.jpeg',
        description: 'The Rössler attractor /ˈrɒslər/ is the attractor for the Rössler system, a system of three non-linear ordinary differential equations originally studied by Otto Rössler in the 1970s. These differential equations define a continuous-time dynamical system that exhibits chaotic dynamics associated with the fractal properties of the attractor.[3]',
        id: '1489'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Examples_of_Polar_Coordinates.svg/500px-Examples_of_Polar_Coordinates.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1490'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/50/Hipparchos_1.jpeg',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1491'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Polar_graph_paper.svg/600px-Polar_graph_paper.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1492'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Polar_to_cartesian.svg/500px-Polar_to_cartesian.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1493'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Imaginarynumber2.svg/530px-Imaginarynumber2.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1494'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Euler%27s_formula.svg/530px-Euler%27s_formula.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1495'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/53/Cartesian_to_polar.gif',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1496'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Circle_r%3D1.svg/440px-Circle_r%3D1.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1497'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Rose_2sin%284theta%29.svg/440px-Rose_2sin%284theta%29.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1498'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Spiral_of_Archimedes.svg/440px-Spiral_of_Archimedes.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1499'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Elps-slr.svg/500px-Elps-slr.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1500'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Polar_coordinates_integration_region.svg/440px-Polar_coordinates_integration_region.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1501'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Polar_coordinates_integration_Riemann_sum.svg/440px-Polar_coordinates_integration_Riemann_sum.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1502'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Planimeter.jpg/440px-Planimeter.jpg',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1503'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/E%5E%28-x%5E2%29.svg/440px-E%5E%28-x%5E2%29.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1504'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Position_vector_plane_polar_coords.svg/200px-Position_vector_plane_polar_coords.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1505'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Velocity_vector_plane_polar_coords.svg/300px-Velocity_vector_plane_polar_coords.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1506'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Acceleration_vector_plane_polar_coords.svg/400px-Acceleration_vector_plane_polar_coords.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1507'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Co-rotating_frame_vector.svg/440px-Co-rotating_frame_vector.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1508'
        },
        {
        title: 'Polar coordinate system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The reference point (analogous to the origin of a Cartesian coordinate system) is called the pole, and the ray from the pole in the reference direction is the polar axis. The distance from the pole is called the radial coordinate, radial distance or simply radius, and the angle is called the angular coordinate, polar angle, or azimuth. Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°).',
        id: '1509'
        },
        {
        title: 'Dijkstras algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Dijkstra_Animation.gif/220px-Dijkstra_Animation.gif',
        description: 'Dijkstras algorithm (/ˈdaɪkstrəz/ DYKE-strəz) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.  It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.[4][5][6',
        id: '1510'
        },
        {
        title: 'Dijkstras algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/23/Dijkstras_progress_animation.gif',
        description: 'Dijkstras algorithm (/ˈdaɪkstrəz/ DYKE-strəz) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.  It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.[4][5][6',
        id: '1511'
        },
        {
        title: 'Dijkstras algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/DijkstraDemo.gif/440px-DijkstraDemo.gif',
        description: 'Dijkstras algorithm (/ˈdaɪkstrəz/ DYKE-strəz) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.  It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.[4][5][6',
        id: '1512'
        },
        {
        title: 'Dijkstras algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Edsger_Wybe_Dijkstra.jpg/180px-Edsger_Wybe_Dijkstra.jpg',
        description: 'Dijkstras algorithm (/ˈdaɪkstrəz/ DYKE-strəz) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.  It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.[4][5][6',
        id: '1513'
        },
        {
        title: 'Dijkstras algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Max_paraboloid.svg/300px-Max_paraboloid.svg.png',
        description: 'Dijkstras algorithm (/ˈdaɪkstrəz/ DYKE-strəz) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.  It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.[4][5][6',
        id: '1514'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/DLA_Cluster.JPG/374px-DLA_Cluster.JPG',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1515'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Brownian_tree_vertical_large.png/294px-Brownian_tree_vertical_large.png',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1516'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Rec8_3kc2p.jpg/476px-Rec8_3kc2p.jpg',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1517'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Of7_p0001_15h.jpg/476px-Of7_p0001_15h.jpg',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1518'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Brownian_tree_circle_large.png/382px-Brownian_tree_circle_large.png',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1519'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Dlasim.PNG/286px-Dlasim.PNG',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1520'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Brownian_tree.gif/200px-Brownian_tree.gif',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1521'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Lichtenberg_figure_in_block_of_Plexiglas.jpg/476px-Lichtenberg_figure_in_block_of_Plexiglas.jpg',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1522'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/DLA_spiral.png/476px-DLA_spiral.png',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1523'
        },
        {
        title: 'Diffusion-limited aggregation ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'Diffusion-limited aggregation (DLA) is the process whereby particles undergoing a random walk due to Brownian motion cluster together to form aggregates of such particles.  This theory, proposed by T.A. Witten Jr. and L.M. Sander in 1981, is applicable to aggregation in any system where diffusion is the primary means of transport in the system.  DLA can be observed in many systems such as electrodeposition, Hele-Shaw flow, mineral deposits, and dielectric breakdown.',
        id: '1524'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/13/A_Trajectory_Through_Phase_Space_in_a_Lorenz_Attractor.gif',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1525'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/3c/Lorenz_Ro14_20_41_20-200px.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1526'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/cb/Lorenz_Ro13-200px.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1527'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/59/Lorenz_Ro15-200px.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1528'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ef/Lorenz_Ro28-200px.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1529'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/c/c8/Lorenz_caos1-175.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1530'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a2/Lorenz_caos2-175.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1531'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/7/73/Lorenz_caos3-175.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1532'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Lorenz_Map.png/580px-Lorenz_Map.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1533'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Lorenz_system_r28_s10_b2-6666.png/240px-Lorenz_system_r28_s10_b2-6666.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1534'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Lorenz_attractor.svg/240px-Lorenz_attractor.svg.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1535'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Lorenzstill-rubel.png/240px-Lorenzstill-rubel.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1536'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Intermittent_Lorenz_Attractor_-_Chaoscope.jpg/240px-Intermittent_Lorenz_Attractor_-_Chaoscope.jpg',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1537'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Lorenz_apparition_small.gif/240px-Lorenz_apparition_small.gif',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1538'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Lorenz%28rho%29.gif/240px-Lorenz%28rho%29.gif',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1539'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/C%C3%B4ne_textileII.png/200px-C%C3%B4ne_textileII.png',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1540'
        },
        {
        title: 'Lorenz system ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Circle_map_poincare_recurrence.jpeg/200px-Circle_map_poincare_recurrence.jpeg',
        description: 'The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. It is notable for having chaotic solutions for certain parameter values and initial conditions. In particular, the Lorenz attractor is a set of chaotic solutions of the Lorenz system. In popular media the "butterfly effect" stems from the real-world implications of the Lorenz attractor, i.e. that in any physical system, in the absence of perfect knowledge of the initial conditions (even the minuscule disturbance of the air due to a butterfly flapping its wings), our ability to predict its future course will always fail. This underscores that physical systems can be completely deterministic and yet still be inherently unpredictable even in the absence of quantum effects. The shape of the Lorenz attractor itself, when plotted graphically, may also be seen to resemble a butterfly.',
        id: '1541'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/SLR_cross_section.svg/520px-SLR_cross_section.svg.png',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1542'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Olympus_E-30-Cutmodel.jpg/600px-Olympus_E-30-Cutmodel.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1543'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Canon_EF-S_18-135mm_IS.JPG/440px-Canon_EF-S_18-135mm_IS.JPG',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1544'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Nikon_D90_Liveview_20090116.jpg/440px-Nikon_D90_Liveview_20090116.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1545'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/SensorSizes.svg/550px-SensorSizes.svg.png',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1546'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Dslr_sensor_comparison.jpg/600px-Dslr_sensor_comparison.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1547'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Early_digital%21.jpg/340px-Early_digital%21.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1548'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Nikon_Nasa_F4_back.jpg/340px-Nikon_Nasa_F4_back.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1549'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Pentax_K10D_front.jpg/440px-Pentax_K10D_front.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1550'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/EOS70D_front.jpg/440px-EOS70D_front.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1551'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Nikon_D850_sensor.jpg/440px-Nikon_D850_sensor.jpg',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1552'
        },
        {
        title: 'Digital single-lens reflex camera ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'A digital single-lens reflex camera (digital SLR or DSLR) is a digital camera that combines the optics and the mechanisms of a single-lens reflex camera with a digital imaging sensor.',
        id: '1553'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1554'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Star_Rain_in_the_Desert.jpg/600px-Star_Rain_in_the_Desert.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1555'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/London_bus_and_telephone_box_on_Haymarket.jpg/440px-London_bus_and_telephone_box_on_Haymarket.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1556'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Dog_Leaping.jpg/440px-Dog_Leaping.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1557'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Figure-Animation2.gif/800px-Figure-Animation2.gif',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1558'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Three_women_in_a_taxi_in_Manhattan_who_said_hello.jpg/440px-Three_women_in_a_taxi_in_Manhattan_who_said_hello.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1559'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/e3/Image_restoration_%28motion_blur%2C_Wiener_filtering%29.png',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1560'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Motorbike_rider_mono.jpg/240px-Motorbike_rider_mono.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1561'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Nightly_Rotation_above_San_Jose_International_Airport.jpg/240px-Nightly_Rotation_above_San_Jose_International_Airport.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1562'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Tj_pullingout.jpg/240px-Tj_pullingout.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1563'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Strickland_Falls_Shadows_Lifted.jpg/240px-Strickland_Falls_Shadows_Lifted.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1564'
        },
        {
        title: 'Motion blur ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Moths_attracted_by_floodlight.jpg/240px-Moths_attracted_by_floodlight.jpg',
        description: 'Motion blur is the apparent streaking of moving objects in a photograph or a sequence of frames, such as a film or animation. It results when the image being recorded changes during the recording of a single exposure, due to rapid movement or long exposure.',
        id: '1565'
        },
        {
        title: 'Circular convolution ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Circular_convolution_example.svg/800px-Circular_convolution_example.svg.png',
        description: 'Circular convolution, also known as cyclic convolution,  is a special case of periodic convolution, which is the convolution of two periodic functions that have the same period.  Periodic convolution arises, for example, in the context of the discrete-time Fourier transform (DTFT). In particular, the DTFT of the product of two discrete sequences is the periodic convolution of the DTFTs of the individual sequences.  And each DTFT is a periodic summation of a continuous Fourier transform function (see DTFT § Definition).  Although DTFTs are usually continuous functions of frequency, the concepts of periodic and circular convolution are also directly applicable to discrete sequences of data.  In that context, circular convolution plays an important role in maximizing the efficiency of a certain kind of common filtering operation.',
        id: '1566'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Nasir_Ahmed.png/300px-Nasir_Ahmed.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1567'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/DCT-symmetries.svg/700px-DCT-symmetries.svg.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1568'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Stages_of_the_3-D_DCT-II_VR_DIF_algorithm.jpg/493px-Stages_of_the_3-D_DCT-II_VR_DIF_algorithm.jpg',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1569'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Single_butterfly_of_the_3-D_DCT-II_VR_DIF_algorithm.jpg/620px-Single_butterfly_of_the_3-D_DCT-II_VR_DIF_algorithm.jpg',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1570'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/2/24/DCT-8x8.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1571'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/DCT_filter_comparison.png/440px-DCT_filter_comparison.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1572'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/1/1a/Letter-a-8x8.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1573'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/6/63/Dct-table.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1574'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/5/5e/Idct-animation.gif',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1575'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/130px-Telecom-icon.svg.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1576'
        },
        {
        title: 'Discrete cosine transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Telecom-icon.svg/56px-Telecom-icon.svg.png',
        description: 'A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. The DCT, first proposed by Nasir Ahmed in 1972, is a widely used transformation technique in signal processing and data compression. It is used in most digital media, including digital images (such as JPEG and HEIF, where small high-frequency components can be discarded), digital video (such as MPEG and H.26x), digital audio (such as Dolby Digital, MP3 and AAC), digital television (such as SDTV, HDTV and VOD), digital radio (such as AAC+ and DAB+), and speech coding (such as AAC-LD, Siren and Opus). DCTs are also important to numerous other applications in science and engineering, such as digital signal processing, telecommunication devices, reducing network bandwidth usage, and spectral methods for the numerical solution of partial differential equations.',
        id: '1577'
        },
        {
        title: 'Hadamard transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/1010_0110_Walsh_spectrum_%28single_row%29.svg/600px-1010_0110_Walsh_spectrum_%28single_row%29.svg.png',
        description: 'The Hadamard transform (also known as the Walsh–Hadamard transform, Hadamard–Rademacher–Walsh transform, Walsh transform, or Walsh–Fourier transform) is an example of a generalized class of Fourier transforms. It performs an orthogonal, symmetric, involutive, linear operation on 2m real numbers (or complex, or hypercomplex numbers, although the Hadamard matrices themselves are purely real)',
        id: '1578'
        },
        {
        title: 'Hadamard transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/1010_0110_Walsh_spectrum_%28fast_WHT%29.svg/600px-1010_0110_Walsh_spectrum_%28fast_WHT%29.svg.png',
        description: 'The Hadamard transform (also known as the Walsh–Hadamard transform, Hadamard–Rademacher–Walsh transform, Walsh transform, or Walsh–Fourier transform) is an example of a generalized class of Fourier transforms. It performs an orthogonal, symmetric, involutive, linear operation on 2m real numbers (or complex, or hypercomplex numbers, although the Hadamard matrices themselves are purely real)',
        id: '1579'
        },
        {
        title: 'Hadamard transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/1010_0110_Walsh_spectrum_%28polynomial%29.svg/600px-1010_0110_Walsh_spectrum_%28polynomial%29.svg.png',
        description: 'The Hadamard transform (also known as the Walsh–Hadamard transform, Hadamard–Rademacher–Walsh transform, Walsh transform, or Walsh–Fourier transform) is an example of a generalized class of Fourier transforms. It performs an orthogonal, symmetric, involutive, linear operation on 2m real numbers (or complex, or hypercomplex numbers, although the Hadamard matrices themselves are purely real)',
        id: '1580'
        },
        {
        title: 'Doo–Sabin subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/DooSabin_subdivision_surface.png/372px-DooSabin_subdivision_surface.png',
        description: 'In 3D computer graphics, a Doo–Sabin subdivision surface is a type of subdivision surface based on a generalization of bi-quadratic uniform B-splines, whereas Catmull-Clark was based on generalized bi-cubic uniform B-splines. The subdivision refinement algorithm was developed in 1978 by Daniel Doo and Malcolm Sabin.',
        id: '1581'
        },
        {
        title: 'Doo–Sabin subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/DooSabin_subdivision.png/617px-DooSabin_subdivision.png',
        description: 'In 3D computer graphics, a Doo–Sabin subdivision surface is a type of subdivision surface based on a generalization of bi-quadratic uniform B-splines, whereas Catmull-Clark was based on generalized bi-cubic uniform B-splines. The subdivision refinement algorithm was developed in 1978 by Daniel Doo and Malcolm Sabin.',
        id: '1582'
        },
        {
        title: 'Doo–Sabin subdivision surface ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/LampFlowchart.svg/44px-LampFlowchart.svg.png',
        description: 'In 3D computer graphics, a Doo–Sabin subdivision surface is a type of subdivision surface based on a generalization of bi-quadratic uniform B-splines, whereas Catmull-Clark was based on generalized bi-cubic uniform B-splines. The subdivision refinement algorithm was developed in 1978 by Daniel Doo and Malcolm Sabin.',
        id: '1583'
        },
        {
        title: 'k-d tree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/3dtree.png/440px-3dtree.png',
        description: 'In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.',
        id: '1584'
        },
        {
        title: 'k-d tree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Kdtree_2d.svg/740px-Kdtree_2d.svg.png',
        description: 'In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.',
        id: '1585'
        },
        {
        title: 'k-d tree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Tree_0001.svg/740px-Tree_0001.svg.png',
        description: 'In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.',
        id: '1586'
        },
        {
        title: 'k-d tree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.',
        id: '1587'
        },
        {
        title: 'k-d tree ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png',
        description: 'In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.',
        id: '1588'
        },
        {
        title: 'Warnock algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Warnock1.svg/400px-Warnock1.svg.png',
        description: 'The Warnock algorithm is a hidden surface algorithm invented by John Warnock that is typically used in the field of computer graphics.     It solves the problem of rendering a complicated image by recursive subdivision of a scene until areas are obtained that are trivial to compute. In other words, if the scene is simple enough to compute efficiently then it is rendered; otherwise it is divided into smaller parts which are likewise tested for simplicity.',
        id: '1589'
        },
        {
        title: 'Warnock algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Warnock_algorithm.svg/400px-Warnock_algorithm.svg.png',
        description: 'The Warnock algorithm is a hidden surface algorithm invented by John Warnock that is typically used in the field of computer graphics.     It solves the problem of rendering a complicated image by recursive subdivision of a scene until areas are obtained that are trivial to compute. In other words, if the scene is simple enough to compute efficiently then it is rendered; otherwise it is divided into smaller parts which are likewise tested for simplicity.',
        id: '1590'
        },
        {
        title: 'Warnock algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Software_spanner.png/80px-Software_spanner.png',
        description: 'The Warnock algorithm is a hidden surface algorithm invented by John Warnock that is typically used in the field of computer graphics.     It solves the problem of rendering a complicated image by recursive subdivision of a scene until areas are obtained that are trivial to compute. In other words, if the scene is simple enough to compute efficiently then it is rendered; otherwise it is divided into smaller parts which are likewise tested for simplicity.',
        id: '1591'
        },
        {
        title: 'painters algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Painter%27s_algorithm.svg/1200px-Painter%27s_algorithm.svg.png',
        description: 'The painter’s algorithm (also depth-sort algorithm and priority fill) is an algorithm for visible surface determination in 3D computer graphics that works on a polygon-by-polygon basis rather than a pixel-by-pixel, row by row, or area by area basis of other Hidden Surface Removal algorithms.[3] The painter’s algorithm creates images by sorting the polygons within the image by their depth and placing each polygon in order from the farthest to the closest object.[4][5]',
        id: '1592'
        },
        {
        title: 'painters algorithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Painters_problem.svg/538px-Painters_problem.svg.png',
        description: 'The painter’s algorithm (also depth-sort algorithm and priority fill) is an algorithm for visible surface determination in 3D computer graphics that works on a polygon-by-polygon basis rather than a pixel-by-pixel, row by row, or area by area basis of other Hidden Surface Removal algorithms.[3] The painter’s algorithm creates images by sorting the polygons within the image by their depth and placing each polygon in order from the farthest to the closest object.[4][5]',
        id: '1593'
        },
        {
        title: 'Scan conversion ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The process of representing continuous graphics objects as a collection of discrete pixels is called scan conversion.',
        id: '1594'
        },
        {
        title: 'Scan conversion ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Scan_converter_SW-22050_big.jpg/440px-Scan_converter_SW-22050_big.jpg',
        description: 'The process of representing continuous graphics objects as a collection of discrete pixels is called scan conversion.',
        id: '1595'
        },
        {
        title: 'Cornell box ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Cornell_box.png/200px-Cornell_box.png',
        description: 'The Cornell box is a test aimed at determining the accuracy of rendering software by comparing the rendered scene with an actual photograph of the same scene, and has become a commonly used 3D test model. It was created by Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile at the Cornell University Program of Computer Graphics for their paper Modeling the Interaction of Light Between Diffuse Surfaces published and presented at SIGGRAPH84.[3]',
        id: '1596'
        },
        {
        title: 'Cornell box ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Cornell_Box_with_3_balls_of_different_materials.jpg/440px-Cornell_Box_with_3_balls_of_different_materials.jpg',
        description: 'The Cornell box is a test aimed at determining the accuracy of rendering software by comparing the rendered scene with an actual photograph of the same scene, and has become a commonly used 3D test model. It was created by Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile at the Cornell University Program of Computer Graphics for their paper Modeling the Interaction of Light Between Diffuse Surfaces published and presented at SIGGRAPH84.[3]',
        id: '1597'
        },
        {
        title: 'YCbCr ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b8/YCbCr.GIF',
        description: 'YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or Y′CBCR, is a family of color spaces used as a part of the color image pipeline in video and digital photography systems. Y′ is the luma component and CB and CR are the blue-difference and red-difference chroma components. Y′ (with prime) is distinguished from Y, which is luminance, meaning that light intensity is nonlinearly encoded based on gamma corrected RGB primaries.',
        id: '1598'
        },
        {
        title: 'YCbCr ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/YCbCr-CbCr_Scaled_Y50.png/600px-YCbCr-CbCr_Scaled_Y50.png',
        description: 'YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or Y′CBCR, is a family of color spaces used as a part of the color image pipeline in video and digital photography systems. Y′ is the luma component and CB and CR are the blue-difference and red-difference chroma components. Y′ (with prime) is distinguished from Y, which is luminance, meaning that light intensity is nonlinearly encoded based on gamma corrected RGB primaries.',
        id: '1599'
        },
        {
        title: 'YCbCr ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Barns_grand_tetons_YCbCr_separation.jpg/440px-Barns_grand_tetons_YCbCr_separation.jpg',
        description: 'YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or Y′CBCR, is a family of color spaces used as a part of the color image pipeline in video and digital photography systems. Y′ is the luma component and CB and CR are the blue-difference and red-difference chroma components. Y′ (with prime) is distinguished from Y, which is luminance, meaning that light intensity is nonlinearly encoded based on gamma corrected RGB primaries.',
        id: '1600'
        },
        {
        title: 'YCbCr ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/CCD.png/440px-CCD.png',
        description: 'YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or Y′CBCR, is a family of color spaces used as a part of the color image pipeline in video and digital photography systems. Y′ is the luma component and CB and CR are the blue-difference and red-difference chroma components. Y′ (with prime) is distinguished from Y, which is luminance, meaning that light intensity is nonlinearly encoded based on gamma corrected RGB primaries.',
        id: '1601'
        },
        {
        title: 'YCbCr ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/CIExy1931_Rec_2020_and_Rec_709.svg/440px-CIExy1931_Rec_2020_and_Rec_709.svg.png',
        description: 'YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or Y′CBCR, is a family of color spaces used as a part of the color image pipeline in video and digital photography systems. Y′ is the luma component and CB and CR are the blue-difference and red-difference chroma components. Y′ (with prime) is distinguished from Y, which is luminance, meaning that light intensity is nonlinearly encoded based on gamma corrected RGB primaries.',
        id: '1602'
        },
        {
        title: 'Bernstein polynomial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/a/a6/Bernstein_Approximation.gif',
        description: 'In the mathematical field of numerical analysis, a Bernstein polynomial is a polynomial that is a linear combination of Bernstein basis polynomials. The idea is named after Sergei Natanovich Bernstein.',
        id: '1603'
        },
        {
        title: 'Bernstein polynomial ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Bernstein_Polynomials.svg/440px-Bernstein_Polynomials.svg.png',
        description: 'In the mathematical field of numerical analysis, a Bernstein polynomial is a polynomial that is a linear combination of Bernstein basis polynomials. The idea is named after Sergei Natanovich Bernstein.',
        id: '1604'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/CubicCurve.svg/440px-CubicCurve.svg.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1605'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Cubic_with_double_point.svg/440px-Cubic_with_double_point.svg.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1606'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/NeubergCurve.png/440px-NeubergCurve.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1607'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Thomson_cubic.svg/440px-Thomson_cubic.svg.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1608'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/DarbouxCubic.png/440px-DarbouxCubic.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1609'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/LucasCubic.png/440px-LucasCubic.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1610'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/FirstBrocardCubic.png/440px-FirstBrocardCubic.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1611'
        },
        {
        title: 'Cubic plane curve ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/FirstEqualAreasCubic.png/440px-FirstEqualAreasCubic.png',
        description: 'In mathematics, a cubic plane curve is a plane algebraic curve C defined by a cubic equation',
        id: '1612'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Circle_radians.gif/300px-Circle_radians.gif',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1613'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/2pi-unrolled.gif/440px-2pi-unrolled.gif',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1614'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Degree-Radian_Conversion.svg/600px-Degree-Radian_Conversion.svg.png',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1615'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Radian-common.svg/714px-Radian-common.svg.png',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1616'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1617'
        },
        {
        title: 'Radian ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/International_System_of_Units_Logo.png/230px-International_System_of_Units_Logo.png',
        description: 'The radian, denoted by the symbol rad, is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics. The unit was formerly an SI supplementary unit (before that category was abolished in 1995) and the radian is now an SI derived unit. The radian is defined in the SI as being a dimensionless unit with 1 rad = 1. Its symbol is accordingly often omitted, especially in mathematical writing',
        id: '1618'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Logarithm_plots.png/600px-Logarithm_plots.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1619'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Binary_logarithm_plot_with_grid.png/600px-Binary_logarithm_plot_with_grid.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1620'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Log4.svg/520px-Log4.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1621'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Logarithms_Britannica_1797.png/720px-Logarithms_Britannica_1797.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1622'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Slide_rule_example2_with_labels.svg/1100px-Slide_rule_example2_with_labels.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1623'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Logarithm_inversefunctiontoexp.svg/440px-Logarithm_inversefunctiontoexp.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1624'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Logarithm_derivative.svg/440px-Logarithm_derivative.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1625'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Natural_logarithm_integral.svg/440px-Natural_logarithm_integral.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1626'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Natural_logarithm_product_formula_proven_geometrically.svg/1000px-Natural_logarithm_product_formula_proven_geometrically.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1627'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logarithm_keys.jpg/440px-Logarithm_keys.jpg',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1628'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Taylor_approximation_of_natural_logarithm.gif/220px-Taylor_approximation_of_natural_logarithm.gif',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1629'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/NautilusCutawayLogarithmicSpiral.jpg/440px-NautilusCutawayLogarithmicSpiral.jpg',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1630'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Germany_Hyperinflation.svg/440px-Germany_Hyperinflation.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1631'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/PDF-log_normal_distributions.svg/440px-PDF-log_normal_distributions.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1632'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0b/Benfords_law_illustrated_by_world%27s_countries_population.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1633'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Chaotic_Bunimovich_stadium.png/440px-Chaotic_Bunimovich_stadium.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1634'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Sierpinski_dimension.svg/800px-Sierpinski_dimension.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1635'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/4Octaves.and.Frequencies.svg/700px-4Octaves.and.Frequencies.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1636'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/4Octaves.and.Frequencies.Ears.svg/700px-4Octaves.and.Frequencies.Ears.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1637'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Complex_number_illustration_multiple_arguments.svg/440px-Complex_number_illustration_multiple_arguments.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1638'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Complex_log_domain.svg/440px-Complex_log_domain.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1639'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1640'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Nuvola_apps_kcmsystem.svg/56px-Nuvola_apps_kcmsystem.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1641'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1642'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/32px-Wiktionary-logo-en-v2.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1643'
        },
        {
        title: 'Logarithm ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Wikiversity_logo_2017.svg/32px-Wikiversity_logo_2017.svg.png',
        description: 'In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number x is the exponent to which another fixed number, the base b, must be raised, to produce that number x. In the simplest case, the logarithm counts the number of occurrences of the same factor in repeated multiplication; e.g. since 1000 = 10 × 10 × 10 = 103, the "logarithm base 10" of 1000 is 3, or log10 (1000) = 3. The logarithm of x to base b is denoted as logb (x), or without parentheses, logb x, or even without the explicit base, log x, when no confusion is possible, or when the base does not matter such as in big O notation',
        id: '1644'
        },
        {
        title: 'Otsus method ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Image_processing_post_otsus_algorithm.jpg/440px-Image_processing_post_otsus_algorithm.jpg',
        description: 'In computer vision and image processing, Otsus method, named after Nobuyuki Otsu (大津展之, Ōtsu Nobuyuki), is used to perform automatic image thresholding. In the simplest form, the algorithm returns a single intensity threshold that separate pixels into two classes, foreground and background. This threshold is determined by minimizing intra-class intensity variance, or equivalently, by maximizing inter-class variance. Otsus method is a one-dimensional discrete analog of Fishers Discriminant Analysis, is related to Jenks optimization method, and is equivalent to a globally optimal k-means[3] performed on the intensity histogram. The extension to multi-level thresholding was described in the original paper, and computationally efficient implementations have since been proposed.[4][5]',
        id: '1645'
        },
        {
        title: 'Otsus method ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Image_processing_pre_otsus_algorithm.jpg/440px-Image_processing_pre_otsus_algorithm.jpg',
        description: 'In computer vision and image processing, Otsus method, named after Nobuyuki Otsu (大津展之, Ōtsu Nobuyuki), is used to perform automatic image thresholding. In the simplest form, the algorithm returns a single intensity threshold that separate pixels into two classes, foreground and background. This threshold is determined by minimizing intra-class intensity variance, or equivalently, by maximizing inter-class variance. Otsus method is a one-dimensional discrete analog of Fishers Discriminant Analysis, is related to Jenks optimization method, and is equivalent to a globally optimal k-means[3] performed on the intensity histogram. The extension to multi-level thresholding was described in the original paper, and computationally efficient implementations have since been proposed.[4][5]',
        id: '1646'
        },
        {
        title: 'Otsus method ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Otsu%27s_Method_Visualization.gif/440px-Otsu%27s_Method_Visualization.gif',
        description: 'In computer vision and image processing, Otsus method, named after Nobuyuki Otsu (大津展之, Ōtsu Nobuyuki), is used to perform automatic image thresholding. In the simplest form, the algorithm returns a single intensity threshold that separate pixels into two classes, foreground and background. This threshold is determined by minimizing intra-class intensity variance, or equivalently, by maximizing inter-class variance. Otsus method is a one-dimensional discrete analog of Fishers Discriminant Analysis, is related to Jenks optimization method, and is equivalent to a globally optimal k-means[3] performed on the intensity histogram. The extension to multi-level thresholding was described in the original paper, and computationally efficient implementations have since been proposed.[4][5]',
        id: '1647'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Green_screens_compare_with_Iman_Crosson_20110524.png/580px-Green_screens_compare_with_Iman_Crosson_20110524.png',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1648'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/SpiderwickChroniclesSet.jpg/534px-SpiderwickChroniclesSet.jpg',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1649'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Girl_in_front_of_a_green_background.jpg/346px-Girl_in_front_of_a_green_background.jpg',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1650'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Girl_in_room%2C_green_screen_example.jpg/412px-Girl_in_room%2C_green_screen_example.jpg',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1651'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/MuseumOfScienceBoston_BlueScreenAtSpecialEffectsShow.jpg/534px-MuseumOfScienceBoston_BlueScreenAtSpecialEffectsShow.jpg',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1652'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/en/d/dc/Myx_tv.jpg',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1653'
        },
        {
        title: 'Chroma key ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/200px-RBG_color_wheel.svg.png',
        description: 'Chroma key compositing, or chroma keying, is a visual-effects and post-production technique for compositing (layering) two images or video streams together based on colour hues (chroma range). The technique has been used in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture, and video game industries. A colour range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as colour keying, colour-separation overlay (CSO; primarily by the BBC[3]), or by various terms for specific colour-related variants such as green screen or blue screen; chroma keying can be done with backgrounds of any colour that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from any human skin colour. No part of the subject being filmed or photographed may duplicate the colour used as the backing, or the part may be erroneously identified as part of the backing.[4',
        id: '1654'
        },
        {
        title: 'Erosion (morphology) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/3/3a/Erosion.png',
        description: 'Erosion (usually represented by ⊖) is one of two fundamental operations (the other being dilation) in morphological image processing from which all other morphological operations are based. It was originally defined for binary images, later being extended to grayscale images, and subsequently to complete lattices. The erosion operation usually uses a structuring element for probing and reducing the shapes contained in the input image.',
        id: '1655'
        },
        {
        title: 'Erosion (morphology) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Grayscale_Morphological_Erosion.gif/440px-Grayscale_Morphological_Erosion.gif',
        description: 'Erosion (usually represented by ⊖) is one of two fundamental operations (the other being dilation) in morphological image processing from which all other morphological operations are based. It was originally defined for binary images, later being extended to grayscale images, and subsequently to complete lattices. The erosion operation usually uses a structuring element for probing and reducing the shapes contained in the input image.',
        id: '1656'
        },
        {
        title: 'Dilation (morphology) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/8/8d/Dilation.png',
        description: 'Dilation (usually represented by ⊕) is one of the basic operations in mathematical morphology. Originally developed for binary images, it has been expanded first to grayscale images, and then to complete lattices. The dilation operation usually uses a structuring element for probing and expanding the shapes contained in the input image.',
        id: '1657'
        },
        {
        title: 'Dilation (morphology) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Grayscale_Morphological_Dilation.gif/440px-Grayscale_Morphological_Dilation.gif',
        description: 'Dilation (usually represented by ⊕) is one of the basic operations in mathematical morphology. Originally developed for binary images, it has been expanded first to grayscale images, and then to complete lattices. The dilation operation usually uses a structuring element for probing and expanding the shapes contained in the input image.',
        id: '1658'
        },
        {
        title: 'Middle-square method ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Middle-square_method.svg/500px-Middle-square_method.svg.png',
        description: 'In mathematics, the middle-square method is a method of generating pseudorandom numbers. In practice it is not a good method, since its period is usually very short and it has some severe weaknesses; repeated enough times, the middle-square method will either begin repeatedly generating the same number or cycle to a previous number in the sequence and loop indefinitely.',
        id: '1659'
        },
        {
        title: 'Middle-square method ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Middle_square_method_2_digits.svg/500px-Middle_square_method_2_digits.svg.png',
        description: 'In mathematics, the middle-square method is a method of generating pseudorandom numbers. In practice it is not a good method, since its period is usually very short and it has some severe weaknesses; repeated enough times, the middle-square method will either begin repeatedly generating the same number or cycle to a previous number in the sequence and loop indefinitely.',
        id: '1660'
        },
        {
        title: 'Heaviside step function ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The Heaviside step function, or the unit step function, usually denoted by H or θ (but sometimes u, 1 or 𝟙), is a step function, named after Oliver Heaviside (1850–1925), the value of which is zero for negative arguments and one for positive arguments. It is an example of the general class of step functions, all of which can be represented as linear combinations of translations of this one.',
        id: '1661'
        },
        {
        title: 'Heaviside step function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/650px-Dirac_distribution_CDF.svg.png',
        description: 'The Heaviside step function, or the unit step function, usually denoted by H or θ (but sometimes u, 1 or 𝟙), is a step function, named after Oliver Heaviside (1850–1925), the value of which is zero for negative arguments and one for positive arguments. It is an example of the general class of step functions, all of which can be represented as linear combinations of translations of this one.',
        id: '1662'
        },
        {
        title: 'Heaviside step function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Step_function_approximation.png/500px-Step_function_approximation.png',
        description: 'The Heaviside step function, or the unit step function, usually denoted by H or θ (but sometimes u, 1 or 𝟙), is a step function, named after Oliver Heaviside (1850–1925), the value of which is zero for negative arguments and one for positive arguments. It is an example of the general class of step functions, all of which can be represented as linear combinations of translations of this one.',
        id: '1663'
        },
        {
        title: 'Dirac delta function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Navier_Stokes_Laminar.svg/470px-Navier_Stokes_Laminar.svg.png',
        description: 'In mathematics, the Dirac delta distribution (δ distribution), also known as the unit impulse symbol, is a generalized function or distribution over the real numbers, whose value is zero everywhere except at zero, and whose integral over the entire real line is equal to one.[3][4',
        id: '1664'
        },
        {
        title: 'Dirac delta function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Dirac_distribution_PDF.svg/650px-Dirac_distribution_PDF.svg.png',
        description: 'In mathematics, the Dirac delta distribution (δ distribution), also known as the unit impulse symbol, is a generalized function or distribution over the real numbers, whose value is zero everywhere except at zero, and whose integral over the entire real line is equal to one.[3][4',
        id: '1665'
        },
        {
        title: 'Dirac delta function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/b4/Dirac_function_approximation.gif',
        description: 'In mathematics, the Dirac delta distribution (δ distribution), also known as the unit impulse symbol, is a generalized function or distribution over the real numbers, whose value is zero everywhere except at zero, and whose integral over the entire real line is equal to one.[3][4',
        id: '1666'
        },
        {
        title: 'Dirac delta function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Dirac_comb.svg/440px-Dirac_comb.svg.png',
        description: 'In mathematics, the Dirac delta distribution (δ distribution), also known as the unit impulse symbol, is a generalized function or distribution over the real numbers, whose value is zero everywhere except at zero, and whose integral over the entire real line is equal to one.[3][4',
        id: '1667'
        },
        {
        title: 'Dirac delta function ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png',
        description: 'In mathematics, the Dirac delta distribution (δ distribution), also known as the unit impulse symbol, is a generalized function or distribution over the real numbers, whose value is zero everywhere except at zero, and whose integral over the entire real line is equal to one.[3][4',
        id: '1668'
        },
        {
        title: 'Inpainting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Restoration.jpg/700px-Restoration.jpg',
        description: 'Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image. This process can be applied to both physical and digital art mediums such as oil or acrylic paintings, chemical photographic prints, sculptures, or digital images and video. ',
        id: '1669'
        },
        {
        title: 'Inpainting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Restoration_using_Artificial_intelligence.jpg/440px-Restoration_using_Artificial_intelligence.jpg',
        description: 'Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image. This process can be applied to both physical and digital art mediums such as oil or acrylic paintings, chemical photographic prints, sculptures, or digital images and video. ',
        id: '1670'
        },
        {
        title: 'Inpainting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Piero_della_Francesca_-_Scene_after_and_before_restoration_-_WGA17592.jpg/440px-Piero_della_Francesca_-_Scene_after_and_before_restoration_-_WGA17592.jpg',
        description: 'Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image. This process can be applied to both physical and digital art mediums such as oil or acrylic paintings, chemical photographic prints, sculptures, or digital images and video. ',
        id: '1671'
        },
        {
        title: 'Inpainting ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Digital_Image_Restoration_and_Reconstraction.jpg/440px-Digital_Image_Restoration_and_Reconstraction.jpg',
        description: 'Inpainting is a conservation process where damaged, deteriorating, or missing parts of an artwork are filled in to present a complete image. This process can be applied to both physical and digital art mediums such as oil or acrylic paintings, chemical photographic prints, sculptures, or digital images and video. ',
        id: '1672'
        },
        {
        title: 'Rear projection ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Rear_projection_effect.jpg/440px-Rear_projection_effect.jpg',
        description: 'Rear projection (background projection, process photography, etc.) is one of many in-camera effects cinematic techniques in film production for combining foreground performances with pre-filmed backgrounds. It was widely used for many years in driving scenes, or to show other forms of "distant" background motion.',
        id: '1673'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Radon_transform.png/542px-Radon_transform.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1674'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Sinogram_-_Two_Square_Indicator_Phantom.svg/798px-Sinogram_-_Two_Square_Indicator_Phantom.svg.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1675'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Sinogram_Source_-_Two_Squares_Phantom.svg/440px-Sinogram_Source_-_Two_Squares_Phantom.svg.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1676'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/9/93/Radon_transform_sinogram.gif',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1677'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/SheppLogan_Phantom.svg/338px-SheppLogan_Phantom.svg.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1678'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Shepp_logan_radon.png/84px-Shepp_logan_radon.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1679'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Shepp_logan_iradon.png/338px-Shepp_logan_iradon.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1680'
        },
        {
        title: 'Radon transform ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Radon_transform_via_Fourier_transform.png/2000px-Radon_transform_via_Fourier_transform.png',
        description: 'In mathematics, the Radon transform is the integral transform which takes a function f defined on the plane to a function Rf defined on the (two-dimensional) space of lines in the plane, whose value at a particular line is equal to the line integral of the function over that line. The transform was introduced in 1917 by Johann Radon, who also provided a formula for the inverse transform. Radon further included formulas for the transform in three dimensions, in which the integral is taken over planes (integrating over lines is known as the X-ray transform).  It was later generalized to higher-dimensional Euclidean spaces, and more broadly in the context of integral geometry.  The complex analogue of the Radon transform is known as the Penrose transform. The Radon transform is widely applicable to tomography, the creation of an image from the projection data associated with cross-sectional scans of an object.',
        id: '1681'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1682'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Convolution_Illustrated_eng.png/270px-Convolution_Illustrated_eng.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1683'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Spherical-aberration-disk.jpg/538px-Spherical-aberration-disk.jpg',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1684'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/PSF_Deconvolution_V.png/530px-PSF_Deconvolution_V.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1685'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/SquarePost.svg/440px-SquarePost.svg.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1686'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/PSF.svg/800px-PSF.svg.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1687'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Airy-3d.svg/600px-Airy-3d.svg.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1688'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/63x_1.4NA_Confocal_Point_Spread_Function_2%2B3D.png/440px-63x_1.4NA_Confocal_Point_Spread_Function_2%2B3D.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1689'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Hubble_PSF_with_flawed_optics.jpg/220px-Hubble_PSF_with_flawed_optics.jpg',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1690'
        },
        {
        title: 'Point spread function ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Airy_spot_overlap.png/600px-Airy_spot_overlap.png',
        description: 'The point spread function (PSF) describes the response of an imaging system to a point source or point object. A more general term for the PSF is a systems impulse response, the PSF being the impulse response of a focused optical system. The PSF in many contexts can be thought of as the extended blob in an image that represents a single point object. In functional terms, it is the spatial domain version of the optical transfer function of the imaging system. It is a useful concept in Fourier optics, astronomical imaging, medical imaging, electron microscopy and other imaging techniques such as 3D microscopy (like in confocal laser scanning microscopy) and fluorescence microscopy. ',
        id: '1691'
        },
        {
        title: 'Wiener filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Wiener_block.svg/700px-Wiener_block.svg.png',
        description: 'In signal processing, the Wiener filter is a filter used to produce an estimate of a desired or target random process by linear time-invariant (LTI) filtering of an observed noisy process, assuming known stationary signal and noise spectra, and additive noise. The Wiener filter minimizes the mean square error between the estimated random process and the desired process.',
        id: '1692'
        },
        {
        title: 'Wiener filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Astronaut-noise.png/400px-Astronaut-noise.png',
        description: 'In signal processing, the Wiener filter is a filter used to produce an estimate of a desired or target random process by linear time-invariant (LTI) filtering of an observed noisy process, assuming known stationary signal and noise spectra, and additive noise. The Wiener filter minimizes the mean square error between the estimated random process and the desired process.',
        id: '1693'
        },
        {
        title: 'Wiener filter ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Astronaut-denoised.png/400px-Astronaut-denoised.png',
        description: 'In signal processing, the Wiener filter is a filter used to produce an estimate of a desired or target random process by linear time-invariant (LTI) filtering of an observed noisy process, assuming known stationary signal and noise spectra, and additive noise. The Wiener filter minimizes the mean square error between the estimated random process and the desired process.',
        id: '1694'
        },
        {
        title: 'Feature (computer vision) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Writing_Desk_with_Harris_Detector.png/440px-Writing_Desk_with_Harris_Detector.png',
        description: 'In computer vision and image processing, a feature is a piece of information about the content of an image; typically about whether a certain region of the image has certain properties. Features may be specific structures in the image such as points, edges or objects. Features may also be the result of a general neighborhood operation or feature detection applied to the image. Other examples of features are related to motion in image sequences, or to shapes defined in terms of curves or boundaries between different image regions.',
        id: '1695'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/d/db/Relief_of_gradient_of_heart_MRI.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1696'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/e/ea/Gradient_of_MRI_heart_image.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1697'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0d/Watershed_of_gradient_of_MRI_heart_image.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1698'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/0/0f/Relief_view_of_the_watershed_of_the_gradient_of_an_MRI_heart_image.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1699'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/FrDo_Capsule_VolSegmentation_Watershed.jpg/440px-FrDo_Capsule_VolSegmentation_Watershed.jpg',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1700'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Minimum_Spanning_Forest_of_the_gradient_of_an_image.png/239px-Minimum_Spanning_Forest_of_the_gradient_of_an_image.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1701'
        },
        {
        title: 'Watershed (image processing) ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Result_of_a_segmentation_by_minimum_spanning_forest.png/240px-Result_of_a_segmentation_by_minimum_spanning_forest.png',
        description: 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.',
        id: '1702'
        },
        {
        title: 'Active contour model ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Snake-contour-example.jpg/500px-Snake-contour-example.jpg',
        description: 'Active contour model, also called snakes, is a framework in computer vision introduced by Michael Kass, Andrew Witkin, and Demetri Terzopoulos for delineating an object outline from a possibly noisy 2D image. The snakes model is popular in computer vision, and snakes are widely used in applications like object tracking, shape recognition, segmentation, edge detection and stereo matching.',
        id: '1703'
        },
        {
        title: 'Lambertian reflectance ',
        url: 'https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png',
        description: 'Lambertian reflectance is the property that defines an ideal "matte" or diffusely reflecting surface. The apparent brightness of a Lambertian surface to an observer is the same regardless of the observers angle of view. More technically, the surfaces luminance is isotropic, and the luminous intensity obeys Lamberts cosine law. Lambertian reflectance is named after Johann Heinrich Lambert, who introduced the concept of perfect diffusion in his 1760 book Photometria.',
        id: '1704'
        },
        {
        title: 'Lambertian reflectance ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Oswietlenie_lamberta.svg/440px-Oswietlenie_lamberta.svg.png',
        description: 'Lambertian reflectance is the property that defines an ideal "matte" or diffusely reflecting surface. The apparent brightness of a Lambertian surface to an observer is the same regardless of the observers angle of view. More technically, the surfaces luminance is isotropic, and the luminous intensity obeys Lamberts cosine law. Lambertian reflectance is named after Johann Heinrich Lambert, who introduced the concept of perfect diffusion in his 1760 book Photometria.',
        id: '1705'
        },
        {
        title: 'Super-resolution imaging ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Structured_Illumination_Superresolution.png/440px-Structured_Illumination_Superresolution.png',
        description: 'Super-resolution imaging (SR) is a class of techniques that enhance (increase) the resolution of an imaging system. In optical SR the diffraction limit of systems is transcended, while in geometrical SR the resolution of digital imaging sensors is enhanced.',
        id: '1706'
        },
        {
        title: 'Super-resolution imaging ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/b/be/Super-resolution_example_closeup.png',
        description: 'Super-resolution imaging (SR) is a class of techniques that enhance (increase) the resolution of an imaging system. In optical SR the diffraction limit of systems is transcended, while in geometrical SR the resolution of digital imaging sensors is enhanced.',
        id: '1707'
        },
        {
        title: 'Super-resolution imaging ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Localization_Resolution.png/220px-Localization_Resolution.png',
        description: 'Super-resolution imaging (SR) is a class of techniques that enhance (increase) the resolution of an imaging system. In optical SR the diffraction limit of systems is transcended, while in geometrical SR the resolution of digital imaging sensors is enhanced.',
        id: '1708'
        },
        {
        title: 'Jenks natural breaks optimization ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Natural_Breaks_Map.gif/220px-Natural_Breaks_Map.gif',
        description: 'The Jenks optimization method, also called the Jenks natural breaks classification method, is a data clustering method designed to determine the best arrangement of values into different classes. This is done by seeking to minimize each classs average deviation from the class mean, while maximizing each classs deviation from the means of the other classes. In other words, the method seeks to reduce the variance within classes and maximize the variance between classes.',
        id: '1709'
        },
        {
        title: 'Linear discriminant analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Fisher2classes.png/440px-Fisher2classes.png',
        description: 'Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fishers linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.',
        id: '1710'
        },
        {
        title: 'Linear discriminant analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/4class3ddiscriminant.png/440px-4class3ddiscriminant.png',
        description: 'Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fishers linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.',
        id: '1711'
        },
        {
        title: 'Linear discriminant analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/3dProjections.png/440px-3dProjections.png',
        description: 'Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fishers linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.',
        id: '1712'
        },
        {
        title: 'Linear discriminant analysis ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png',
        description: 'Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fishers linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.',
        id: '1713'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/The_Colors_of_Noise.png/440px-The_Colors_of_Noise.png',
        description: '',
        id: '1714'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/White_noise_spectrum.svg/440px-White_noise_spectrum.svg.png',
        description: '',
        id: '1715'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Pink_noise_spectrum.svg/440px-Pink_noise_spectrum.svg.png',
        description: '',
        id: '1716'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Brown_noise_spectrum.svg/440px-Brown_noise_spectrum.svg.png',
        description: '',
        id: '1717'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Blue_noise_spectrum.svg/440px-Blue_noise_spectrum.svg.png',
        description: '',
        id: '1718'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Violet_noise_spectrum.svg/440px-Violet_noise_spectrum.svg.png',
        description: '',
        id: '1719'
        },
        {
        title: 'Colors of noise ',
        url: 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Gray_noise_spectrum.svg/440px-Gray_noise_spectrum.svg.png',
        description: '',
        id: '1720'
        }


];